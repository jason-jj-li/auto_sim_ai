# é«˜çº§åŠŸèƒ½æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†é¡¹ç›®ä¸­å·²å®ç°ä½†åœ¨ä¸»æ–‡æ¡£ä¸­æœªå……åˆ†è¯´æ˜çš„é«˜çº§åŠŸèƒ½ã€‚

---

## ğŸ“‘ ç›®å½•

1. [é¡¹ç›®å¯¼å‡ºä¸å¯¼å…¥](#é¡¹ç›®å¯¼å‡ºä¸å¯¼å…¥)
2. [æ ·å¼ç³»ç»Ÿä¸UIå®šåˆ¶](#æ ·å¼ç³»ç»Ÿä¸uiå®šåˆ¶)
3. [å“åº”éªŒè¯ä¸è´¨é‡æ§åˆ¶](#å“åº”éªŒè¯ä¸è´¨é‡æ§åˆ¶)
4. [æ•æ„Ÿæ€§åˆ†æè¯¦è§£](#æ•æ„Ÿæ€§åˆ†æè¯¦è§£)
5. [äººç‰©ç”Ÿæˆå™¨é«˜çº§ç”¨æ³•](#äººç‰©ç”Ÿæˆå™¨é«˜çº§ç”¨æ³•)
6. [A/Bæµ‹è¯•è¿›é˜¶](#abæµ‹è¯•è¿›é˜¶)
7. [ä¼šè¯ç®¡ç†ä¸ä¸´æ—¶äººç‰©](#ä¼šè¯ç®¡ç†ä¸ä¸´æ—¶äººç‰©)

---

## 1. é¡¹ç›®å¯¼å‡ºä¸å¯¼å…¥

### åŠŸèƒ½æ¦‚è¿°

`ProjectManager` å…è®¸æ‚¨å°†æ•´ä¸ªç ”ç©¶é¡¹ç›®ï¼ˆåŒ…æ‹¬äººç‰©ã€è°ƒæŸ¥é…ç½®ã€ç»“æœï¼‰æ‰“åŒ…ä¸º `.zip` æ–‡ä»¶ï¼Œæ–¹ä¾¿åˆ†äº«ã€å¤‡ä»½å’Œç‰ˆæœ¬æ§åˆ¶ã€‚

### æ ¸å¿ƒç±»

**ä½ç½®**: `src/project.py`

```python
from src import ProjectManager
```

### ä½¿ç”¨ç¤ºä¾‹

#### 1.1 å¯¼å‡ºé¡¹ç›®

```python
from pathlib import Path
from src import ProjectManager

# åˆå§‹åŒ–é¡¹ç›®ç®¡ç†å™¨
project_manager = ProjectManager(
    workspace_dir=".",           # å·¥ä½œç©ºé—´æ ¹ç›®å½•
    export_dir="exports"         # å¯¼å‡ºç›®å½•
)

# å¯¼å‡ºå®Œæ•´é¡¹ç›®
export_path = project_manager.export_project(
    project_name="health_intervention_study",
    include_personas=True,        # åŒ…å«äººç‰©æ•°æ®
    include_survey_configs=True,  # åŒ…å«è°ƒæŸ¥é…ç½®
    include_results=True,         # åŒ…å«ç»“æœæ•°æ®
    description="ç ”ç©¶æ­£å¿µå†¥æƒ³å¯¹å‹åŠ›çš„å½±å“"
)

print(f"é¡¹ç›®å·²å¯¼å‡ºè‡³: {export_path}")
# è¾“å‡º: é¡¹ç›®å·²å¯¼å‡ºè‡³: exports/health_intervention_study_20231028_143022.zip
```

#### 1.2 å¯¼å…¥é¡¹ç›®

```python
# å¯¼å…¥å·²å¯¼å‡ºçš„é¡¹ç›®
import_dir = project_manager.import_project(
    zip_path="exports/health_intervention_study_20231028_143022.zip",
    target_dir="imported_projects/health_study"
)

print(f"é¡¹ç›®å·²å¯¼å…¥è‡³: {import_dir}")

# æŸ¥çœ‹é¡¹ç›®å…ƒæ•°æ®
metadata_path = Path(import_dir) / "project_metadata.json"
import json
with open(metadata_path, 'r') as f:
    metadata = json.load(f)

print(f"é¡¹ç›®åç§°: {metadata['project_name']}")
print(f"å¯¼å‡ºæ—¥æœŸ: {metadata['export_date']}")
print(f"æè¿°: {metadata['description']}")
```

#### 1.3 é€‰æ‹©æ€§å¯¼å‡º

```python
# ä»…å¯¼å‡ºäººç‰©å’Œé…ç½®ï¼Œä¸åŒ…å«ç»“æœï¼ˆç”¨äºåˆ†äº«ç ”ç©¶è®¾è®¡ï¼‰
export_path = project_manager.export_project(
    project_name="meditation_study_design",
    include_personas=True,
    include_survey_configs=True,
    include_results=False,  # ä¸åŒ…å«ç»“æœ
    description="å†¥æƒ³å¹²é¢„ç ”ç©¶è®¾è®¡æ¨¡æ¿"
)
```

### å¯¼å‡ºåŒ…ç»“æ„

```
project_name_timestamp.zip
â”œâ”€â”€ project_metadata.json    # é¡¹ç›®å…ƒæ•°æ®
â”œâ”€â”€ personas/                # äººç‰©æ•°æ®
â”‚   â”œâ”€â”€ persona_001.json
â”‚   â”œâ”€â”€ persona_002.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ survey_configs/          # è°ƒæŸ¥é…ç½®
â”‚   â”œâ”€â”€ phq9_config.json
â”‚   â””â”€â”€ ...
â””â”€â”€ results/                 # ç»“æœæ•°æ®ï¼ˆå¯é€‰ï¼‰
    â”œâ”€â”€ simulation_001.json
    â”œâ”€â”€ simulation_001.csv
    â””â”€â”€ ...
```

### ä½¿ç”¨åœºæ™¯

- âœ… **å›¢é˜Ÿåä½œ**: åˆ†äº«ç ”ç©¶è®¾è®¡ç»™åŒäº‹
- âœ… **ç‰ˆæœ¬æ§åˆ¶**: ä¿å­˜ç ”ç©¶çš„ä¸åŒç‰ˆæœ¬
- âœ… **å¤‡ä»½**: å®šæœŸå¤‡ä»½é‡è¦é¡¹ç›®
- âœ… **å‘å¸ƒ**: ä¸è®ºæ–‡ä¸€èµ·å‘å¸ƒå¯é‡å¤çš„ç ”ç©¶æ•°æ®
- âœ… **è¿ç§»**: åœ¨ä¸åŒè®¡ç®—æœºé—´è½¬ç§»é¡¹ç›®

---

## 2. æ ·å¼ç³»ç»Ÿä¸UIå®šåˆ¶

### åŠŸèƒ½æ¦‚è¿°

é¡¹ç›®ä½¿ç”¨ç»Ÿä¸€çš„è®¾è®¡ç³»ç»Ÿ (`src/styles.py`) æ¥ç¡®ä¿æ‰€æœ‰ Streamlit é¡µé¢çš„ä¸€è‡´æ€§å’Œä¸“ä¸šå¤–è§‚ã€‚

### æ ¸å¿ƒæ¨¡å—

**ä½ç½®**: `src/styles.py`

```python
from src.styles import apply_global_styles, GLOBAL_STYLES
```

### è®¾è®¡ç³»ç»Ÿå˜é‡

```python
# ä¸»è‰²è°ƒ
--primary: #3b82f6          # è“è‰²
--primary-hover: #2563eb    
--primary-light: #eff6ff    

# è¯­ä¹‰è‰²å½©
--success: #22c55e          # ç»¿è‰²ï¼ˆæˆåŠŸï¼‰
--warning: #f59e0b          # æ©™è‰²ï¼ˆè­¦å‘Šï¼‰
--error: #ef4444            # çº¢è‰²ï¼ˆé”™è¯¯ï¼‰
--info: #3b82f6             # è“è‰²ï¼ˆä¿¡æ¯ï¼‰

# ç°åº¦è‰²å½©
--gray-50 åˆ° --gray-900     # æ¸å˜ç°åº¦

# é˜´å½±
--shadow-xs åˆ° --shadow-xl  # ä¸åŒå±‚çº§é˜´å½±

# åœ†è§’
--radius-sm: 4px
--radius-md: 8px
--radius-lg: 12px
```

### ä½¿ç”¨ç¤ºä¾‹

#### 2.1 åº”ç”¨å…¨å±€æ ·å¼

```python
import streamlit as st
from src.styles import apply_global_styles

st.set_page_config(page_title="My Page", layout="wide")

# åº”ç”¨å…¨å±€æ ·å¼
apply_global_styles()

# ä¹‹åçš„æ‰€æœ‰ç»„ä»¶è‡ªåŠ¨åº”ç”¨ç»Ÿä¸€æ ·å¼
st.title("æ ‡é¢˜ä¼šä½¿ç”¨è®¾è®¡ç³»ç»Ÿæ ·å¼")
st.button("Primary Button", type="primary")
```

#### 2.2 è‡ªå®šä¹‰å¡ç‰‡ç»„ä»¶

```python
st.markdown(f"""
<div style="
    background: white;
    padding: 1.5rem;
    border-radius: var(--radius-lg);
    box-shadow: var(--shadow-md);
    margin-bottom: 1rem;
">
    <h3 style="color: var(--primary); margin-top: 0;">å¡ç‰‡æ ‡é¢˜</h3>
    <p style="color: var(--gray-700);">å¡ç‰‡å†…å®¹</p>
</div>
""", unsafe_allow_html=True)
```

#### 2.3 çŠ¶æ€æŒ‡ç¤ºå™¨

```python
# æˆåŠŸçŠ¶æ€
st.markdown("""
<div style="
    background: var(--success-light);
    color: var(--success);
    padding: 1rem;
    border-radius: var(--radius-md);
    border-left: 4px solid var(--success);
">
    âœ… æ“ä½œæˆåŠŸï¼
</div>
""", unsafe_allow_html=True)

# è­¦å‘ŠçŠ¶æ€
st.markdown("""
<div style="
    background: var(--warning-light);
    color: var(--warning);
    padding: 1rem;
    border-radius: var(--radius-md);
    border-left: 4px solid var(--warning);
">
    âš ï¸ è¯·æ³¨æ„è¿™ä¸ªé—®é¢˜
</div>
""", unsafe_allow_html=True)
```

### å¯ç”¨ç»„ä»¶æ ·å¼

ç³»ç»Ÿå·²é¢„å®šä¹‰ä»¥ä¸‹ç»„ä»¶æ ·å¼ï¼š
- æŒ‰é’®ï¼ˆä¸»è¦ã€æ¬¡è¦ã€ç¦ç”¨ï¼‰
- å¡ç‰‡å’Œå®¹å™¨
- è¾“å…¥æ¡†å’Œè¡¨å•å…ƒç´ 
- è¡¨æ ¼å’Œæ•°æ®æ˜¾ç¤º
- ä¾§è¾¹æ å’Œå¯¼èˆª
- çŠ¶æ€æŒ‡ç¤ºå™¨ï¼ˆæˆåŠŸã€è­¦å‘Šã€é”™è¯¯ã€ä¿¡æ¯ï¼‰
- åŠ è½½åŠ¨ç”»å’Œè¿›åº¦æ¡

### å®šåˆ¶å»ºè®®

å¦‚éœ€å®šåˆ¶UIï¼Œä¿®æ”¹ `src/styles.py` ä¸­çš„ CSS å˜é‡å³å¯å½±å“æ•´ä¸ªåº”ç”¨ï¼š

```python
# ä¾‹å¦‚ï¼šæ›´æ”¹ä¸»è‰²è°ƒä¸ºç´«è‰²
:root {
    --primary: #8b5cf6;
    --primary-hover: #7c3aed;
    --primary-light: #f3e8ff;
}
```

---

## 3. å“åº”éªŒè¯ä¸è´¨é‡æ§åˆ¶

### åŠŸèƒ½æ¦‚è¿°

`ResponseValidator` å’Œ `ConsistencyChecker` æä¾›å…¨é¢çš„å“åº”è´¨é‡éªŒè¯ï¼Œç¡®ä¿ LLM ç”Ÿæˆçš„å“åº”ç¬¦åˆé¢„æœŸã€‚

### æ ¸å¿ƒç±»

**ä½ç½®**: `src/validation.py`

```python
from src import ResponseValidator, ConsistencyChecker, ConsistencyMetrics
```

### 3.1 å“åº”éªŒè¯å™¨ (ResponseValidator)

#### æ£€æµ‹æ— æ•ˆå“åº”

```python
validator = ResponseValidator()

# æ£€æµ‹å•ä¸ªå“åº”
response = "I don't know"
is_valid = validator.is_valid_response(response)
print(f"å“åº”æ˜¯å¦æœ‰æ•ˆ: {is_valid}")  # False

# æ£€æµ‹æ— å›ç­”æ¨¡å¼
response = "N/A"
is_non_responsive = validator.is_non_responsive(response)
print(f"æ˜¯å¦ä¸ºæ— å›ç­”: {is_non_responsive}")  # True
```

#### æå–æ•°å€¼

```python
# ä»æ–‡æœ¬ä¸­æå–æ•°å€¼
response = "æˆ‘çš„å‹åŠ›æ°´å¹³æ˜¯ 8 åˆ†ï¼ˆæ»¡åˆ†10åˆ†ï¼‰"
value = validator.extract_numeric_value(response)
print(f"æå–çš„æ•°å€¼: {value}")  # 8.0

# ä»é‡è¡¨å“åº”ä¸­æå–
response = "æˆ‘é€‰æ‹© 'éå¸¸åŒæ„'ï¼Œè¿™å¯¹åº”åˆ†æ•° 5"
value = validator.extract_scale_value(response, scale_type="likert_5")
print(f"é‡è¡¨å¾—åˆ†: {value}")  # 5.0
```

#### éªŒè¯å“åº”é•¿åº¦

```python
response = "å¥½çš„"
is_sufficient = validator.is_sufficient_length(
    response, 
    min_length=10,      # æœ€å°‘10ä¸ªå­—ç¬¦
    min_words=3         # æœ€å°‘3ä¸ªè¯
)
print(f"é•¿åº¦æ˜¯å¦å……åˆ†: {is_sufficient}")  # False
```

#### æ£€æµ‹çŸ›ç›¾å“åº”

```python
response = "æˆ‘éå¸¸åŒæ„ï¼Œä½†æˆ‘å®Œå…¨ä¸èµæˆè¿™ä¸ªè§‚ç‚¹"
is_contradictory = validator.has_contradictions(response)
print(f"æ˜¯å¦å­˜åœ¨çŸ›ç›¾: {is_contradictory}")  # True
```

### 3.2 ä¸€è‡´æ€§æ£€æŸ¥å™¨ (ConsistencyChecker)

#### æ£€æŸ¥é‡å¤æµ‹è¯•çš„ä¸€è‡´æ€§

```python
checker = ConsistencyChecker()

# åŒä¸€é—®é¢˜çš„å¤šæ¬¡å“åº”
persona_name = "å¼ ä¸‰"
question = "ä½ çš„å‹åŠ›æ°´å¹³ï¼ˆ1-10ï¼‰"
responses = ["7", "8", "7", "6", "7"]

metrics = checker.check_consistency(
    persona_name=persona_name,
    question=question,
    responses=responses,
    threshold=0.8  # ä¸€è‡´æ€§é˜ˆå€¼
)

print(f"å¹³å‡å€¼: {metrics.mean_value}")           # 7.0
print(f"æ ‡å‡†å·®: {metrics.std_dev}")               # 0.71
print(f"å˜å¼‚ç³»æ•°: {metrics.coefficient_variation}")  # 0.10
print(f"ä¸€è‡´æ€§å¾—åˆ†: {metrics.consistency_score}")    # 0.93
print(f"æ˜¯å¦ä¸€è‡´: {metrics.is_consistent}")          # True
```

#### æ‰¹é‡æ£€æŸ¥å¤šä¸ªäººç‰©

```python
# æ£€æŸ¥æ‰€æœ‰äººç‰©å¯¹æŸé—®é¢˜çš„ä¸€è‡´æ€§
results = [
    {"persona": "å¼ ä¸‰", "question": "Q1", "response": "7"},
    {"persona": "å¼ ä¸‰", "question": "Q1", "response": "8"},
    {"persona": "æå››", "question": "Q1", "response": "3"},
    {"persona": "æå››", "question": "Q1", "response": "3"},
]

all_metrics = checker.check_multiple_personas(results)

for metrics in all_metrics:
    print(f"{metrics.persona_name} - {metrics.question}: "
          f"ä¸€è‡´æ€§å¾—åˆ† {metrics.consistency_score:.2f}")
```

#### ç”Ÿæˆä¸€è‡´æ€§æŠ¥å‘Š

```python
# ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
report = checker.generate_consistency_report(all_metrics)

print(report['summary'])
# è¾“å‡º:
# {
#   'total_personas': 2,
#   'total_questions': 1,
#   'overall_consistency': 0.95,
#   'highly_consistent': 2,
#   'inconsistent': 0
# }
```

### 3.3 å®æˆ˜æ¡ˆä¾‹ï¼šè´¨é‡æ§åˆ¶æµç¨‹

```python
from src import SimulationEngine, ResponseValidator, ConsistencyChecker

# 1. è¿è¡Œæ¨¡æ‹Ÿ
engine = SimulationEngine(llm_client=client)
results = engine.run_simulation(personas=personas, questions=questions)

# 2. éªŒè¯å“åº”è´¨é‡
validator = ResponseValidator()
valid_results = []
invalid_count = 0

for result in results:
    response = result['response']
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ•ˆ
    if validator.is_valid_response(response):
        # æ£€æŸ¥æ˜¯å¦è¶³å¤Ÿè¯¦ç»†
        if validator.is_sufficient_length(response, min_words=5):
            valid_results.append(result)
        else:
            print(f"å“åº”è¿‡çŸ­: {result['persona_name']} - {response}")
            invalid_count += 1
    else:
        print(f"æ— æ•ˆå“åº”: {result['persona_name']} - {response}")
        invalid_count += 1

print(f"æœ‰æ•ˆå“åº”: {len(valid_results)} / {len(results)}")
print(f"æ— æ•ˆå“åº”: {invalid_count}")

# 3. æ£€æŸ¥ä¸€è‡´æ€§ï¼ˆé‡å¤æµ‹è¯•ï¼‰
if 'ç¬¬äºŒè½®' in results:
    checker = ConsistencyChecker()
    consistency_metrics = checker.check_consistency(
        persona_name="å¼ ä¸‰",
        question="Q1",
        responses=[r['response'] for r in results if r['persona_name']=='å¼ ä¸‰']
    )
    
    if not consistency_metrics.is_consistent:
        print(f"è­¦å‘Š: {consistency_metrics.persona_name} çš„å“åº”ä¸ä¸€è‡´!")
```

### éªŒè¯æœ€ä½³å®è·µ

1. **é¢„è¿‡æ»¤**: è¿è¡Œå°è§„æ¨¡æµ‹è¯•ï¼Œè°ƒæ•´ prompt ç›´åˆ°æ— æ•ˆå“åº”ç‡ < 5%
2. **é‡è¯•æœºåˆ¶**: å¯¹æ— æ•ˆå“åº”è‡ªåŠ¨é‡æ–°ç”Ÿæˆ
3. **é˜ˆå€¼è°ƒæ•´**: æ ¹æ®ç ”ç©¶éœ€æ±‚è°ƒæ•´ä¸€è‡´æ€§é˜ˆå€¼ï¼ˆå®½æ¾ï¼š0.6ï¼Œä¸¥æ ¼ï¼š0.9ï¼‰
4. **æ—¥å¿—è®°å½•**: ä¿å­˜æ‰€æœ‰éªŒè¯ç»“æœç”¨äºè´¨é‡å®¡è®¡

---

## 4. æ•æ„Ÿæ€§åˆ†æè¯¦è§£

### åŠŸèƒ½æ¦‚è¿°

`SensitivityAnalyzer` ç”¨äºæµ‹è¯•æ¨¡æ‹Ÿç»“æœå¯¹å‚æ•°å˜åŒ–çš„æ•æ„Ÿæ€§ï¼Œè¯„ä¼°å‘ç°çš„ç¨³å¥æ€§ã€‚

### æ ¸å¿ƒç±»

**ä½ç½®**: `src/sensitivity.py`

```python
from src import SensitivityAnalyzer
```

### 4.1 æ¸©åº¦å‚æ•°æ•æ„Ÿæ€§

```python
from src import SensitivityAnalyzer, SimulationEngine, LMStudioClient

analyzer = SensitivityAnalyzer()
client = LMStudioClient(base_url="http://localhost:1234/v1")
engine = SimulationEngine(llm_client=client)

# å®šä¹‰æ¨¡æ‹Ÿå‡½æ•°
def run_simulation(personas, questions, temperature, **kwargs):
    client.temperature = temperature
    return engine.run_simulation(personas=personas, questions=questions)

# æµ‹è¯•ä¸åŒæ¸©åº¦
temp_results = analyzer.temperature_sensitivity(
    simulation_func=run_simulation,
    personas=personas,
    questions=questions,
    temperature_range=[0.1, 0.3, 0.5, 0.7, 0.9],
)

print(f"æ¸©åº¦æ•æ„Ÿæ€§: {temp_results['variance']}")
print(f"æœ€ç¨³å®šæ¸©åº¦: {temp_results['most_stable_temp']}")
```

### 4.2 Prompt æªè¾æ•æ„Ÿæ€§

```python
# æµ‹è¯•ä¸åŒ prompt æªè¾
prompt_variants = [
    "è¯·è¯„ä¼°ä½ çš„å‹åŠ›æ°´å¹³ï¼ˆ1-10ï¼‰",
    "åœ¨1åˆ°10çš„èŒƒå›´å†…ï¼Œä½ çš„å‹åŠ›æœ‰å¤šå¤§ï¼Ÿ",
    "ç”¨1-10çš„æ•°å­—æè¿°ä½ ç›®å‰çš„å‹åŠ›ç¨‹åº¦",
]

prompt_results = analyzer.prompt_sensitivity(
    simulation_func=run_simulation,
    personas=personas,
    prompt_variants=prompt_variants
)

# æŸ¥çœ‹ä¸åŒæªè¾çš„å“åº”åˆ†å¸ƒ
for i, prompt in enumerate(prompt_variants):
    print(f"Prompt {i+1}: å¹³å‡å¾—åˆ† {prompt_results['means'][i]:.2f}")
```

### 4.3 äººç‰©æ ·æœ¬æ•æ„Ÿæ€§

```python
# æµ‹è¯•ä¸åŒäººç‰©å­é›†
subset_results = analyzer.persona_subset_sensitivity(
    simulation_func=run_simulation,
    personas=personas,
    questions=questions,
    subset_sizes=[10, 20, 50, 100],  # ä¸åŒæ ·æœ¬é‡
    num_iterations=5  # æ¯ä¸ªæ ·æœ¬é‡é‡å¤5æ¬¡
)

print(f"æ ·æœ¬ç¨³å®šæ€§: {subset_results['stability_score']}")
```

### 4.4 è‡ªå®šä¹‰å‚æ•°æ•æ„Ÿæ€§

```python
# æµ‹è¯•ä»»æ„å‚æ•°
custom_results = analyzer.parameter_sensitivity(
    simulation_func=run_simulation,
    personas=personas,
    questions=questions,
    parameter_name="max_tokens",
    parameter_values=[100, 300, 500, 1000],
)

print(f"Tokené™åˆ¶å¯¹å“åº”çš„å½±å“: {custom_results['effect_size']}")
```

### 4.5 ç»¼åˆæ•æ„Ÿæ€§æŠ¥å‘Š

```python
# ç”Ÿæˆå®Œæ•´æ•æ„Ÿæ€§æŠ¥å‘Š
comprehensive_report = analyzer.comprehensive_sensitivity_analysis(
    simulation_func=run_simulation,
    personas=personas,
    questions=questions,
    test_temperature=True,
    test_prompts=True,
    test_subsets=True,
    output_file="sensitivity_report.json"
)

print(f"æ€»ä½“ç¨³å¥æ€§å¾—åˆ†: {comprehensive_report['overall_robustness']:.2f}")
# 0-1 åˆ†æ•°ï¼Œè¶Šé«˜è¡¨ç¤ºå‘ç°è¶Šç¨³å¥
```

### ä½¿ç”¨åœºæ™¯

- ğŸ”¬ **ç ”ç©¶éªŒè¯**: ç¡®ä¿å‘ç°ä¸ä¾èµ–äºç‰¹å®šå‚æ•°é€‰æ‹©
- ğŸ“Š **æŠ¥å‘Šè¡¥å……**: åœ¨è®ºæ–‡ä¸­æŠ¥å‘Šæ•æ„Ÿæ€§åˆ†æç»“æœ
- âš™ï¸ **å‚æ•°ä¼˜åŒ–**: æ‰¾åˆ°æœ€ä½³æ¸©åº¦ã€tokené™åˆ¶ç­‰
- ğŸ¯ **ç½®ä¿¡åº¦è¯„ä¼°**: é‡åŒ–ç»“æœçš„å¯é æ€§

---

## 5. äººç‰©ç”Ÿæˆå™¨é«˜çº§ç”¨æ³•

### åŠŸèƒ½æ¦‚è¿°

`PersonaGenerator` å¯ä»¥æ ¹æ®ç»Ÿè®¡åˆ†å¸ƒè‡ªåŠ¨ç”Ÿæˆå¤§é‡ç¬¦åˆäººå£å­¦ç‰¹å¾çš„è™šæ‹Ÿäººç‰©ã€‚

### æ ¸å¿ƒç±»

**ä½ç½®**: `src/persona_generator.py`

```python
from src import PersonaGenerator, DistributionConfig
```

### 5.1 åŸºäºåˆ†å¸ƒç”Ÿæˆäººç‰©

#### æ­£æ€åˆ†å¸ƒ

```python
from src import PersonaGenerator, DistributionConfig

generator = PersonaGenerator()

# å®šä¹‰å¹´é¾„åˆ†å¸ƒï¼ˆæ­£æ€åˆ†å¸ƒï¼‰
age_dist = DistributionConfig(
    variable_name="age",
    distribution_type="normal",
    parameters={
        'mean': 35,      # å¹³å‡å¹´é¾„35å²
        'std': 10,       # æ ‡å‡†å·®10
        'integer': True  # å–æ•´
    }
)

# ç”Ÿæˆ100ä¸ªäººç‰©
personas = generator.generate_from_distributions(
    distributions=[age_dist],
    n_personas=100
)

# éªŒè¯åˆ†å¸ƒ
ages = [p.demographics.get('age') for p in personas]
print(f"å¹³å‡å¹´é¾„: {sum(ages)/len(ages):.1f}")  # ~35
```

#### åˆ†ç±»åˆ†å¸ƒ

```python
# æ€§åˆ«åˆ†å¸ƒï¼ˆ60% å¥³æ€§ï¼Œ40% ç”·æ€§ï¼‰
gender_dist = DistributionConfig(
    variable_name="gender",
    distribution_type="categorical",
    parameters={
        'categories': ['å¥³', 'ç”·'],
        'probabilities': [0.6, 0.4]
    }
)

# èŒä¸šåˆ†å¸ƒ
occupation_dist = DistributionConfig(
    variable_name="occupation",
    distribution_type="categorical",
    parameters={
        'categories': ['æ•™å¸ˆ', 'å·¥ç¨‹å¸ˆ', 'åŒ»ç”Ÿ', 'é”€å”®', 'å­¦ç”Ÿ'],
        'probabilities': [0.2, 0.25, 0.15, 0.2, 0.2]
    }
)

# ç»„åˆå¤šä¸ªåˆ†å¸ƒ
personas = generator.generate_from_distributions(
    distributions=[age_dist, gender_dist, occupation_dist],
    n_personas=200
)
```

#### å‡åŒ€åˆ†å¸ƒ

```python
# æ”¶å…¥å‡åŒ€åˆ†å¸ƒåœ¨50k-150kä¹‹é—´
income_dist = DistributionConfig(
    variable_name="income",
    distribution_type="uniform",
    parameters={
        'low': 50000,
        'high': 150000,
        'integer': True
    }
)
```

### 5.2 å¤æ‚äººå£æ¨¡æ‹Ÿ

```python
# æ¨¡æ‹ŸçœŸå®åŸå¸‚äººå£
city_population = generator.generate_from_distributions(
    distributions=[
        # å¹´é¾„ï¼šæ­£æ€åˆ†å¸ƒï¼Œå‡å€¼38ï¼Œæ ‡å‡†å·®15
        DistributionConfig("age", "normal", 
            {'mean': 38, 'std': 15, 'integer': True}),
        
        # æ€§åˆ«ï¼š51% å¥³æ€§
        DistributionConfig("gender", "categorical",
            {'categories': ['å¥³', 'ç”·'], 'probabilities': [0.51, 0.49]}),
        
        # æ•™è‚²ï¼šå¤šç±»åˆ«åˆ†å¸ƒ
        DistributionConfig("education", "categorical", {
            'categories': ['é«˜ä¸­', 'å¤§ä¸“', 'æœ¬ç§‘', 'ç ”ç©¶ç”Ÿ'],
            'probabilities': [0.3, 0.25, 0.35, 0.1]
        }),
        
        # æ”¶å…¥ï¼šå¯¹æ•°æ­£æ€åˆ†å¸ƒï¼ˆåæ€ï¼‰
        DistributionConfig("income", "custom", {
            'values': [30000, 50000, 70000, 90000, 120000, 150000, 200000],
        }),
    ],
    n_personas=500
)

print(f"ç”Ÿæˆäº† {len(city_population)} ä¸ªåŸå¸‚å±…æ°‘äººç‰©")
```

### 5.3 æ¡ä»¶ç”Ÿæˆ

```python
# ç”Ÿæˆç‰¹å®šæ¡ä»¶çš„äººç‰©
def generate_high_stress_workers(n=50):
    """ç”Ÿæˆé«˜å‹åŠ›èŒä¸šäººç¾¤"""
    
    personas = generator.generate_from_distributions(
        distributions=[
            DistributionConfig("age", "normal", 
                {'mean': 32, 'std': 8, 'integer': True}),
            DistributionConfig("occupation", "categorical", {
                'categories': ['åŒ»ç”Ÿ', 'å¾‹å¸ˆ', 'æŠ•èµ„é“¶è¡Œå®¶', 'åˆ›ä¸šè€…'],
                'probabilities': [0.3, 0.3, 0.2, 0.2]
            }),
            DistributionConfig("stress_level", "normal",
                {'mean': 7.5, 'std': 1.0}),  # é«˜å‹åŠ›
        ],
        n_personas=n
    )
    
    return personas

stressed_workers = generate_high_stress_workers(100)
```

### 5.4 ä»çœŸå®æ•°æ®åŒ¹é…åˆ†å¸ƒ

```python
import pandas as pd
import numpy as np

# ä»çœŸå®è°ƒæŸ¥æ•°æ®æå–åˆ†å¸ƒ
real_data = pd.read_csv("real_survey_data.csv")

# æ‹Ÿåˆå¹´é¾„åˆ†å¸ƒ
age_mean = real_data['age'].mean()
age_std = real_data['age'].std()

# æ‹ŸåˆèŒä¸šåˆ†å¸ƒ
occupation_counts = real_data['occupation'].value_counts(normalize=True)

# ä½¿ç”¨æå–çš„åˆ†å¸ƒç”Ÿæˆè™šæ‹Ÿäººç‰©
synthetic_personas = generator.generate_from_distributions(
    distributions=[
        DistributionConfig("age", "normal", 
            {'mean': age_mean, 'std': age_std, 'integer': True}),
        DistributionConfig("occupation", "categorical", {
            'categories': occupation_counts.index.tolist(),
            'probabilities': occupation_counts.values.tolist()
        }),
    ],
    n_personas=len(real_data)  # ç”Ÿæˆç›¸åŒæ•°é‡
)

print("âœ… å·²ç”Ÿæˆä¸çœŸå®æ•°æ®åˆ†å¸ƒåŒ¹é…çš„è™šæ‹Ÿäººç‰©")
```

### 5.5 åˆ†å±‚æŠ½æ ·ç”Ÿæˆ

```python
def generate_stratified_sample():
    """ç”Ÿæˆåˆ†å±‚æ ·æœ¬ï¼šæ¯ä¸ªå¹´é¾„æ®µå„50äºº"""
    
    age_groups = [
        (18, 30, 50),  # 18-30å²ï¼Œ50äºº
        (31, 45, 50),  # 31-45å²ï¼Œ50äºº
        (46, 60, 50),  # 46-60å²ï¼Œ50äºº
        (61, 75, 50),  # 61-75å²ï¼Œ50äºº
    ]
    
    all_personas = []
    
    for min_age, max_age, n in age_groups:
        personas = generator.generate_from_distributions(
            distributions=[
                DistributionConfig("age", "uniform", {
                    'low': min_age,
                    'high': max_age,
                    'integer': True
                }),
            ],
            n_personas=n
        )
        all_personas.extend(personas)
    
    return all_personas

stratified_sample = generate_stratified_sample()
print(f"åˆ†å±‚æ ·æœ¬æ€»æ•°: {len(stratified_sample)}")
```

---

## 6. A/Bæµ‹è¯•è¿›é˜¶

### åŠŸèƒ½æ¦‚è¿°

`ABTestManager` æä¾›å®Œæ•´çš„éšæœºåˆ†é…ã€æ•ˆæœæ¯”è¾ƒå’Œç»Ÿè®¡æ£€éªŒåŠŸèƒ½ã€‚

### æ ¸å¿ƒç±»

**ä½ç½®**: `src/ab_testing.py`

```python
from src import ABTestManager, Condition, ABTestConfig
```

### 6.1 åŸºç¡€ A/B æµ‹è¯•

```python
from src import ABTestManager, Condition, Persona

# å®šä¹‰æµ‹è¯•æ¡ä»¶
condition_a = Condition(
    condition_id="control",
    condition_name="å¯¹ç…§ç»„ï¼ˆæ— å¹²é¢„ï¼‰",
    intervention_text="",
    allocation_weight=1.0
)

condition_b = Condition(
    condition_id="treatment",
    condition_name="å¹²é¢„ç»„ï¼ˆæ­£å¿µå†¥æƒ³ï¼‰",
    intervention_text="æ¯å¤©ç»ƒä¹ 10åˆ†é’Ÿæ­£å¿µå†¥æƒ³å¯ä»¥å¸®åŠ©å‡è½»å‹åŠ›...",
    allocation_weight=1.0
)

# åˆ›å»º AB æµ‹è¯•ç®¡ç†å™¨
ab_manager = ABTestManager(seed=42)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤

# åˆ†é…äººç‰©åˆ°æ¡ä»¶
assignments = ab_manager.assign_personas(
    personas=personas,
    conditions=[condition_a, condition_b]
)

print(f"å¯¹ç…§ç»„: {sum(1 for c in assignments.values() if c=='control')}")
print(f"å¹²é¢„ç»„: {sum(1 for c in assignments.values() if c=='treatment')}")
```

### 6.2 å¤šè‡‚æµ‹è¯•ï¼ˆA/B/C/Dï¼‰

```python
# æµ‹è¯•4ä¸ªä¸åŒçš„å¹²é¢„æ–¹æ¡ˆ
conditions = [
    Condition("control", "å¯¹ç…§ç»„", ""),
    Condition("mindfulness", "æ­£å¿µå†¥æƒ³", "ç»ƒä¹ æ­£å¿µå†¥æƒ³..."),
    Condition("exercise", "è¿åŠ¨", "æ¯å¤©è¿åŠ¨30åˆ†é’Ÿ..."),
    Condition("socializing", "ç¤¾äº¤", "å¤šä¸æœ‹å‹èšä¼š..."),
]

# è¿è¡Œå¤šè‡‚æµ‹è¯•
assignments = ab_manager.assign_personas(personas, conditions)

# æŒ‰æ¡ä»¶åˆ†ç»„è¿è¡Œæ¨¡æ‹Ÿ
from src import SimulationEngine

engine = SimulationEngine(llm_client=client)
results_by_condition = {}

for condition in conditions:
    # è·å–è¯¥æ¡ä»¶çš„äººç‰©
    condition_personas = [
        p for p in personas 
        if assignments[p.id] == condition.condition_id
    ]
    
    # è¿è¡Œæ¨¡æ‹Ÿï¼ˆåŒ…å«å¹²é¢„æ–‡æœ¬ï¼‰
    results = engine.run_intervention_simulation(
        personas=condition_personas,
        questions=questions,
        intervention_text=condition.intervention_text
    )
    
    results_by_condition[condition.condition_id] = results

# æ¯”è¾ƒç»“æœ
comparison = ab_manager.compare_conditions(results_by_condition)
print(comparison)
```

### 6.3 åˆ†å±‚éšæœºåŒ–

```python
# æŒ‰æ€§åˆ«åˆ†å±‚ï¼Œç¡®ä¿æ¯ç»„æ€§åˆ«æ¯”ä¾‹ç›¸åŒ
stratified_assignments = ab_manager.assign_personas(
    personas=personas,
    conditions=[condition_a, condition_b],
    stratify_by="gender"  # æŒ‰æ€§åˆ«åˆ†å±‚
)

# éªŒè¯åˆ†å±‚æ•ˆæœ
for condition_id in ["control", "treatment"]:
    condition_personas = [
        p for p in personas 
        if stratified_assignments[p.id] == condition_id
    ]
    females = sum(1 for p in condition_personas if p.demographics['gender']=='å¥³')
    print(f"{condition_id}: å¥³æ€§æ¯”ä¾‹ {females/len(condition_personas):.2%}")
```

### 6.4 ä¸ç­‰åˆ†é…æƒé‡

```python
# 2:1 åˆ†é…ï¼ˆå¹²é¢„ç»„2ä»½ï¼Œå¯¹ç…§ç»„1ä»½ï¼‰
condition_a.allocation_weight = 1.0
condition_b.allocation_weight = 2.0

assignments = ab_manager.assign_personas(
    personas=personas,
    conditions=[condition_a, condition_b]
)

# éªŒè¯åˆ†é…æ¯”ä¾‹
control_count = sum(1 for c in assignments.values() if c=='control')
treatment_count = sum(1 for c in assignments.values() if c=='treatment')
print(f"åˆ†é…æ¯”ä¾‹: {treatment_count}:{control_count} â‰ˆ 2:1")
```

### 6.5 ç»Ÿè®¡æ£€éªŒ

```python
# è¿è¡Œç»Ÿè®¡æ£€éªŒ
from scipy import stats
import pandas as pd

# å‡è®¾æˆ‘ä»¬æœ‰æ•°å€¼å‹ç»“æœï¼ˆå¦‚å‹åŠ›å¾—åˆ†ï¼‰
df = pd.DataFrame([
    {'persona_id': p.id, 'condition': assignments[p.id], 
     'stress_score': result['score']}
    for p, result in zip(personas, results)
])

# t æ£€éªŒ
control_scores = df[df['condition']=='control']['stress_score']
treatment_scores = df[df['condition']=='treatment']['stress_score']

t_stat, p_value = stats.ttest_ind(control_scores, treatment_scores)

print(f"tç»Ÿè®¡é‡: {t_stat:.3f}")
print(f"på€¼: {p_value:.4f}")
print(f"æ˜¾è‘—æ€§: {'æ˜¾è‘—' if p_value < 0.05 else 'ä¸æ˜¾è‘—'}")

# æ•ˆåº”é‡ï¼ˆCohen's dï¼‰
mean_diff = treatment_scores.mean() - control_scores.mean()
pooled_std = np.sqrt(
    (control_scores.std()**2 + treatment_scores.std()**2) / 2
)
cohens_d = mean_diff / pooled_std
print(f"Cohen's d: {cohens_d:.3f}")
```

### 6.6 å®Œæ•´ A/B æµ‹è¯•å·¥ä½œæµ

```python
from src import ABTestManager, ABTestConfig, SimulationEngine

# 1. å®šä¹‰æµ‹è¯•é…ç½®
config = ABTestConfig(
    test_name="meditation_stress_reduction",
    conditions=[
        Condition("control", "å¯¹ç…§ç»„", ""),
        Condition("treatment", "å†¥æƒ³å¹²é¢„", "æ¯å¤©ç»ƒä¹ 10åˆ†é’Ÿæ­£å¿µå†¥æƒ³...")
    ],
    questions=[
        "ä½ ç›®å‰çš„å‹åŠ›æ°´å¹³æ˜¯å¤šå°‘ï¼Ÿï¼ˆ1-10ï¼‰",
        "ä½ ç¡çœ è´¨é‡å¦‚ä½•ï¼Ÿï¼ˆ1-10ï¼‰"
    ],
    random_assignment=True,
    stratify_by="gender"
)

# 2. åˆå§‹åŒ–ç®¡ç†å™¨
ab_manager = ABTestManager(seed=42)

# 3. åˆ†é…äººç‰©
assignments = ab_manager.assign_personas(
    personas=personas,
    conditions=config.conditions,
    stratify_by=config.stratify_by
)

# 4. è¿è¡Œå®éªŒ
engine = SimulationEngine(llm_client=client)
results = ab_manager.run_ab_test(
    config=config,
    personas=personas,
    assignments=assignments,
    engine=engine
)

# 5. åˆ†æç»“æœ
analysis = ab_manager.analyze_results(results)

print(f"å¯¹ç…§ç»„å¹³å‡å‹åŠ›: {analysis['control']['mean_stress']:.2f}")
print(f"å¹²é¢„ç»„å¹³å‡å‹åŠ›: {analysis['treatment']['mean_stress']:.2f}")
print(f"å·®å¼‚: {analysis['difference']:.2f}")
print(f"på€¼: {analysis['p_value']:.4f}")
print(f"æ•ˆåº”é‡: {analysis['effect_size']:.3f}")

# 6. å¯¼å‡ºæŠ¥å‘Š
ab_manager.export_report(analysis, "ab_test_report.pdf")
```

---

## 7. ä¼šè¯ç®¡ç†ä¸ä¸´æ—¶äººç‰©

### åŠŸèƒ½æ¦‚è¿°

ç³»ç»Ÿæ”¯æŒä¸‰ç§äººç‰©å­˜å‚¨æ¨¡å¼ï¼Œé€‚åº”ä¸åŒä½¿ç”¨åœºæ™¯ã€‚

### 7.1 ä¸‰ç§äººç‰©ç±»å‹

```python
# 1. ç£ç›˜äººç‰©ï¼ˆæ°¸ä¹…ä¿å­˜ï¼‰
from src import PersonaManager

manager = PersonaManager()
persona = Persona(name="å¼ ä¸‰", age=30, gender="ç”·")
manager.save_persona(persona)  # ä¿å­˜åˆ° data/personas/

# 2. ä¼šè¯äººç‰©ï¼ˆæµè§ˆå™¨ä¼šè¯æœŸé—´æœ‰æ•ˆï¼‰
st.session_state.session_personas.append(persona)
# å…³é—­æµè§ˆå™¨åæ¶ˆå¤±

# 3. ç”Ÿæˆäººç‰©ï¼ˆä¸´æ—¶ç”Ÿæˆï¼Œæœªä¿å­˜ï¼‰
from src import PersonaGenerator
generator = PersonaGenerator()
temp_personas = generator.generate_from_distributions(...)
st.session_state.generated_personas = temp_personas
# å¯é€‰æ‹©æ€§ä¿å­˜åˆ°ç£ç›˜
```

### 7.2 æ‰¹é‡ä¸Šä¼ ä¸´æ—¶äººç‰©

åœ¨ Setup é¡µé¢ï¼š

1. ä¸Šä¼  CSV æ–‡ä»¶
2. äººç‰©è¢«åŠ è½½åˆ° `session_personas`
3. å¯ä»¥åœ¨å½“å‰ä¼šè¯ä¸­ä½¿ç”¨
4. å¯é€‰æ‹©ä¿å­˜åˆ°ç£ç›˜ï¼ˆæ°¸ä¹…åŒ–ï¼‰

### 7.3 äººç‰©ç”Ÿå‘½å‘¨æœŸç®¡ç†

```python
# è·å–æ‰€æœ‰å¯ç”¨äººç‰©
def get_all_personas():
    disk_personas = st.session_state.persona_manager.load_all_personas()
    session_personas = st.session_state.get('session_personas', [])
    generated_personas = st.session_state.get('generated_personas', [])
    
    return disk_personas + session_personas + generated_personas

# æ¸…ç†ä¸´æ—¶äººç‰©
def clear_temporary_personas():
    st.session_state.session_personas = []
    st.session_state.generated_personas = []
    st.success("å·²æ¸…é™¤æ‰€æœ‰ä¸´æ—¶äººç‰©")

# æ°¸ä¹…åŒ–ä¸´æ—¶äººç‰©
def save_temporary_personas_to_disk():
    temp_personas = (
        st.session_state.get('session_personas', []) + 
        st.session_state.get('generated_personas', [])
    )
    
    for persona in temp_personas:
        st.session_state.persona_manager.save_persona(persona)
    
    # æ¸…ç©ºä¸´æ—¶å­˜å‚¨
    clear_temporary_personas()
    
    st.success(f"å·²ä¿å­˜ {len(temp_personas)} ä¸ªäººç‰©åˆ°ç£ç›˜")
```

### 7.4 ä½¿ç”¨åœºæ™¯å»ºè®®

| äººç‰©ç±»å‹ | é€‚ç”¨åœºæ™¯ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|---------|---------|------|------|
| **ç£ç›˜äººç‰©** | é•¿æœŸé¡¹ç›®ã€é‡å¤ä½¿ç”¨ | æ°¸ä¹…ä¿å­˜ã€å¯å…±äº« | å ç”¨å­˜å‚¨ç©ºé—´ |
| **ä¼šè¯äººç‰©** | å¿«é€Ÿæµ‹è¯•ã€ä¸€æ¬¡æ€§ä»»åŠ¡ | æ— éœ€æ¸…ç† | å…³é—­æµè§ˆå™¨åä¸¢å¤± |
| **ç”Ÿæˆäººç‰©** | å¤§è§„æ¨¡æ¨¡æ‹Ÿã€å‚æ•°æ¢ç´¢ | å¿«é€Ÿç”Ÿæˆå¤§é‡æ ·æœ¬ | éœ€æ‰‹åŠ¨ä¿å­˜ |

**æœ€ä½³å®è·µ**:
- å¼€å‘/æµ‹è¯•é˜¶æ®µï¼šä½¿ç”¨ä¼šè¯äººç‰©æˆ–ç”Ÿæˆäººç‰©
- æ­£å¼ç ”ç©¶ï¼šå°†ç¡®å®šçš„äººç‰©ä¿å­˜åˆ°ç£ç›˜
- å¤§è§„æ¨¡æ¨¡æ‹Ÿï¼šç”Ÿæˆä¸´æ—¶äººç‰©ï¼Œä»…ä¿å­˜ç»“æœ
- å›¢é˜Ÿåä½œï¼šä½¿ç”¨ç£ç›˜äººç‰© + é¡¹ç›®å¯¼å‡ºåŠŸèƒ½

---

## æ€»ç»“

æœ¬æ–‡æ¡£æ¶µç›–äº†ä»¥ä¸‹é«˜çº§åŠŸèƒ½ï¼š

1. âœ… **é¡¹ç›®ç®¡ç†** - å¯¼å‡º/å¯¼å…¥å®Œæ•´é¡¹ç›®
2. âœ… **æ ·å¼ç³»ç»Ÿ** - ç»Ÿä¸€çš„UIè®¾è®¡ç³»ç»Ÿ
3. âœ… **è´¨é‡æ§åˆ¶** - å“åº”éªŒè¯ä¸ä¸€è‡´æ€§æ£€æŸ¥
4. âœ… **æ•æ„Ÿæ€§åˆ†æ** - è¯„ä¼°ç»“æœç¨³å¥æ€§
5. âœ… **äººç‰©ç”Ÿæˆ** - åŸºäºç»Ÿè®¡åˆ†å¸ƒçš„æ‰¹é‡ç”Ÿæˆ
6. âœ… **A/Bæµ‹è¯•** - å®Œæ•´çš„éšæœºå¯¹ç…§è¯•éªŒæµç¨‹
7. âœ… **ä¼šè¯ç®¡ç†** - çµæ´»çš„äººç‰©ç”Ÿå‘½å‘¨æœŸç®¡ç†

è¿™äº›åŠŸèƒ½åœ¨ä¸»æ–‡æ¡£ä¸­æåŠä½†ç¼ºä¹è¯¦ç»†ç¤ºä¾‹ï¼Œæœ¬æŒ‡å—æä¾›äº†å®Œæ•´çš„ä½¿ç”¨æ–¹æ³•å’Œæœ€ä½³å®è·µã€‚

---

**ç›¸å…³æ–‡æ¡£**:
- [README.md](README.md) - é¡¹ç›®æ¦‚è§ˆ
- [API_GUIDE.md](API_GUIDE.md) - APIå‚è€ƒ
- [ARCHITECTURE.md](ARCHITECTURE.md) - æ¶æ„è®¾è®¡
- [LONGITUDINAL_GUIDE.md](LONGITUDINAL_GUIDE.md) - çºµå‘ç ”ç©¶æŒ‡å—
