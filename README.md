# Auto Sim AI - LLM Survey Simulation System# Auto Sim AI - LLM Survey Simulation System# Auto Sim AI - LLM Survey Simulation System



<div align="center">



**English Version | [中文版](./README_zh.md)**<div align="center"><div align="right">



---



🔬 **AI-Powered Survey and Intervention Simulation System****English Version | [中文版](./README_zh.md)**[![English](https://img.shields.io/badge/docs-English-blue?style=flat-square)](./docs/en/README.md)



Simulate real survey research and intervention effects using LLM-driven virtual personas[![中文文档](https://img.shields.io/badge/文档-中文-red?style=flat-square)](./docs/zh/README.md)



[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)---

[![Streamlit](https://img.shields.io/badge/streamlit-1.32.0-FF4B4B.svg)](https://streamlit.io)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)</div>



📖 **[Complete English Documentation](./docs/en/README.md)**🔬 **AI-Powered Survey and Intervention Simulation System**



[Quick Start](#-quick-start) •<div align="center">

[Features](#-features) •

[API Reference](./docs/en/api/README.md) •Simulate real survey research and intervention effects using LLM-driven virtual personas

[Contributing](./docs/en/contributing/README.md)

**Language / 语言:** [English](#english) | [中文](#中文)

</div>

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

---

[![Streamlit](https://img.shields.io/badge/streamlit-1.32.0-FF4B4B.svg)](https://streamlit.io)---

## 📋 Table of Contents

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

- [Overview](#-overview)

- [Features](#-features)## English

- [Quick Start](#-quick-start)

- [User Guide](#-user-guide)📖 **[View Full English Documentation](./docs/en/README.md)**

- [Architecture](#-architecture)

- [Advanced Features](#-advanced-features)🔬 **AI-Powered Survey and Intervention Simulation System**

- [API Documentation](#-api-documentation)

- [FAQ](#-faq)[Quick Start](#quick-start) •

- [Contributing](#-contributing)

- [License](#-license)[Features](#features) •Simulate real survey research and intervention effects using LLM-driven virtual personas



---[API Reference](./docs/en/api/README.md) •



## 🎯 Overview[Contributing](./docs/en/contributing/README.md)[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)



**Auto Sim AI** is an innovative research tool that leverages Large Language Models (LLMs) to generate virtual personas that simulate real human responses to surveys and interventions.[![Streamlit](https://img.shields.io/badge/streamlit-1.32.0-FF4B4B.svg)](https://streamlit.io)



### Use Cases</div>[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)



- 🏥 **Health Intervention Research** - Test health messaging impact on different populations

- 📊 **Market Research** - Rapidly evaluate product/service user feedback

- 🎓 **Educational Research** - Assess teaching method effectiveness across learner types---📖 **[View Full English Documentation](./docs/en/README.md)**

- 💡 **Policy Analysis** - Predict policy impact on diverse populations

- 🧪 **A/B Testing** - Compare effectiveness of different approaches

- 📈 **Prototype Validation** - Rapidly iterate designs before real-world research

## 📋 Table of Contents[Quick Start](./docs/en/quickstart/README.md) •

### Key Advantages

[Features](#features-en) •

✅ **Fast Iteration** - Complete hundreds of survey simulations in minutes  

✅ **Cost-Effective** - No need to recruit real participants  - [Overview](#overview)[API Reference](./docs/en/api/README.md) •

✅ **Reproducible** - Precise variable control ensures repeatability  

✅ **Diverse** - Easily create personas with varied backgrounds, ages, cultures  - [Features](#features)[Contributing](./docs/en/contributing/README.md)

✅ **Deep Insights** - Obtain detailed qualitative and quantitative data  

✅ **Flexible Deployment** - Support for local and cloud API deployments- [Quick Start](#quick-start)



---- [User Guide](#user-guide)### Features (EN)



## 🚀 Features- [📚 Complete Documentation](./docs/en/README.md)



### Core Capabilities  - [Quick Start Guide](./docs/en/quickstart/README.md)- **Three Research Modes**: Survey Testing, Message Testing, A/B Testing



#### 1. Virtual Persona Management  - [API Documentation](./docs/en/api/README.md)- **Longitudinal Studies**: Multi-wave research with persona memory



- **Rich Attributes**: Age, gender, occupation, education, personality traits, values, etc.  - [Architecture Design](./docs/en/architecture/README.md)- **Async Processing**: High-performance parallel simulations

- **Batch Creation**: Auto-generate samples matching real population distributions

- **CSV Import/Export**: Bulk import personas from Excel or databases  - [Longitudinal Studies](./docs/en/longitudinal/README.md)- **Flexible LLM Support**: Local (LM Studio) or API (DeepSeek, OpenAI)

- **Demo Templates**: Built-in templates for common persona types, ready to use

  - [Contributing Guide](./docs/en/contributing/README.md)- **Web Interface**: User-friendly Streamlit UI

#### 2. Multiple Simulation Modes

- [FAQ](#faq)- **Complete Data Export**: CSV, JSON formats for statistical analysis

- **Survey Mode**: Run standardized questionnaires (PHQ-9, GAD-7, etc.)

- **Intervention Mode**: Test health messages, ad copy, etc. on different populations- [License](#license)

- **A/B Testing**: Test multiple versions simultaneously and compare effects

- **Longitudinal Studies**: Multi-wave research to track changes over time### Quick Start (EN)

- **Sensitivity Analysis**: Systematically test parameter impact on results

---

#### 3. LLM Integration

```bash

- **Local Deployment**: LM Studio (free, completely private)

- **Commercial APIs**:## 🎯 Overviewgit clone https://github.com/jason-jj-li/auto_sim_ai.git

  - DeepSeek (cost-effective, Chinese-optimized)

  - OpenAI (GPT-4, GPT-3.5)cd auto_sim_ai

  - Other OpenAI-compatible services

- **Flexible Switching**: Change models or providers anytime**Auto Sim AI** is an innovative research tool that leverages Large Language Models (LLMs) to generate virtual personas that simulate real human responses to surveys and interventions../setup.sh



#### 4. Advanced Analysisstreamlit run app.py



- **Auto-Scoring**: Built-in scoring for standardized scales### Use Cases```

- **Statistical Analysis**: Descriptive stats, correlation, group comparisons

- **Consistency Checks**: Validate response internal consistency and logic

- **Visualization**: Interactive charts, word clouds, distributions

- **Export Features**: CSV, JSON, Python/R analysis scripts- 🏥 **Health Intervention Research** - Test health messaging impact on different populations📘 **[Complete English Documentation →](./docs/en/README.md)**



#### 5. Performance Optimization- 📊 **Market Research** - Rapidly evaluate product/service user feedback



- **Parallel Execution**: Async processing for multiple persona responses- 🎓 **Educational Research** - Assess teaching method effectiveness across learner types---

- **Smart Caching**: Avoid redundant LLM calls, save time and cost

- **Resume Capability**: Pause and resume large-scale simulations- 💡 **Policy Analysis** - Predict policy impact on diverse populations

- **Progress Tracking**: Real-time progress and estimated completion time

- 🧪 **A/B Testing** - Compare effectiveness of different approaches## 中文

---

- 📈 **Prototype Validation** - Rapidly iterate designs before real-world research

## ⚡ Quick Start

🔬 **基于大语言模型的调查与干预模拟系统**

### System Requirements

### Key Advantages

- **Python**: 3.8 or higher

- **Memory**: 8GB+ recommended使用 AI 驱动的虚拟人物模拟真实的调查研究和干预效果

- **LLM Provider** (choose one):

  - LM Studio (local, free)✅ **Fast Iteration** - Complete hundreds of survey simulations in minutes  

  - DeepSeek/OpenAI API key

✅ **Cost-Effective** - No need to recruit real participants  📗 **[查看完整中文文档](./docs/zh/README.md)**

### Installation Steps

✅ **Reproducible** - Precise variable control ensures repeatability  

#### Step 1: Clone Repository

✅ **Diverse** - Easily create personas with varied backgrounds, ages, cultures  [快速开始](./docs/zh/quickstart/README.md) •

```bash

git clone https://github.com/jason-jj-li/auto_sim_ai.git✅ **Deep Insights** - Obtain detailed qualitative and quantitative data  [功能特性](#功能特性) •

cd auto_sim_ai

```✅ **Flexible Deployment** - Support for local and cloud API deployments[API 参考](./docs/zh/api/README.md) •



#### Step 2: Install Dependencies[贡献指南](./docs/zh/contributing/README.md)



**Option A: Automated Setup (Recommended)**---



```bash</div>

chmod +x setup.sh

./setup.sh## 🚀 Features

```

---

**Option B: Manual Installation**

### Core Capabilities

```bash

# Create virtual environment## 📋 目录

python -m venv venv

source venv/bin/activate  # Windows: venv\Scripts\activate#### 1️⃣ Virtual Persona Management



# Install dependencies- [项目简介](#项目简介)

pip install -r requirements.txt

```- **Rich Attributes**: Age, gender, occupation, education, personality traits, values, etc.- [功能特性](#功能特性)



#### Step 3: Configure LLM- **Batch Creation**: Auto-generate samples matching real population distributions- [快速开始](#快速开始)



**Option A: Local LM Studio (Recommended for Learning)**- **CSV Import/Export**: Bulk import personas from Excel or databases- [使用指南](#使用指南)



1. Download [LM Studio](https://lmstudio.ai/)- **Demo Templates**: Built-in templates for common persona types, ready to use- [📚 完整文档](./docs/README.md)

2. Download a model in LM Studio:

   - Recommended: `mistral-7b-instruct`, `llama-2-7b-chat`  - [快速开始指南](./docs/quickstart/README.md)

   - Minimum: 7B parameter model

3. Start local server:#### 2️⃣ Multiple Simulation Modes  - [API文档](./docs/api/README.md)

   - Click "Local Server" tab

   - Select model  - [架构设计](./docs/architecture/README.md)

   - Click "Start Server"

   - Confirm address is `http://localhost:1234`- **Survey Mode**: Run standardized questionnaires (PHQ-9, GAD-7, etc.)  - [纵向研究指南](./docs/longitudinal/README.md)



**Option B: Online API (Recommended for Production)**- **Intervention Mode**: Test health messages, ad copy, etc. on different populations  - [贡献指南](./docs/contributing/README.md)



```bash- **A/B Testing**: Test multiple versions simultaneously and compare effects- [常见问题](#常见问题)

# Copy environment template

cp env.example .env- **Longitudinal Studies**: Multi-wave research to track changes over time- [许可证](#许可证)



# Edit .env file and add your API key- **Sensitivity Analysis**: Systematically test parameter impact on results

# DEEPSEEK_API_KEY=your_api_key_here

# or---

# OPENAI_API_KEY=your_api_key_here

```#### 3️⃣ LLM Integration



#### Step 4: Launch Application## 🎯 项目简介



```bash- **Local Deployment**: LM Studio (free, completely private)

streamlit run app.py

```- **Commercial APIs**:**LLM Simulation Survey System** 是一个创新的研究工具，利用大语言模型（LLM）生成虚拟人物（Personas），模拟真实人群对调查问卷和干预措施的响应。



The app will automatically open in your browser at: `http://localhost:8501`  - DeepSeek (cost-effective, Chinese-optimized)



### First-Time User Guide  - OpenAI (GPT-4, GPT-3.5)### 适用场景



**1. Connect LLM (Home Page)**  - Other OpenAI-compatible services

   - Select your LLM provider

   - Test the connection- **Flexible Switching**: Change models or providers anytime- 🏥 **健康干预研究** - 测试健康信息对不同人群的影响

   - Wait for "System Ready" message

- 📊 **市场调研** - 快速评估产品或服务的用户反馈

**2. Create Virtual Personas (Setup Page)**

   - Click "Create Demo Personas" for quick start#### 4️⃣ Advanced Analysis- 🎓 **教育研究** - 评估教学方法对不同学习者的效果

   - Or manually create custom personas

   - Or upload CSV for bulk import- 💡 **政策分析** - 预测政策对多元群体的潜在影响



**3. Run Simulation (Simulation Page)**- **Auto-Scoring**: Built-in scoring for standardized scales- 🧪 **A/B 测试** - 比较不同方案的效果差异

   - Choose simulation type (Survey/Intervention/A/B Test)

   - Select personas to participate- **Statistical Analysis**: Descriptive stats, correlation, group comparisons- 📈 **原型验证** - 在真实调研前快速迭代设计

   - Choose questionnaire template or enter custom questions

   - Click "Run Simulation"- **Consistency Checks**: Validate response internal consistency and logic



**4. View Results (Results Page)**- **Visualization**: Interactive charts, word clouds, distributions### 核心优势

   - Browse response data

   - View statistical analysis- **Export Features**: CSV, JSON, Python/R analysis scripts

   - Export results for further analysis

✅ **快速迭代** - 几分钟内完成数百人的调查模拟  

---

#### 5️⃣ Performance Optimization✅ **成本低廉** - 无需招募真实参与者  

## 📖 User Guide

✅ **可重复性** - 精确控制变量，确保实验可重复  

### Persona Design Best Practices

- **Parallel Execution**: Async processing for multiple persona responses✅ **多样化** - 轻松创建不同背景、年龄、文化的虚拟人物  

#### Creating High-Quality Personas

- **Smart Caching**: Avoid redundant LLM calls, save time and cost✅ **深度洞察** - 获得详细的质性和量化数据  

**Good Example: Specific, detailed, realistic**

- **Resume Capability**: Pause and resume large-scale simulations✅ **灵活部署** - 支持本地运行和云端API

```python

{- **Progress Tracking**: Real-time progress and estimated completion time

    "name": "Sarah Chen",

    "age": 32,---

    "gender": "Female",

    "occupation": "Software Engineer at startup",---

    "education": "Bachelor's in Computer Science",

    "location": "San Francisco, CA",## 🚀 功能特性

    "background": "Works at a fast-growing tech company, often works overtime. Recently experiencing work stress and sleep quality decline. Likes to relieve stress through exercise but often too busy.",

    "personality_traits": ["Perfectionist", "Strong sense of responsibility", "Somewhat anxious"],## ⚡ Quick Start

    "values": ["Career development", "Work-life balance", "Family health"]

}### 核心功能

```

### System Requirements

**Bad Example: Vague, generic**

#### 1️⃣ 虚拟人物管理

```python

{- **Python**: 3.8 or higher- **丰富的人物属性**：年龄、性别、职业、教育背景、性格特征、价值观等

    "name": "John Doe",

    "age": 30,- **Memory**: 8GB+ recommended- **批量创建**：使用人口统计分布自动生成符合真实人口的虚拟样本

    "gender": "Male",

    "occupation": "Engineer",- **LLM Provider** (choose one):- **CSV 导入/导出**：支持从Excel或数据库批量导入人物

    "background": "Regular person",

    "personality_traits": ["Normal"],  - LM Studio (local, free)- **演示模板**：内置多种典型人物模板，即开即用

    "values": ["Happiness"]

}  - DeepSeek/OpenAI API key

```

#### 2️⃣ 多种模拟模式

#### Persona Diversity Guidelines

### Installation- **调查模式**：运行标准化问卷（PHQ-9、GAD-7 等）

Ensure your virtual sample reflects real population diversity:

- **干预模式**：测试健康信息、广告文案等对不同人群的影响

- **Age**: Cover different age groups (18-80 years)

- **Gender**: Male, female, non-binary#### 1. Clone Repository- **A/B 测试**：同时测试多个版本，比较效果差异

- **Occupation**: Different industries and position levels

- **Education**: High school to graduate degrees- **纵向研究**：模拟多波次调查，追踪变化趋势

- **Geography**: Urban, rural, different regions

- **Cultural Background**: Different ethnicities, religions, cultural traditions```bash- **敏感性分析**：系统性测试参数变化对结果的影响



### Questionnaire Design Tipsgit clone https://github.com/jason-jj-li/auto_sim_ai.git



#### Characteristics of Good Questionscd auto_sim_ai#### 3️⃣ LLM 集成



✅ **Clear and Specific**```- **本地部署**：LM Studio（免费，完全私密）



```- **商业API**：

Good: "In the past two weeks, how many days have you felt down or depressed?"

Bad: "How have you been feeling lately?"#### 2. Install Dependencies  - DeepSeek（高性价比，中文优化）

```

  - OpenAI（GPT-4、GPT-3.5）

✅ **Avoid Compound Questions**

```bash  - 其他 OpenAI 兼容服务

```

Good: "How many times per week do you exercise?" + "How long is each exercise session?"# Create virtual environment (recommended)- **灵活切换**：随时更换模型或提供商

Bad: "How often do you exercise, for how long, and at what intensity?"

```python -m venv venv



✅ **Use Standardized Scales**source venv/bin/activate  # Windows: venv\Scripts\activate#### 4️⃣ 高级分析



```- **自动评分**：内置标准化量表的自动评分系统

Never(0) - Sometimes(1) - Often(2) - Always(3)

```# Install dependencies- **统计分析**：描述统计、相关分析、组间比较



#### Built-in Templatespip install -r requirements.txt- **一致性检查**：验证响应的内部一致性和逻辑性



The system includes validated standardized scales:```- **可视化**：交互式图表、词云、分布图



- **PHQ-9**: Depression screening scale- **导出功能**：CSV、JSON、Python/R 分析脚本

- **GAD-7**: Anxiety screening scale  

- **PSS-10**: Perceived Stress ScaleOr use the setup script:

- More templates continuously being added...

#### 5️⃣ 性能优化

### Simulation Settings Optimization

```bash- **并行执行**：异步处理多个人物的响应

#### Temperature Parameter

chmod +x setup.sh- **智能缓存**：避免重复调用 LLM，节省时间和成本

Controls response randomness and creativity:

./setup.sh- **断点续传**：支持暂停和恢复大规模模拟

- **0.0 - 0.3**: High consistency, suitable for standardized responses

- **0.5 - 0.7**: Balanced mode, recommended for most surveys (default)```- **进度追踪**：实时显示模拟进度和预估完成时间

- **0.8 - 1.0**: More diverse, suitable for exploratory research



#### Max Tokens

#### 3. Configure LLM---

- **150-300**: Short answers (multiple choice, scale ratings)

- **300-500**: Medium length (short answer questions)

- **500-1000**: Detailed responses (open-ended questions, in-depth interviews)

**Option A: Local LM Studio (recommended for learning/development)**## ⚡ 快速开始

#### Parallel Settings



- **Small Scale** (<10 personas): Concurrency 2-3

- **Medium Scale** (10-50 personas): Concurrency 5-101. Download [LM Studio](https://lmstudio.ai/)### 系统要求

- **Large Scale** (50+ personas): Concurrency 10-15 (watch API rate limits)

2. Download a model in LM Studio:

---

   - Recommended: `mistral-7b-instruct`, `llama-2-7b-chat`- **Python**: 3.8 或更高版本

## 🏗️ Architecture

   - Minimum: 7B parameter model- **内存**: 建议 8GB 以上

For detailed architecture documentation, see **[Architecture Guide](./docs/en/architecture/README.md)**

3. Start local server:- **LLM 提供商**（任选其一）：

### Project Structure

   - Click "Local Server" tab  - LM Studio（本地运行，免费）

```

auto_sim_ai/   - Select model  - DeepSeek/OpenAI API 密钥

├── app.py                      # Streamlit main application

├── pages/                      # Multi-page application   - Click "Start Server"

│   ├── 1_Setup.py             # Persona management

│   ├── 2_Simulation.py        # Run simulations   - Confirm address is `http://localhost:1234`### 安装步骤

│   └── 3_Results.py           # View results

├── src/                        # Core modules

│   ├── llm_client.py          # LLM client (sync/async)

│   ├── persona.py             # Persona management**Option B: Online API (recommended for production)**#### 1. 克隆项目

│   ├── simulation.py          # Simulation engine

│   ├── storage.py             # Results storage

│   ├── cache.py               # Response caching

│   ├── scoring.py             # Auto-scoring```bash```bash

│   └── ...                    # Additional modules

├── tests/                      # Test suite# Copy environment templategit clone https://github.com/jason-jj-li/auto_sim_ai.git

├── data/                       # Data directory

│   ├── personas/              # Persona datacp env.example .envcd auto_sim_ai

│   ├── results/               # Simulation results

│   └── cache/                 # Cached responses```

└── docs/                       # Documentation

```# Edit .env file, add API key



### Core Modules# DEEPSEEK_API_KEY=your_api_key_here#### 2. 安装依赖



**LLM Client** (`llm_client.py`)# or

- Synchronous and asynchronous modes

- Compatible with OpenAI API format# OPENAI_API_KEY=your_api_key_here```bash

- Seamless switching between providers

```# 创建虚拟环境（推荐）

**Simulation Engine** (`simulation.py`)

- Sequential and parallel executionpython -m venv venv

- Automatic error retry and progress tracking

- Result aggregation#### 4. Launch Applicationsource venv/bin/activate  # Windows: venv\Scripts\activate



**Cache System** (`cache.py`)

- Content-hash based smart caching

- Significantly reduce API costs```bash# 安装依赖

- Import/export capability

streamlit run app.pypip install -r requirements.txt

**Scoring System** (`scoring.py`)

- Automated scoring for standardized scales``````

- Configurable custom rules

- Total and subscale calculations



---The app will automatically open in your browser: `http://localhost:8501`或使用安装脚本：



## 🔬 Advanced Features```bash



> 💡 **See [API Guide](./docs/en/api/README.md) for detailed documentation**### First-Time User Guidechmod +x setup.sh



### 1. A/B Testing./setup.sh



Compare different intervention versions:1. **Connect LLM** (Home Page)```



```python   - Select LLM provider

from src import ABTestManager, Condition

   - Test connection#### 3. 配置 LLM

# Define test conditions

condition_a = Condition(   - Wait for "System Ready" message

    name="Version A",

    intervention_text="Meditating 10 minutes daily can reduce stress.",**方式 A：本地 LM Studio（推荐用于学习和开发）**

    questions=["Would you try this method?"]

)2. **Create Virtual Personas** (Setup Page)



condition_b = Condition(   - Click "Create Demo Personas" for quick start1. 下载 [LM Studio](https://lmstudio.ai/)

    name="Version B", 

    intervention_text="Research shows daily 10-minute meditation reduces stress by 30%.",   - Or manually create custom personas2. 在 LM Studio 中下载模型：

    questions=["Would you try this method?"]

)   - Or upload CSV for bulk import   - 推荐：`mistral-7b-instruct`、`llama-2-7b-chat`



# Run A/B test   - 最低：7B 参数模型

ab_manager = ABTestManager()

results = ab_manager.run_test([condition_a, condition_b], personas)3. **Run Simulation** (Simulation Page)3. 启动本地服务器：

```

   - Choose simulation type (Survey/Intervention)   - 点击 "Local Server" 标签

### 2. Longitudinal Studies

   - Select personas to participate   - 选择模型

Multi-wave tracking with conversation memory:

   - Choose questionnaire template or enter custom questions   - 点击 "Start Server"

```python

from src import LongitudinalStudyEngine, WaveConfig, LongitudinalStudyConfig   - Click "Run Simulation"   - 确认地址为 `http://localhost:1234`



# Configure study waves

waves = [

    WaveConfig(4. **View Results** (Results Page)**方式 B：在线 API（推荐用于生产环境）**

        wave_number=1,

        wave_name="Baseline",   - Browse response data

        questions=["What is your current stress level? (1-10)"],

        days_from_baseline=0   - View statistical analysis```bash

    ),

    WaveConfig(   - Export results for further analysis# 复制环境变量模板

        wave_number=2,

        wave_name="1 Month Follow-up",cp env.example .env

        questions=["What is your stress level now? (1-10)"],

        days_from_baseline=30,---

        intervention_text="Practice 10 minutes of meditation daily"

    )# 编辑 .env 文件，添加 API 密钥

]

## 📖 User Guide# DEEPSEEK_API_KEY=your_api_key_here

# Run study

config = LongitudinalStudyConfig(# 或

    study_id="stress_study",

    study_name="Stress Intervention Study",### Persona Design Best Practices# OPENAI_API_KEY=your_api_key_here

    waves=waves

)```



engine = LongitudinalStudyEngine(llm_client)#### Creating High-Quality Personas

results = engine.run_study(personas, config)

```#### 4. 启动应用



See **[Longitudinal Study Guide](./docs/en/longitudinal/README.md)** for details.```python



### 3. Batch Persona Generation# Good Example: Specific, detailed, realistic```bash



Generate samples based on real demographic distributions:{streamlit run app.py



```python    "name": "Sarah Chen",```

from src import PersonaGenerator, DistributionConfig

    "age": 32,

# Configure distribution

config = DistributionConfig(    "gender": "Female",应用将在浏览器中自动打开：`http://localhost:8501`

    age_distribution={"18-30": 0.3, "31-50": 0.4, "51-70": 0.3},

    gender_distribution={"Male": 0.48, "Female": 0.52}    "occupation": "Software Engineer at startup",

)

    "education": "Bachelor's in Computer Science",### 首次使用指南

# Generate 100 personas

generator = PersonaGenerator()    "location": "San Francisco, CA",

personas = generator.generate_batch(

    count=100,    "background": "Works at a fast-growing tech company, often works overtime. Recently experiencing work stress and sleep quality decline. Likes to relieve stress through exercise but often too busy.",1. **连接 LLM**（首页）

    distribution_config=config,

    llm_client=client    "personality_traits": ["Perfectionist", "Strong sense of responsibility", "Somewhat anxious"],   - 选择 LLM 提供商

)

```    "values": ["Career development", "Work-life balance", "Family health"]   - 测试连接



### 4. Response Validation}   - 等待"系统就绪"提示



Check response quality and consistency:



```python# Bad Example: Vague, generic2. **创建虚拟人物**（Setup 页面）

from src import ResponseValidator, ConsistencyChecker

{   - 点击 "Create Demo Personas" 快速创建

validator = ResponseValidator()

checker = ConsistencyChecker()    "name": "John Doe",   - 或手动创建自定义人物



# Validate format    "age": 30,   - 或上传 CSV 批量导入

is_valid = validator.validate_response(response, question_type)

    "gender": "Male",

# Check consistency

metrics = checker.check_consistency(persona_responses)    "occupation": "Engineer",3. **运行模拟**（Simulation 页面）

print(f"Consistency score: {metrics.consistency_score}")

```    "background": "Regular person",   - 选择模拟类型（调查/干预）



---    "personality_traits": ["Normal"],   - 选择要参与的人物



## 📚 API Documentation    "values": ["Happiness"]   - 选择问卷模板或输入自定义问题



### PersonaManager}   - 点击 "Run Simulation"



```python```

from src import PersonaManager

4. **查看结果**（Results 页面）

manager = PersonaManager()

#### Persona Diversity   - 浏览响应数据

# Add persona

manager.add_persona(persona)   - 查看统计分析



# Get all personasEnsure virtual samples reflect real population diversity:   - 导出结果用于进一步分析

personas = manager.get_all_personas()



# Filter by criteria

young_adults = manager.filter_personas(- **Age**: Cover different age groups (18-80 years)---

    age_range=(18, 30),

    gender="Female"- **Gender**: Male, female, non-binary

)

- **Occupation**: Different industries and position levels## 📖 使用指南

# Save/load

manager.save_to_file("personas.json")- **Education**: High school to graduate degrees

manager.load_from_file("personas.json")

```- **Geography**: Urban, rural, different regions### 虚拟人物设计最佳实践



### SimulationEngine- **Cultural Background**: Different ethnicities, religions, cultural traditions



```python#### 创建高质量人物

from src import SimulationEngine

### Questionnaire Design Tips

engine = SimulationEngine(

    llm_client=client,```python

    cache=cache,

    checkpoint_manager=checkpoint_mgr#### Good Question Characteristics# 好的例子：具体、详细、真实

)

{

# Run survey

result = engine.run_survey(✅ **Clear and Specific**    "name": "李明",

    personas=personas,

    questions=questions,    "age": 32,

    temperature=0.7,

    max_tokens=300```    "gender": "男",

)

Good: In the past two weeks, how many days have you felt down or depressed?    "occupation": "初创公司软件工程师",

# Run intervention

result = engine.run_intervention(Bad: How have you been feeling lately?    "education": "本科计算机科学",

    personas=personas,

    intervention_text="Health intervention text",```    "location": "北京",

    questions=followup_questions

)    "background": "在一家快速成长的科技公司工作，经常加班。最近感到工作压力大，睡眠质量下降。喜欢通过运动缓解压力，但工作繁忙常常没时间。",

```

✅ **Avoid Compound Questions**    "personality_traits": ["完美主义", "责任心强", "有些焦虑"],

### ResultsStorage

    "values": ["职业发展", "工作生活平衡", "家庭健康"]

```python

from src import ResultsStorage```}



storage = ResultsStorage()Good: How many times per week do you exercise? How long is each exercise session?



# Save resultBad: How often do you exercise, for how long, and at what intensity?# 不好的例子：模糊、一般化

storage.save_result(simulation_result)

```{

# Load results

results = storage.load_all_results()    "name": "张三",



# Export to CSV✅ **Use Standardized Scales**    "age": 30,

storage.export_to_csv(result, "output.csv")

    "gender": "男",

# Export analysis script

storage.export_analysis_script(result, "analysis.py", language="python")```    "occupation": "工程师",

```

Never(0) - Sometimes(1) - Often(2) - Always(3)    "background": "普通人",

---

```    "personality_traits": ["正常"],

## ❓ FAQ

    "values": ["幸福"]

### How many LLM API calls are needed?

#### Use Built-in Templates}

Call count = Number of personas × Number of questions

```

Example:

- 10 personas × 9 questions = 90 callsThe system includes validated standardized scales:

- Caching significantly reduces repeat calls

#### 人物多样性

### How long does simulation take?

- **PHQ-9**: Depression screening scale

Depends on:

- **Local model**: ~5-15 seconds/response- **GAD-7**: Anxiety screening scale确保虚拟样本反映真实人口的多样性：

- **Online API**: ~1-3 seconds/response

- **Parallel execution**: Can reduce time by 50-80%- **PSS-10**: Perceived Stress Scale



### How reliable are the results?- More templates continuously being added...- **年龄**：覆盖不同年龄段（18-80岁）



LLM simulation is an exploratory research tool, suitable for:- **性别**：男、女、非二元性别



✅ Rapid prototyping  ### Simulation Settings Optimization- **职业**：不同行业和职位层级

✅ Hypothesis generation  

✅ Questionnaire pre-testing  - **教育**：从高中到研究生

❌ **Cannot** replace real human research

#### Temperature Parameter- **地域**：城市、农村、不同地区

### How to improve response quality?

- **文化背景**：不同种族、宗教、文化传统

1. Create detailed, realistic persona backgrounds

2. Use clear, specific questionsControls response randomness and creativity:

3. Choose appropriate temperature parameters

4. Use more powerful models (e.g., GPT-4)### 问卷设计技巧

5. Enable response validation and consistency checks

- **0.0 - 0.3**: High consistency, suitable for standardized responses

### What about costs?

- **0.5 - 0.7**: Balanced mode, recommended for most surveys (default)#### 好的问题特征

- **Local LM Studio**: Completely free (requires GPU)

- **DeepSeek API**: ~$0.0001/1k tokens (extremely low cost)- **0.8 - 1.0**: More diverse, suitable for exploratory research and creative testing

- **OpenAI GPT-3.5**: ~$0.002/1k tokens

- **OpenAI GPT-4**: ~$0.03/1k tokens✅ **清晰具体**



### Is my data secure?#### Max Tokens```



- **Local mode**: Data never leaves your machine好：在过去两周内，您有多少天感到情绪低落或沮丧？

- **API mode**: Follows each provider's privacy policy

- **Recommendation**: Use local mode for sensitive data- **150-300**: Short answers (multiple choice, scale ratings)差：您最近心情怎么样？



---- **300-500**: Medium length (short answer questions)```



## 🤝 Contributing- **500-1000**: Detailed responses (open-ended questions, in-depth interviews)



Contributions welcome! See [Contributing Guide](./docs/en/contributing/README.md) for details.✅ **避免复合问题**



### Development Setup#### Parallel Settings```



```bash好：您每周锻炼多少次？您每次锻炼多长时间？

# Install development dependencies

pip install -r requirements-dev.txt- **Small Scale** (<10 personas): Concurrency 2-3差：您多久锻炼一次，每次多长时间，什么强度？



# Run tests- **Medium Scale** (10-50 personas): Concurrency 5-10```

pytest

- **Large Scale** (50+ personas): Concurrency 10-15 (watch API rate limits)

# Code formatting

black src/ tests/✅ **使用标准化量表**

isort src/ tests/

---```

# Type checking

mypy src/从不(0) - 偶尔(1) - 经常(2) - 总是(3)

```

## 🏗️ Architecture```

### Report Issues



Found a bug or have a feature suggestion? Please [create an issue](https://github.com/jason-jj-li/auto_sim_ai/issues).

For detailed architecture documentation, see **[Architecture Guide](./docs/en/architecture/README.md)**#### 使用内置模板

---



## 📄 License

### Project Structure系统内置多个验证过的标准化量表：

This project is licensed under the MIT License. See [LICENSE](LICENSE) file for details.



---

```- **PHQ-9**：抑郁症筛查量表

## 🙏 Acknowledgments

auto_sim_ai/- **GAD-7**：焦虑症筛查量表

- [Streamlit](https://streamlit.io/) - Python web framework

- [LM Studio](https://lmstudio.ai/) - Local LLM runtime├── app.py                      # Streamlit main application- **PSS-10**：压力感知量表

- [OpenAI](https://openai.com/) - API standards

- [DeepSeek](https://www.deepseek.com/) - Cost-effective LLM service├── pages/                      # Multi-page application- 更多模板持续添加中...



---│   ├── 1_Setup.py             # Persona management page



## 📞 Contact│   ├── 2_Simulation.py        # Simulation execution page### 模拟设置优化



- **Maintainer**: Jason Li│   └── 3_Results.py           # Results analysis page

- **GitHub**: [@jason-jj-li](https://github.com/jason-jj-li)

- **Email**: Contact via GitHub Issues├── src/                        # Core modules#### 温度参数（Temperature）



---│   ├── llm_client.py          # LLM client (sync/async)



<div align="center">│   ├── persona.py             # Persona management控制响应的随机性和创造性：



**⭐ If this project helps you, please give it a star!**│   ├── simulation.py          # Simulation engine (single/parallel)



Made with ❤️ by Jason Li│   ├── storage.py             # Results storage- **0.0 - 0.3**：高度一致，适合需要标准化响应的场景



</div>│   ├── cache.py               # Response cache- **0.5 - 0.7**：平衡模式，推荐用于大多数调查（默认）


│   ├── checkpoint.py          # Checkpoint management- **0.8 - 1.0**：更多样化，适合探索性研究和创意测试

│   ├── scoring.py             # Auto-scoring

│   ├── ab_testing.py          # A/B testing#### 最大令牌数（Max Tokens）

│   ├── intervention_study.py  # Intervention studies (legacy)

│   ├── persona_generator.py   # Persona generator- **150-300**：简短答案（选择题、量表评分）

│   ├── survey_templates.py    # Survey template library- **300-500**：中等长度（简答题）

│   ├── survey_config.py       # Survey configuration- **500-1000**：详细回答（开放式问题、深度访谈）

│   ├── tools.py               # Tool registration system

│   ├── ui_components.py       # UI components#### 并行设置

│   ├── styles.py              # Design system

│   └── validators.py          # Input validation- **小规模**（<10人）：并发数 2-3

├── tests/                      # Test suite- **中等规模**（10-50人）：并发数 5-10

├── data/                       # Data directory- **大规模**（50+人）：并发数 10-15（注意API速率限制）

│   ├── personas/              # Persona data

│   ├── results/               # Simulation results---

│   ├── cache/                 # Cache data

│   ├── checkpoints/           # Checkpoints## 🏗️ 架构设计

│   └── survey_configs/        # Survey configurations

├── docs/                       # Documentation详细的架构文档请查看 **[Architecture Guide](./docs/architecture/README.md)**

├── requirements.txt            # Dependencies

└── pytest.ini                 # Test configuration### 项目结构

```

```

### Core Module Overviewauto_sim_ai/

├── app.py                      # Streamlit 主应用

#### LLM Client (`llm_client.py`)├── pages/                      # 多页面应用

│   ├── 1_Setup.py             # 人物管理页面

Supports both synchronous and asynchronous modes:│   ├── 2_Simulation.py        # 模拟运行页面

│   └── 3_Results.py           # 结果分析页面

- **LMStudioClient**: Sync client, suitable for simple scenarios├── src/                        # 核心模块

- **AsyncLLMClient**: Async client, supports high concurrency│   ├── llm_client.py          # LLM 客户端（同步/异步）

│   ├── persona.py             # 人物管理

Compatible with OpenAI API format, seamless switching between providers.│   ├── simulation.py          # 模拟引擎（单线程/并行）

│   ├── storage.py             # 结果存储

#### Simulation Engine (`simulation.py`)│   ├── cache.py               # 响应缓存

│   ├── checkpoint.py          # 断点管理

- **SimulationEngine**: Base engine, sequential execution│   ├── scoring.py             # 自动评分

- **ParallelSimulationEngine**: Parallel engine, supports async batch processing│   ├── ab_testing.py          # A/B测试

│   ├── intervention_study.py  # 干预研究（旧版）

Automatically handles error retry, progress tracking, result aggregation.│   ├── longitudinal_study.py  # 纵向研究（新版，推荐）

│   ├── persona_generator.py   # 人物生成器

#### Cache System (`cache.py`)│   ├── survey_templates.py    # 问卷模板库

│   ├── survey_config.py       # 问卷配置

Content-hash based smart caching:│   ├── tools.py               # 工具注册系统

│   ├── ui_components.py       # UI 组件

- Same persona + same question = directly return cached result│   ├── styles.py              # 设计系统

- Support cache export and import│   └── validators.py          # 输入验证

- Significantly reduce LLM API call costs├── tests/                      # 测试套件

├── data/                       # 数据目录

#### Scoring System (`scoring.py`)│   ├── personas/              # 人物数据

│   ├── results/               # 模拟结果

Automated scoring features:│   ├── cache/                 # 缓存数据

│   ├── checkpoints/           # 检查点

- Support for multiple standardized scales│   └── survey_configs/        # 问卷配置

- Configurable custom scoring rules├── docs/                       # 文档

- Auto-calculate total and subscale scores├── requirements.txt            # 依赖列表

└── pytest.ini                 # 测试配置

---```



## 🔬 Advanced Features### 核心模块说明



> 💡 **Tip**: For detailed API documentation and advanced features, see [API Guide](./docs/en/api/README.md)#### LLM 客户端 (`llm_client.py`)



### 1. A/B Testing支持同步和异步两种模式：



Compare intervention effects across versions:- **LMStudioClient**：同步客户端，适合简单场景

- **AsyncLLMClient**：异步客户端，支持高并发

```python

from src import ABTestManager, Condition兼容 OpenAI API 格式，可无缝切换不同提供商。



# Define test conditions#### 模拟引擎 (`simulation.py`)

condition_a = Condition(

    name="Version A",- **SimulationEngine**：基础引擎，顺序执行

    intervention_text="Meditating 10 minutes daily can reduce stress.",- **ParallelSimulationEngine**：并行引擎，支持异步批处理

    questions=["Would you try this method?"]

)自动处理错误重试、进度追踪、结果聚合。



condition_b = Condition(#### 缓存系统 (`cache.py`)

    name="Version B", 

    intervention_text="Research shows daily 10-minute meditation reduces stress levels by 30%.",基于内容哈希的智能缓存：

    questions=["Would you try this method?"]- 相同人物 + 相同问题 = 直接返回缓存结果

)- 支持缓存导出和导入

- 显著降低 LLM API 调用成本

# Run A/B test

ab_manager = ABTestManager()#### 评分系统 (`scoring.py`)

results = ab_manager.run_test([condition_a, condition_b], personas)

```自动化评分功能：

- 支持多种标准化量表

### 2. Longitudinal Studies (Multi-Wave Tracking)- 可配置自定义评分规则

- 自动计算总分和子量表分数

Implement realistic longitudinal tracking with conversation memory:

---

```python

from src import LongitudinalStudyEngine, WaveConfig, LongitudinalStudyConfig## 🔬 高级功能



# Configure study waves> 💡 **提示**: 详细的API文档和高级功能请查看 [API Guide](./docs/api/README.md)

waves = [

    WaveConfig(### 1. A/B 测试

        wave_number=1,

        wave_name="Baseline",比较不同版本的干预效果：

        questions=["What is your current stress level? (1-10)"],

        days_from_baseline=0```python

    ),from src import ABTestManager, Condition

    WaveConfig(

        wave_number=2,# 定义测试条件

        wave_name="1 Month Follow-up",condition_a = Condition(

        questions=["What is your stress level now? (1-10)"],    name="版本A",

        days_from_baseline=30,    intervention_text="每天冥想10分钟可以降低压力。",

        intervention_text="Practice 10 minutes of meditation daily"    questions=["您会尝试这个方法吗？"]

    ))

]

condition_b = Condition(

# Run longitudinal study    name="版本B", 

config = LongitudinalStudyConfig(    intervention_text="研究表明，每天冥想10分钟可以降低30%的压力水平。",

    study_id="stress_study",    questions=["您会尝试这个方法吗？"]

    study_name="Stress Intervention Study",)

    waves=waves

)# 运行A/B测试

ab_manager = ABTestManager()

engine = LongitudinalStudyEngine(llm_client)results = ab_manager.run_test([condition_a, condition_b], personas)

results = engine.run_study(personas, config)```

```

### 2. 纵向研究（多波次追踪）

For detailed longitudinal study guide, see **[Longitudinal Study Guide](./docs/en/longitudinal/README.md)**

使用对话记忆实现真实的纵向追踪：

### 3. Batch Persona Generation

```python

Generate virtual samples based on real demographic distributions:from src import LongitudinalStudyEngine, WaveConfig, LongitudinalStudyConfig



```python# 配置研究波次

from src import PersonaGenerator, DistributionConfigwaves = [

    WaveConfig(

# Configure distribution        wave_number=1,

config = DistributionConfig(        wave_name="基线",

    age_distribution={        questions=["您目前的压力水平如何？(1-10)"],

        "18-30": 0.3,        days_from_baseline=0

        "31-50": 0.4,    ),

        "51-70": 0.3    WaveConfig(

    },        wave_number=2,

    gender_distribution={        wave_name="1个月后",

        "Male": 0.48,        questions=["您现在的压力水平如何？(1-10)"],

        "Female": 0.52        days_from_baseline=30,

    }        intervention_text="每天练习10分钟冥想"

)    )

]

# Generate 100 personas

generator = PersonaGenerator()# 运行纵向研究

personas = generator.generate_batch(config = LongitudinalStudyConfig(

    count=100,    study_id="stress_study",

    distribution_config=config,    study_name="压力干预研究",

    llm_client=client    waves=waves

))

```

engine = LongitudinalStudyEngine(llm_client)

### 4. Response Validationresults = engine.run_study(personas, config)

```

Automatically check response quality and consistency:

详细的纵向研究指南请查看 **[Longitudinal Study Guide](./docs/longitudinal/README.md)**

```python

from src import ResponseValidator, ConsistencyChecker### 3. 批量人物生成



validator = ResponseValidator()基于真实人口统计分布生成虚拟样本：

checker = ConsistencyChecker()

```python

# Validate response formatfrom src import PersonaGenerator, DistributionConfig

is_valid = validator.validate_response(response, question_type)

# 配置分布

# Check consistencyconfig = DistributionConfig(

metrics = checker.check_consistency(persona_responses)    age_distribution={

print(f"Consistency score: {metrics.consistency_score}")        "18-30": 0.3,

```        "31-50": 0.4,

        "51-70": 0.3

---    },

    gender_distribution={

## 📚 API Documentation        "男": 0.48,

        "女": 0.52

### PersonaManager    }

)

```python

from src import PersonaManager# 生成100个人物

generator = PersonaGenerator()

manager = PersonaManager()personas = generator.generate_batch(

    count=100,

# Add persona    distribution_config=config,

manager.add_persona(persona)    llm_client=client

)

# Get all personas```

personas = manager.get_all_personas()

### 5. 响应验证

# Filter by criteria

young_adults = manager.filter_personas(自动检查响应质量和一致性：

    age_range=(18, 30),

    gender="Female"```python

)from src import ResponseValidator, ConsistencyChecker



# Save/loadvalidator = ResponseValidator()

manager.save_to_file("personas.json")checker = ConsistencyChecker()

manager.load_from_file("personas.json")

```# 验证响应格式

is_valid = validator.validate_response(response, question_type)

### SimulationEngine

# 检查一致性

```pythonmetrics = checker.check_consistency(persona_responses)

from src import SimulationEngineprint(f"一致性得分: {metrics.consistency_score}")

```

engine = SimulationEngine(

    llm_client=client,---

    cache=cache,

    checkpoint_manager=checkpoint_mgr## 📚 API 文档

)

### PersonaManager

# Run survey

result = engine.run_survey(```python

    personas=personas,from src import PersonaManager

    questions=questions,

    temperature=0.7,manager = PersonaManager()

    max_tokens=300

)# 添加人物

manager.add_persona(persona)

# Run intervention

result = engine.run_intervention(# 获取所有人物

    personas=personas,personas = manager.get_all_personas()

    intervention_text="Health intervention text",

    questions=followup_questions# 按条件筛选

)young_adults = manager.filter_personas(

```    age_range=(18, 30),

    gender="女"

### ResultsStorage)



```python# 保存/加载

from src import ResultsStoragemanager.save_to_file("personas.json")

manager.load_from_file("personas.json")

storage = ResultsStorage()```



# Save result### SimulationEngine

storage.save_result(simulation_result)

```python

# Load resultsfrom src import SimulationEngine

results = storage.load_all_results()

engine = SimulationEngine(

# Export to CSV    llm_client=client,

storage.export_to_csv(result, "output.csv")    cache=cache,

    checkpoint_manager=checkpoint_mgr

# Export analysis script)

storage.export_analysis_script(result, "analysis.py", language="python")

```# 运行调查

result = engine.run_survey(

---    personas=personas,

    questions=questions,

## ❓ FAQ    temperature=0.7,

    max_tokens=300

### Q: How many LLM API calls are needed?)



A: Call count = Number of personas × Number of questions. For example:# 运行干预

result = engine.run_intervention(

- 10 personas × 9 questions = 90 calls    personas=personas,

- Caching can significantly reduce repeat calls    intervention_text="健康干预文本",

    questions=followup_questions

### Q: How long does simulation take?)

```

A: Depends on:

### ResultsStorage

- **Local model**: ~5-15 seconds/response

- **Online API**: ~1-3 seconds/response```python

- **Parallel execution**: Can reduce time by 50-80%from src import ResultsStorage



### Q: How reliable are the results?storage = ResultsStorage()



A: LLM simulation is an exploratory research tool, suitable for:# 保存结果

storage.save_result(simulation_result)

- ✅ Rapid prototyping

- ✅ Hypothesis generation# 加载结果

- ✅ Questionnaire pre-testingresults = storage.load_all_results()

- ❌ **Cannot** replace real human research

# 导出为CSV

### Q: How to improve response quality?storage.export_to_csv(result, "output.csv")



1. Create detailed, realistic persona backgrounds# 导出分析脚本

2. Use clear, specific questionsstorage.export_analysis_script(result, "analysis.py", language="python")

3. Choose appropriate temperature parameters```

4. Use more powerful models (e.g., GPT-4)

5. Enable response validation and consistency checks---



### Q: What about costs?## ❓ 常见问题



- **Local LM Studio**: Completely free (requires GPU)### Q: 需要多少 LLM API 调用？

- **DeepSeek API**: ~$0.0001/1k tokens, extremely low cost

- **OpenAI GPT-3.5**: ~$0.002/1k tokensA: 调用次数 = 人物数量 × 问题数量。例如：

- **OpenAI GPT-4**: ~$0.03/1k tokens- 10个人物 × 9个问题 = 90次调用

- 使用缓存可大幅减少重复调用

### Q: Is my data secure?

### Q: 模拟需要多长时间？

- Local mode: Data never leaves your machine

- API mode: Follows each provider's privacy policyA: 取决于：

- Recommendation: Use local mode for sensitive data- **本地模型**：约 5-15 秒/响应

- **在线API**：约 1-3 秒/响应

---- **并行执行**：可缩短 50-80% 时间



## 🤝 Contributing### Q: 结果的可靠性如何？



Contributions welcome! See [CONTRIBUTING.md](./docs/en/contributing/README.md) for details.A: LLM模拟是探索性研究工具，适合：

- ✅ 快速原型测试

### Development Setup- ✅ 假设生成

- ✅ 问卷预测试

```bash- ❌ **不能**替代真实人类研究

# Install development dependencies

pip install -r requirements-dev.txt### Q: 如何提高响应质量？



# Run tests1. 创建详细、真实的人物背景

pytest2. 使用清晰、具体的问题

3. 选择合适的温度参数

# Code formatting4. 使用更强大的模型（如 GPT-4）

black src/ tests/5. 启用响应验证和一致性检查

isort src/ tests/

### Q: 成本如何？

# Type checking

mypy src/- **本地LM Studio**：完全免费（需要GPU）

```- **DeepSeek API**：~0.001元/千token，极低成本

- **OpenAI GPT-3.5**：~0.015元/千token

### Report Issues- **OpenAI GPT-4**：~0.3元/千token



Found a bug or have a feature suggestion? Please [create an issue](https://github.com/jason-jj-li/auto_sim_ai/issues).### Q: 数据安全吗？



---- 本地模式：数据完全不出本地

- API模式：遵循各提供商的隐私政策

## 📄 License- 建议：敏感数据使用本地模式



This project is licensed under the MIT License. See [LICENSE](LICENSE) file for details.---



---## 🤝 贡献



## 🙏 Acknowledgments欢迎贡献！请查看 [CONTRIBUTING.md](CONTRIBUTING.md) 了解详情。



- [Streamlit](https://streamlit.io/) - Excellent Python web framework### 开发设置

- [LM Studio](https://lmstudio.ai/) - Local LLM runtime environment

- [OpenAI](https://openai.com/) - API standards```bash

- [DeepSeek](https://www.deepseek.com/) - Cost-effective LLM service# 安装开发依赖

pip install -r requirements-dev.txt

---

# 运行测试

## 📞 Contactpytest



- **Maintainer**: Jason Li# 代码格式化

- **GitHub**: [@jason-jj-li](https://github.com/jason-jj-li)black src/ tests/

- **Email**: [Contact via GitHub Issues]isort src/ tests/



---# 类型检查

mypy src/

<div align="center">```



**⭐ If this project helps you, please give it a star!**### 报告问题



Made with ❤️ by Jason Li发现 Bug 或有功能建议？请[创建 Issue](https://github.com/jason-jj-li/auto_sim_ai/issues)。



</div>---


## 📄 许可证

本项目采用 MIT 许可证。详见 [LICENSE](LICENSE) 文件。

---

## 🙏 致谢

- [Streamlit](https://streamlit.io/) - 优秀的Python Web框架
- [LM Studio](https://lmstudio.ai/) - 本地LLM运行环境
- [OpenAI](https://openai.com/) - API标准
- [DeepSeek](https://www.deepseek.com/) - 高性价比LLM服务

---

## 📞 联系方式

- **维护者**: Jason Li
- **GitHub**: [@jason-jj-li](https://github.com/jason-jj-li)
- **Email**: [通过GitHub Issues联系]

---

<div align="center">

**⭐ 如果这个项目对您有帮助，请给一个星标！**

Made with ❤️ by Jason Li

</div>
