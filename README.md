# Auto Sim AI - LLM Survey Simulation System# Auto Sim AI - LLM Survey Simulation System# Auto Sim AI - LLM Survey Simulation System



<div align="center">



**English Version | [ä¸­æ–‡ç‰ˆ](./README_zh.md)**<div align="center"><div align="right">



---



ğŸ”¬ **AI-Powered Survey and Intervention Simulation System****English Version | [ä¸­æ–‡ç‰ˆ](./README_zh.md)**[![English](https://img.shields.io/badge/docs-English-blue?style=flat-square)](./docs/en/README.md)



Simulate real survey research and intervention effects using LLM-driven virtual personas[![ä¸­æ–‡æ–‡æ¡£](https://img.shields.io/badge/æ–‡æ¡£-ä¸­æ–‡-red?style=flat-square)](./docs/zh/README.md)



[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)---

[![Streamlit](https://img.shields.io/badge/streamlit-1.32.0-FF4B4B.svg)](https://streamlit.io)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)</div>



ğŸ“– **[Complete English Documentation](./docs/en/README.md)**ğŸ”¬ **AI-Powered Survey and Intervention Simulation System**



[Quick Start](#-quick-start) â€¢<div align="center">

[Features](#-features) â€¢

[API Reference](./docs/en/api/README.md) â€¢Simulate real survey research and intervention effects using LLM-driven virtual personas

[Contributing](./docs/en/contributing/README.md)

**Language / è¯­è¨€:** [English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

</div>

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

---

[![Streamlit](https://img.shields.io/badge/streamlit-1.32.0-FF4B4B.svg)](https://streamlit.io)---

## ğŸ“‹ Table of Contents

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

- [Overview](#-overview)

- [Features](#-features)## English

- [Quick Start](#-quick-start)

- [User Guide](#-user-guide)ğŸ“– **[View Full English Documentation](./docs/en/README.md)**

- [Architecture](#-architecture)

- [Advanced Features](#-advanced-features)ğŸ”¬ **AI-Powered Survey and Intervention Simulation System**

- [API Documentation](#-api-documentation)

- [FAQ](#-faq)[Quick Start](#quick-start) â€¢

- [Contributing](#-contributing)

- [License](#-license)[Features](#features) â€¢Simulate real survey research and intervention effects using LLM-driven virtual personas



---[API Reference](./docs/en/api/README.md) â€¢



## ğŸ¯ Overview[Contributing](./docs/en/contributing/README.md)[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)



**Auto Sim AI** is an innovative research tool that leverages Large Language Models (LLMs) to generate virtual personas that simulate real human responses to surveys and interventions.[![Streamlit](https://img.shields.io/badge/streamlit-1.32.0-FF4B4B.svg)](https://streamlit.io)



### Use Cases</div>[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)



- ğŸ¥ **Health Intervention Research** - Test health messaging impact on different populations

- ğŸ“Š **Market Research** - Rapidly evaluate product/service user feedback

- ğŸ“ **Educational Research** - Assess teaching method effectiveness across learner types---ğŸ“– **[View Full English Documentation](./docs/en/README.md)**

- ğŸ’¡ **Policy Analysis** - Predict policy impact on diverse populations

- ğŸ§ª **A/B Testing** - Compare effectiveness of different approaches

- ğŸ“ˆ **Prototype Validation** - Rapidly iterate designs before real-world research

## ğŸ“‹ Table of Contents[Quick Start](./docs/en/quickstart/README.md) â€¢

### Key Advantages

[Features](#features-en) â€¢

âœ… **Fast Iteration** - Complete hundreds of survey simulations in minutes  

âœ… **Cost-Effective** - No need to recruit real participants  - [Overview](#overview)[API Reference](./docs/en/api/README.md) â€¢

âœ… **Reproducible** - Precise variable control ensures repeatability  

âœ… **Diverse** - Easily create personas with varied backgrounds, ages, cultures  - [Features](#features)[Contributing](./docs/en/contributing/README.md)

âœ… **Deep Insights** - Obtain detailed qualitative and quantitative data  

âœ… **Flexible Deployment** - Support for local and cloud API deployments- [Quick Start](#quick-start)



---- [User Guide](#user-guide)### Features (EN)



## ğŸš€ Features- [ğŸ“š Complete Documentation](./docs/en/README.md)



### Core Capabilities  - [Quick Start Guide](./docs/en/quickstart/README.md)- **Three Research Modes**: Survey Testing, Message Testing, A/B Testing



#### 1. Virtual Persona Management  - [API Documentation](./docs/en/api/README.md)- **Longitudinal Studies**: Multi-wave research with persona memory



- **Rich Attributes**: Age, gender, occupation, education, personality traits, values, etc.  - [Architecture Design](./docs/en/architecture/README.md)- **Async Processing**: High-performance parallel simulations

- **Batch Creation**: Auto-generate samples matching real population distributions

- **CSV Import/Export**: Bulk import personas from Excel or databases  - [Longitudinal Studies](./docs/en/longitudinal/README.md)- **Flexible LLM Support**: Local (LM Studio) or API (DeepSeek, OpenAI)

- **Demo Templates**: Built-in templates for common persona types, ready to use

  - [Contributing Guide](./docs/en/contributing/README.md)- **Web Interface**: User-friendly Streamlit UI

#### 2. Multiple Simulation Modes

- [FAQ](#faq)- **Complete Data Export**: CSV, JSON formats for statistical analysis

- **Survey Mode**: Run standardized questionnaires (PHQ-9, GAD-7, etc.)

- **Intervention Mode**: Test health messages, ad copy, etc. on different populations- [License](#license)

- **A/B Testing**: Test multiple versions simultaneously and compare effects

- **Longitudinal Studies**: Multi-wave research to track changes over time### Quick Start (EN)

- **Sensitivity Analysis**: Systematically test parameter impact on results

---

#### 3. LLM Integration

```bash

- **Local Deployment**: LM Studio (free, completely private)

- **Commercial APIs**:## ğŸ¯ Overviewgit clone https://github.com/jason-jj-li/auto_sim_ai.git

  - DeepSeek (cost-effective, Chinese-optimized)

  - OpenAI (GPT-4, GPT-3.5)cd auto_sim_ai

  - Other OpenAI-compatible services

- **Flexible Switching**: Change models or providers anytime**Auto Sim AI** is an innovative research tool that leverages Large Language Models (LLMs) to generate virtual personas that simulate real human responses to surveys and interventions../setup.sh



#### 4. Advanced Analysisstreamlit run app.py



- **Auto-Scoring**: Built-in scoring for standardized scales### Use Cases```

- **Statistical Analysis**: Descriptive stats, correlation, group comparisons

- **Consistency Checks**: Validate response internal consistency and logic

- **Visualization**: Interactive charts, word clouds, distributions

- **Export Features**: CSV, JSON, Python/R analysis scripts- ğŸ¥ **Health Intervention Research** - Test health messaging impact on different populationsğŸ“˜ **[Complete English Documentation â†’](./docs/en/README.md)**



#### 5. Performance Optimization- ğŸ“Š **Market Research** - Rapidly evaluate product/service user feedback



- **Parallel Execution**: Async processing for multiple persona responses- ğŸ“ **Educational Research** - Assess teaching method effectiveness across learner types---

- **Smart Caching**: Avoid redundant LLM calls, save time and cost

- **Resume Capability**: Pause and resume large-scale simulations- ğŸ’¡ **Policy Analysis** - Predict policy impact on diverse populations

- **Progress Tracking**: Real-time progress and estimated completion time

- ğŸ§ª **A/B Testing** - Compare effectiveness of different approaches## ä¸­æ–‡

---

- ğŸ“ˆ **Prototype Validation** - Rapidly iterate designs before real-world research

## âš¡ Quick Start

ğŸ”¬ **åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è°ƒæŸ¥ä¸å¹²é¢„æ¨¡æ‹Ÿç³»ç»Ÿ**

### System Requirements

### Key Advantages

- **Python**: 3.8 or higher

- **Memory**: 8GB+ recommendedä½¿ç”¨ AI é©±åŠ¨çš„è™šæ‹Ÿäººç‰©æ¨¡æ‹ŸçœŸå®çš„è°ƒæŸ¥ç ”ç©¶å’Œå¹²é¢„æ•ˆæœ

- **LLM Provider** (choose one):

  - LM Studio (local, free)âœ… **Fast Iteration** - Complete hundreds of survey simulations in minutes  

  - DeepSeek/OpenAI API key

âœ… **Cost-Effective** - No need to recruit real participants  ğŸ“— **[æŸ¥çœ‹å®Œæ•´ä¸­æ–‡æ–‡æ¡£](./docs/zh/README.md)**

### Installation Steps

âœ… **Reproducible** - Precise variable control ensures repeatability  

#### Step 1: Clone Repository

âœ… **Diverse** - Easily create personas with varied backgrounds, ages, cultures  [å¿«é€Ÿå¼€å§‹](./docs/zh/quickstart/README.md) â€¢

```bash

git clone https://github.com/jason-jj-li/auto_sim_ai.gitâœ… **Deep Insights** - Obtain detailed qualitative and quantitative data  [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§) â€¢

cd auto_sim_ai

```âœ… **Flexible Deployment** - Support for local and cloud API deployments[API å‚è€ƒ](./docs/zh/api/README.md) â€¢



#### Step 2: Install Dependencies[è´¡çŒ®æŒ‡å—](./docs/zh/contributing/README.md)



**Option A: Automated Setup (Recommended)**---



```bash</div>

chmod +x setup.sh

./setup.sh## ğŸš€ Features

```

---

**Option B: Manual Installation**

### Core Capabilities

```bash

# Create virtual environment## ğŸ“‹ ç›®å½•

python -m venv venv

source venv/bin/activate  # Windows: venv\Scripts\activate#### 1ï¸âƒ£ Virtual Persona Management



# Install dependencies- [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)

pip install -r requirements.txt

```- **Rich Attributes**: Age, gender, occupation, education, personality traits, values, etc.- [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§)



#### Step 3: Configure LLM- **Batch Creation**: Auto-generate samples matching real population distributions- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)



**Option A: Local LM Studio (Recommended for Learning)**- **CSV Import/Export**: Bulk import personas from Excel or databases- [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)



1. Download [LM Studio](https://lmstudio.ai/)- **Demo Templates**: Built-in templates for common persona types, ready to use- [ğŸ“š å®Œæ•´æ–‡æ¡£](./docs/README.md)

2. Download a model in LM Studio:

   - Recommended: `mistral-7b-instruct`, `llama-2-7b-chat`  - [å¿«é€Ÿå¼€å§‹æŒ‡å—](./docs/quickstart/README.md)

   - Minimum: 7B parameter model

3. Start local server:#### 2ï¸âƒ£ Multiple Simulation Modes  - [APIæ–‡æ¡£](./docs/api/README.md)

   - Click "Local Server" tab

   - Select model  - [æ¶æ„è®¾è®¡](./docs/architecture/README.md)

   - Click "Start Server"

   - Confirm address is `http://localhost:1234`- **Survey Mode**: Run standardized questionnaires (PHQ-9, GAD-7, etc.)  - [çºµå‘ç ”ç©¶æŒ‡å—](./docs/longitudinal/README.md)



**Option B: Online API (Recommended for Production)**- **Intervention Mode**: Test health messages, ad copy, etc. on different populations  - [è´¡çŒ®æŒ‡å—](./docs/contributing/README.md)



```bash- **A/B Testing**: Test multiple versions simultaneously and compare effects- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

# Copy environment template

cp env.example .env- **Longitudinal Studies**: Multi-wave research to track changes over time- [è®¸å¯è¯](#è®¸å¯è¯)



# Edit .env file and add your API key- **Sensitivity Analysis**: Systematically test parameter impact on results

# DEEPSEEK_API_KEY=your_api_key_here

# or---

# OPENAI_API_KEY=your_api_key_here

```#### 3ï¸âƒ£ LLM Integration



#### Step 4: Launch Application## ğŸ¯ é¡¹ç›®ç®€ä»‹



```bash- **Local Deployment**: LM Studio (free, completely private)

streamlit run app.py

```- **Commercial APIs**:**LLM Simulation Survey System** æ˜¯ä¸€ä¸ªåˆ›æ–°çš„ç ”ç©¶å·¥å…·ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆè™šæ‹Ÿäººç‰©ï¼ˆPersonasï¼‰ï¼Œæ¨¡æ‹ŸçœŸå®äººç¾¤å¯¹è°ƒæŸ¥é—®å·å’Œå¹²é¢„æªæ–½çš„å“åº”ã€‚



The app will automatically open in your browser at: `http://localhost:8501`  - DeepSeek (cost-effective, Chinese-optimized)



### First-Time User Guide  - OpenAI (GPT-4, GPT-3.5)### é€‚ç”¨åœºæ™¯



**1. Connect LLM (Home Page)**  - Other OpenAI-compatible services

   - Select your LLM provider

   - Test the connection- **Flexible Switching**: Change models or providers anytime- ğŸ¥ **å¥åº·å¹²é¢„ç ”ç©¶** - æµ‹è¯•å¥åº·ä¿¡æ¯å¯¹ä¸åŒäººç¾¤çš„å½±å“

   - Wait for "System Ready" message

- ğŸ“Š **å¸‚åœºè°ƒç ”** - å¿«é€Ÿè¯„ä¼°äº§å“æˆ–æœåŠ¡çš„ç”¨æˆ·åé¦ˆ

**2. Create Virtual Personas (Setup Page)**

   - Click "Create Demo Personas" for quick start#### 4ï¸âƒ£ Advanced Analysis- ğŸ“ **æ•™è‚²ç ”ç©¶** - è¯„ä¼°æ•™å­¦æ–¹æ³•å¯¹ä¸åŒå­¦ä¹ è€…çš„æ•ˆæœ

   - Or manually create custom personas

   - Or upload CSV for bulk import- ğŸ’¡ **æ”¿ç­–åˆ†æ** - é¢„æµ‹æ”¿ç­–å¯¹å¤šå…ƒç¾¤ä½“çš„æ½œåœ¨å½±å“



**3. Run Simulation (Simulation Page)**- **Auto-Scoring**: Built-in scoring for standardized scales- ğŸ§ª **A/B æµ‹è¯•** - æ¯”è¾ƒä¸åŒæ–¹æ¡ˆçš„æ•ˆæœå·®å¼‚

   - Choose simulation type (Survey/Intervention/A/B Test)

   - Select personas to participate- **Statistical Analysis**: Descriptive stats, correlation, group comparisons- ğŸ“ˆ **åŸå‹éªŒè¯** - åœ¨çœŸå®è°ƒç ”å‰å¿«é€Ÿè¿­ä»£è®¾è®¡

   - Choose questionnaire template or enter custom questions

   - Click "Run Simulation"- **Consistency Checks**: Validate response internal consistency and logic



**4. View Results (Results Page)**- **Visualization**: Interactive charts, word clouds, distributions### æ ¸å¿ƒä¼˜åŠ¿

   - Browse response data

   - View statistical analysis- **Export Features**: CSV, JSON, Python/R analysis scripts

   - Export results for further analysis

âœ… **å¿«é€Ÿè¿­ä»£** - å‡ åˆ†é’Ÿå†…å®Œæˆæ•°ç™¾äººçš„è°ƒæŸ¥æ¨¡æ‹Ÿ  

---

#### 5ï¸âƒ£ Performance Optimizationâœ… **æˆæœ¬ä½å»‰** - æ— éœ€æ‹›å‹ŸçœŸå®å‚ä¸è€…  

## ğŸ“– User Guide

âœ… **å¯é‡å¤æ€§** - ç²¾ç¡®æ§åˆ¶å˜é‡ï¼Œç¡®ä¿å®éªŒå¯é‡å¤  

### Persona Design Best Practices

- **Parallel Execution**: Async processing for multiple persona responsesâœ… **å¤šæ ·åŒ–** - è½»æ¾åˆ›å»ºä¸åŒèƒŒæ™¯ã€å¹´é¾„ã€æ–‡åŒ–çš„è™šæ‹Ÿäººç‰©  

#### Creating High-Quality Personas

- **Smart Caching**: Avoid redundant LLM calls, save time and costâœ… **æ·±åº¦æ´å¯Ÿ** - è·å¾—è¯¦ç»†çš„è´¨æ€§å’Œé‡åŒ–æ•°æ®  

**Good Example: Specific, detailed, realistic**

- **Resume Capability**: Pause and resume large-scale simulationsâœ… **çµæ´»éƒ¨ç½²** - æ”¯æŒæœ¬åœ°è¿è¡Œå’Œäº‘ç«¯API

```python

{- **Progress Tracking**: Real-time progress and estimated completion time

    "name": "Sarah Chen",

    "age": 32,---

    "gender": "Female",

    "occupation": "Software Engineer at startup",---

    "education": "Bachelor's in Computer Science",

    "location": "San Francisco, CA",## ğŸš€ åŠŸèƒ½ç‰¹æ€§

    "background": "Works at a fast-growing tech company, often works overtime. Recently experiencing work stress and sleep quality decline. Likes to relieve stress through exercise but often too busy.",

    "personality_traits": ["Perfectionist", "Strong sense of responsibility", "Somewhat anxious"],## âš¡ Quick Start

    "values": ["Career development", "Work-life balance", "Family health"]

}### æ ¸å¿ƒåŠŸèƒ½

```

### System Requirements

**Bad Example: Vague, generic**

#### 1ï¸âƒ£ è™šæ‹Ÿäººç‰©ç®¡ç†

```python

{- **Python**: 3.8 or higher- **ä¸°å¯Œçš„äººç‰©å±æ€§**ï¼šå¹´é¾„ã€æ€§åˆ«ã€èŒä¸šã€æ•™è‚²èƒŒæ™¯ã€æ€§æ ¼ç‰¹å¾ã€ä»·å€¼è§‚ç­‰

    "name": "John Doe",

    "age": 30,- **Memory**: 8GB+ recommended- **æ‰¹é‡åˆ›å»º**ï¼šä½¿ç”¨äººå£ç»Ÿè®¡åˆ†å¸ƒè‡ªåŠ¨ç”Ÿæˆç¬¦åˆçœŸå®äººå£çš„è™šæ‹Ÿæ ·æœ¬

    "gender": "Male",

    "occupation": "Engineer",- **LLM Provider** (choose one):- **CSV å¯¼å…¥/å¯¼å‡º**ï¼šæ”¯æŒä»Excelæˆ–æ•°æ®åº“æ‰¹é‡å¯¼å…¥äººç‰©

    "background": "Regular person",

    "personality_traits": ["Normal"],  - LM Studio (local, free)- **æ¼”ç¤ºæ¨¡æ¿**ï¼šå†…ç½®å¤šç§å…¸å‹äººç‰©æ¨¡æ¿ï¼Œå³å¼€å³ç”¨

    "values": ["Happiness"]

}  - DeepSeek/OpenAI API key

```

#### 2ï¸âƒ£ å¤šç§æ¨¡æ‹Ÿæ¨¡å¼

#### Persona Diversity Guidelines

### Installation- **è°ƒæŸ¥æ¨¡å¼**ï¼šè¿è¡Œæ ‡å‡†åŒ–é—®å·ï¼ˆPHQ-9ã€GAD-7 ç­‰ï¼‰

Ensure your virtual sample reflects real population diversity:

- **å¹²é¢„æ¨¡å¼**ï¼šæµ‹è¯•å¥åº·ä¿¡æ¯ã€å¹¿å‘Šæ–‡æ¡ˆç­‰å¯¹ä¸åŒäººç¾¤çš„å½±å“

- **Age**: Cover different age groups (18-80 years)

- **Gender**: Male, female, non-binary#### 1. Clone Repository- **A/B æµ‹è¯•**ï¼šåŒæ—¶æµ‹è¯•å¤šä¸ªç‰ˆæœ¬ï¼Œæ¯”è¾ƒæ•ˆæœå·®å¼‚

- **Occupation**: Different industries and position levels

- **Education**: High school to graduate degrees- **çºµå‘ç ”ç©¶**ï¼šæ¨¡æ‹Ÿå¤šæ³¢æ¬¡è°ƒæŸ¥ï¼Œè¿½è¸ªå˜åŒ–è¶‹åŠ¿

- **Geography**: Urban, rural, different regions

- **Cultural Background**: Different ethnicities, religions, cultural traditions```bash- **æ•æ„Ÿæ€§åˆ†æ**ï¼šç³»ç»Ÿæ€§æµ‹è¯•å‚æ•°å˜åŒ–å¯¹ç»“æœçš„å½±å“



### Questionnaire Design Tipsgit clone https://github.com/jason-jj-li/auto_sim_ai.git



#### Characteristics of Good Questionscd auto_sim_ai#### 3ï¸âƒ£ LLM é›†æˆ



âœ… **Clear and Specific**```- **æœ¬åœ°éƒ¨ç½²**ï¼šLM Studioï¼ˆå…è´¹ï¼Œå®Œå…¨ç§å¯†ï¼‰



```- **å•†ä¸šAPI**ï¼š

Good: "In the past two weeks, how many days have you felt down or depressed?"

Bad: "How have you been feeling lately?"#### 2. Install Dependencies  - DeepSeekï¼ˆé«˜æ€§ä»·æ¯”ï¼Œä¸­æ–‡ä¼˜åŒ–ï¼‰

```

  - OpenAIï¼ˆGPT-4ã€GPT-3.5ï¼‰

âœ… **Avoid Compound Questions**

```bash  - å…¶ä»– OpenAI å…¼å®¹æœåŠ¡

```

Good: "How many times per week do you exercise?" + "How long is each exercise session?"# Create virtual environment (recommended)- **çµæ´»åˆ‡æ¢**ï¼šéšæ—¶æ›´æ¢æ¨¡å‹æˆ–æä¾›å•†

Bad: "How often do you exercise, for how long, and at what intensity?"

```python -m venv venv



âœ… **Use Standardized Scales**source venv/bin/activate  # Windows: venv\Scripts\activate#### 4ï¸âƒ£ é«˜çº§åˆ†æ



```- **è‡ªåŠ¨è¯„åˆ†**ï¼šå†…ç½®æ ‡å‡†åŒ–é‡è¡¨çš„è‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿ

Never(0) - Sometimes(1) - Often(2) - Always(3)

```# Install dependencies- **ç»Ÿè®¡åˆ†æ**ï¼šæè¿°ç»Ÿè®¡ã€ç›¸å…³åˆ†æã€ç»„é—´æ¯”è¾ƒ



#### Built-in Templatespip install -r requirements.txt- **ä¸€è‡´æ€§æ£€æŸ¥**ï¼šéªŒè¯å“åº”çš„å†…éƒ¨ä¸€è‡´æ€§å’Œé€»è¾‘æ€§



The system includes validated standardized scales:```- **å¯è§†åŒ–**ï¼šäº¤äº’å¼å›¾è¡¨ã€è¯äº‘ã€åˆ†å¸ƒå›¾



- **PHQ-9**: Depression screening scale- **å¯¼å‡ºåŠŸèƒ½**ï¼šCSVã€JSONã€Python/R åˆ†æè„šæœ¬

- **GAD-7**: Anxiety screening scale  

- **PSS-10**: Perceived Stress ScaleOr use the setup script:

- More templates continuously being added...

#### 5ï¸âƒ£ æ€§èƒ½ä¼˜åŒ–

### Simulation Settings Optimization

```bash- **å¹¶è¡Œæ‰§è¡Œ**ï¼šå¼‚æ­¥å¤„ç†å¤šä¸ªäººç‰©çš„å“åº”

#### Temperature Parameter

chmod +x setup.sh- **æ™ºèƒ½ç¼“å­˜**ï¼šé¿å…é‡å¤è°ƒç”¨ LLMï¼ŒèŠ‚çœæ—¶é—´å’Œæˆæœ¬

Controls response randomness and creativity:

./setup.sh- **æ–­ç‚¹ç»­ä¼ **ï¼šæ”¯æŒæš‚åœå’Œæ¢å¤å¤§è§„æ¨¡æ¨¡æ‹Ÿ

- **0.0 - 0.3**: High consistency, suitable for standardized responses

- **0.5 - 0.7**: Balanced mode, recommended for most surveys (default)```- **è¿›åº¦è¿½è¸ª**ï¼šå®æ—¶æ˜¾ç¤ºæ¨¡æ‹Ÿè¿›åº¦å’Œé¢„ä¼°å®Œæˆæ—¶é—´

- **0.8 - 1.0**: More diverse, suitable for exploratory research



#### Max Tokens

#### 3. Configure LLM---

- **150-300**: Short answers (multiple choice, scale ratings)

- **300-500**: Medium length (short answer questions)

- **500-1000**: Detailed responses (open-ended questions, in-depth interviews)

**Option A: Local LM Studio (recommended for learning/development)**## âš¡ å¿«é€Ÿå¼€å§‹

#### Parallel Settings



- **Small Scale** (<10 personas): Concurrency 2-3

- **Medium Scale** (10-50 personas): Concurrency 5-101. Download [LM Studio](https://lmstudio.ai/)### ç³»ç»Ÿè¦æ±‚

- **Large Scale** (50+ personas): Concurrency 10-15 (watch API rate limits)

2. Download a model in LM Studio:

---

   - Recommended: `mistral-7b-instruct`, `llama-2-7b-chat`- **Python**: 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬

## ğŸ—ï¸ Architecture

   - Minimum: 7B parameter model- **å†…å­˜**: å»ºè®® 8GB ä»¥ä¸Š

For detailed architecture documentation, see **[Architecture Guide](./docs/en/architecture/README.md)**

3. Start local server:- **LLM æä¾›å•†**ï¼ˆä»»é€‰å…¶ä¸€ï¼‰ï¼š

### Project Structure

   - Click "Local Server" tab  - LM Studioï¼ˆæœ¬åœ°è¿è¡Œï¼Œå…è´¹ï¼‰

```

auto_sim_ai/   - Select model  - DeepSeek/OpenAI API å¯†é’¥

â”œâ”€â”€ app.py                      # Streamlit main application

â”œâ”€â”€ pages/                      # Multi-page application   - Click "Start Server"

â”‚   â”œâ”€â”€ 1_Setup.py             # Persona management

â”‚   â”œâ”€â”€ 2_Simulation.py        # Run simulations   - Confirm address is `http://localhost:1234`### å®‰è£…æ­¥éª¤

â”‚   â””â”€â”€ 3_Results.py           # View results

â”œâ”€â”€ src/                        # Core modules

â”‚   â”œâ”€â”€ llm_client.py          # LLM client (sync/async)

â”‚   â”œâ”€â”€ persona.py             # Persona management**Option B: Online API (recommended for production)**#### 1. å…‹éš†é¡¹ç›®

â”‚   â”œâ”€â”€ simulation.py          # Simulation engine

â”‚   â”œâ”€â”€ storage.py             # Results storage

â”‚   â”œâ”€â”€ cache.py               # Response caching

â”‚   â”œâ”€â”€ scoring.py             # Auto-scoring```bash```bash

â”‚   â””â”€â”€ ...                    # Additional modules

â”œâ”€â”€ tests/                      # Test suite# Copy environment templategit clone https://github.com/jason-jj-li/auto_sim_ai.git

â”œâ”€â”€ data/                       # Data directory

â”‚   â”œâ”€â”€ personas/              # Persona datacp env.example .envcd auto_sim_ai

â”‚   â”œâ”€â”€ results/               # Simulation results

â”‚   â””â”€â”€ cache/                 # Cached responses```

â””â”€â”€ docs/                       # Documentation

```# Edit .env file, add API key



### Core Modules# DEEPSEEK_API_KEY=your_api_key_here#### 2. å®‰è£…ä¾èµ–



**LLM Client** (`llm_client.py`)# or

- Synchronous and asynchronous modes

- Compatible with OpenAI API format# OPENAI_API_KEY=your_api_key_here```bash

- Seamless switching between providers

```# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

**Simulation Engine** (`simulation.py`)

- Sequential and parallel executionpython -m venv venv

- Automatic error retry and progress tracking

- Result aggregation#### 4. Launch Applicationsource venv/bin/activate  # Windows: venv\Scripts\activate



**Cache System** (`cache.py`)

- Content-hash based smart caching

- Significantly reduce API costs```bash# å®‰è£…ä¾èµ–

- Import/export capability

streamlit run app.pypip install -r requirements.txt

**Scoring System** (`scoring.py`)

- Automated scoring for standardized scales``````

- Configurable custom rules

- Total and subscale calculations



---The app will automatically open in your browser: `http://localhost:8501`æˆ–ä½¿ç”¨å®‰è£…è„šæœ¬ï¼š



## ğŸ”¬ Advanced Features```bash



> ğŸ’¡ **See [API Guide](./docs/en/api/README.md) for detailed documentation**### First-Time User Guidechmod +x setup.sh



### 1. A/B Testing./setup.sh



Compare different intervention versions:1. **Connect LLM** (Home Page)```



```python   - Select LLM provider

from src import ABTestManager, Condition

   - Test connection#### 3. é…ç½® LLM

# Define test conditions

condition_a = Condition(   - Wait for "System Ready" message

    name="Version A",

    intervention_text="Meditating 10 minutes daily can reduce stress.",**æ–¹å¼ Aï¼šæœ¬åœ° LM Studioï¼ˆæ¨èç”¨äºå­¦ä¹ å’Œå¼€å‘ï¼‰**

    questions=["Would you try this method?"]

)2. **Create Virtual Personas** (Setup Page)



condition_b = Condition(   - Click "Create Demo Personas" for quick start1. ä¸‹è½½ [LM Studio](https://lmstudio.ai/)

    name="Version B", 

    intervention_text="Research shows daily 10-minute meditation reduces stress by 30%.",   - Or manually create custom personas2. åœ¨ LM Studio ä¸­ä¸‹è½½æ¨¡å‹ï¼š

    questions=["Would you try this method?"]

)   - Or upload CSV for bulk import   - æ¨èï¼š`mistral-7b-instruct`ã€`llama-2-7b-chat`



# Run A/B test   - æœ€ä½ï¼š7B å‚æ•°æ¨¡å‹

ab_manager = ABTestManager()

results = ab_manager.run_test([condition_a, condition_b], personas)3. **Run Simulation** (Simulation Page)3. å¯åŠ¨æœ¬åœ°æœåŠ¡å™¨ï¼š

```

   - Choose simulation type (Survey/Intervention)   - ç‚¹å‡» "Local Server" æ ‡ç­¾

### 2. Longitudinal Studies

   - Select personas to participate   - é€‰æ‹©æ¨¡å‹

Multi-wave tracking with conversation memory:

   - Choose questionnaire template or enter custom questions   - ç‚¹å‡» "Start Server"

```python

from src import LongitudinalStudyEngine, WaveConfig, LongitudinalStudyConfig   - Click "Run Simulation"   - ç¡®è®¤åœ°å€ä¸º `http://localhost:1234`



# Configure study waves

waves = [

    WaveConfig(4. **View Results** (Results Page)**æ–¹å¼ Bï¼šåœ¨çº¿ APIï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰**

        wave_number=1,

        wave_name="Baseline",   - Browse response data

        questions=["What is your current stress level? (1-10)"],

        days_from_baseline=0   - View statistical analysis```bash

    ),

    WaveConfig(   - Export results for further analysis# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿

        wave_number=2,

        wave_name="1 Month Follow-up",cp env.example .env

        questions=["What is your stress level now? (1-10)"],

        days_from_baseline=30,---

        intervention_text="Practice 10 minutes of meditation daily"

    )# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œæ·»åŠ  API å¯†é’¥

]

## ğŸ“– User Guide# DEEPSEEK_API_KEY=your_api_key_here

# Run study

config = LongitudinalStudyConfig(# æˆ–

    study_id="stress_study",

    study_name="Stress Intervention Study",### Persona Design Best Practices# OPENAI_API_KEY=your_api_key_here

    waves=waves

)```



engine = LongitudinalStudyEngine(llm_client)#### Creating High-Quality Personas

results = engine.run_study(personas, config)

```#### 4. å¯åŠ¨åº”ç”¨



See **[Longitudinal Study Guide](./docs/en/longitudinal/README.md)** for details.```python



### 3. Batch Persona Generation# Good Example: Specific, detailed, realistic```bash



Generate samples based on real demographic distributions:{streamlit run app.py



```python    "name": "Sarah Chen",```

from src import PersonaGenerator, DistributionConfig

    "age": 32,

# Configure distribution

config = DistributionConfig(    "gender": "Female",åº”ç”¨å°†åœ¨æµè§ˆå™¨ä¸­è‡ªåŠ¨æ‰“å¼€ï¼š`http://localhost:8501`

    age_distribution={"18-30": 0.3, "31-50": 0.4, "51-70": 0.3},

    gender_distribution={"Male": 0.48, "Female": 0.52}    "occupation": "Software Engineer at startup",

)

    "education": "Bachelor's in Computer Science",### é¦–æ¬¡ä½¿ç”¨æŒ‡å—

# Generate 100 personas

generator = PersonaGenerator()    "location": "San Francisco, CA",

personas = generator.generate_batch(

    count=100,    "background": "Works at a fast-growing tech company, often works overtime. Recently experiencing work stress and sleep quality decline. Likes to relieve stress through exercise but often too busy.",1. **è¿æ¥ LLM**ï¼ˆé¦–é¡µï¼‰

    distribution_config=config,

    llm_client=client    "personality_traits": ["Perfectionist", "Strong sense of responsibility", "Somewhat anxious"],   - é€‰æ‹© LLM æä¾›å•†

)

```    "values": ["Career development", "Work-life balance", "Family health"]   - æµ‹è¯•è¿æ¥



### 4. Response Validation}   - ç­‰å¾…"ç³»ç»Ÿå°±ç»ª"æç¤º



Check response quality and consistency:



```python# Bad Example: Vague, generic2. **åˆ›å»ºè™šæ‹Ÿäººç‰©**ï¼ˆSetup é¡µé¢ï¼‰

from src import ResponseValidator, ConsistencyChecker

{   - ç‚¹å‡» "Create Demo Personas" å¿«é€Ÿåˆ›å»º

validator = ResponseValidator()

checker = ConsistencyChecker()    "name": "John Doe",   - æˆ–æ‰‹åŠ¨åˆ›å»ºè‡ªå®šä¹‰äººç‰©



# Validate format    "age": 30,   - æˆ–ä¸Šä¼  CSV æ‰¹é‡å¯¼å…¥

is_valid = validator.validate_response(response, question_type)

    "gender": "Male",

# Check consistency

metrics = checker.check_consistency(persona_responses)    "occupation": "Engineer",3. **è¿è¡Œæ¨¡æ‹Ÿ**ï¼ˆSimulation é¡µé¢ï¼‰

print(f"Consistency score: {metrics.consistency_score}")

```    "background": "Regular person",   - é€‰æ‹©æ¨¡æ‹Ÿç±»å‹ï¼ˆè°ƒæŸ¥/å¹²é¢„ï¼‰



---    "personality_traits": ["Normal"],   - é€‰æ‹©è¦å‚ä¸çš„äººç‰©



## ğŸ“š API Documentation    "values": ["Happiness"]   - é€‰æ‹©é—®å·æ¨¡æ¿æˆ–è¾“å…¥è‡ªå®šä¹‰é—®é¢˜



### PersonaManager}   - ç‚¹å‡» "Run Simulation"



```python```

from src import PersonaManager

4. **æŸ¥çœ‹ç»“æœ**ï¼ˆResults é¡µé¢ï¼‰

manager = PersonaManager()

#### Persona Diversity   - æµè§ˆå“åº”æ•°æ®

# Add persona

manager.add_persona(persona)   - æŸ¥çœ‹ç»Ÿè®¡åˆ†æ



# Get all personasEnsure virtual samples reflect real population diversity:   - å¯¼å‡ºç»“æœç”¨äºè¿›ä¸€æ­¥åˆ†æ

personas = manager.get_all_personas()



# Filter by criteria

young_adults = manager.filter_personas(- **Age**: Cover different age groups (18-80 years)---

    age_range=(18, 30),

    gender="Female"- **Gender**: Male, female, non-binary

)

- **Occupation**: Different industries and position levels## ğŸ“– ä½¿ç”¨æŒ‡å—

# Save/load

manager.save_to_file("personas.json")- **Education**: High school to graduate degrees

manager.load_from_file("personas.json")

```- **Geography**: Urban, rural, different regions### è™šæ‹Ÿäººç‰©è®¾è®¡æœ€ä½³å®è·µ



### SimulationEngine- **Cultural Background**: Different ethnicities, religions, cultural traditions



```python#### åˆ›å»ºé«˜è´¨é‡äººç‰©

from src import SimulationEngine

### Questionnaire Design Tips

engine = SimulationEngine(

    llm_client=client,```python

    cache=cache,

    checkpoint_manager=checkpoint_mgr#### Good Question Characteristics# å¥½çš„ä¾‹å­ï¼šå…·ä½“ã€è¯¦ç»†ã€çœŸå®

)

{

# Run survey

result = engine.run_survey(âœ… **Clear and Specific**    "name": "ææ˜",

    personas=personas,

    questions=questions,    "age": 32,

    temperature=0.7,

    max_tokens=300```    "gender": "ç”·",

)

Good: In the past two weeks, how many days have you felt down or depressed?    "occupation": "åˆåˆ›å…¬å¸è½¯ä»¶å·¥ç¨‹å¸ˆ",

# Run intervention

result = engine.run_intervention(Bad: How have you been feeling lately?    "education": "æœ¬ç§‘è®¡ç®—æœºç§‘å­¦",

    personas=personas,

    intervention_text="Health intervention text",```    "location": "åŒ—äº¬",

    questions=followup_questions

)    "background": "åœ¨ä¸€å®¶å¿«é€Ÿæˆé•¿çš„ç§‘æŠ€å…¬å¸å·¥ä½œï¼Œç»å¸¸åŠ ç­ã€‚æœ€è¿‘æ„Ÿåˆ°å·¥ä½œå‹åŠ›å¤§ï¼Œç¡çœ è´¨é‡ä¸‹é™ã€‚å–œæ¬¢é€šè¿‡è¿åŠ¨ç¼“è§£å‹åŠ›ï¼Œä½†å·¥ä½œç¹å¿™å¸¸å¸¸æ²¡æ—¶é—´ã€‚",

```

âœ… **Avoid Compound Questions**    "personality_traits": ["å®Œç¾ä¸»ä¹‰", "è´£ä»»å¿ƒå¼º", "æœ‰äº›ç„¦è™‘"],

### ResultsStorage

    "values": ["èŒä¸šå‘å±•", "å·¥ä½œç”Ÿæ´»å¹³è¡¡", "å®¶åº­å¥åº·"]

```python

from src import ResultsStorage```}



storage = ResultsStorage()Good: How many times per week do you exercise? How long is each exercise session?



# Save resultBad: How often do you exercise, for how long, and at what intensity?# ä¸å¥½çš„ä¾‹å­ï¼šæ¨¡ç³Šã€ä¸€èˆ¬åŒ–

storage.save_result(simulation_result)

```{

# Load results

results = storage.load_all_results()    "name": "å¼ ä¸‰",



# Export to CSVâœ… **Use Standardized Scales**    "age": 30,

storage.export_to_csv(result, "output.csv")

    "gender": "ç”·",

# Export analysis script

storage.export_analysis_script(result, "analysis.py", language="python")```    "occupation": "å·¥ç¨‹å¸ˆ",

```

Never(0) - Sometimes(1) - Often(2) - Always(3)    "background": "æ™®é€šäºº",

---

```    "personality_traits": ["æ­£å¸¸"],

## â“ FAQ

    "values": ["å¹¸ç¦"]

### How many LLM API calls are needed?

#### Use Built-in Templates}

Call count = Number of personas Ã— Number of questions

```

Example:

- 10 personas Ã— 9 questions = 90 callsThe system includes validated standardized scales:

- Caching significantly reduces repeat calls

#### äººç‰©å¤šæ ·æ€§

### How long does simulation take?

- **PHQ-9**: Depression screening scale

Depends on:

- **Local model**: ~5-15 seconds/response- **GAD-7**: Anxiety screening scaleç¡®ä¿è™šæ‹Ÿæ ·æœ¬åæ˜ çœŸå®äººå£çš„å¤šæ ·æ€§ï¼š

- **Online API**: ~1-3 seconds/response

- **Parallel execution**: Can reduce time by 50-80%- **PSS-10**: Perceived Stress Scale



### How reliable are the results?- More templates continuously being added...- **å¹´é¾„**ï¼šè¦†ç›–ä¸åŒå¹´é¾„æ®µï¼ˆ18-80å²ï¼‰



LLM simulation is an exploratory research tool, suitable for:- **æ€§åˆ«**ï¼šç”·ã€å¥³ã€éäºŒå…ƒæ€§åˆ«



âœ… Rapid prototyping  ### Simulation Settings Optimization- **èŒä¸š**ï¼šä¸åŒè¡Œä¸šå’ŒèŒä½å±‚çº§

âœ… Hypothesis generation  

âœ… Questionnaire pre-testing  - **æ•™è‚²**ï¼šä»é«˜ä¸­åˆ°ç ”ç©¶ç”Ÿ

âŒ **Cannot** replace real human research

#### Temperature Parameter- **åœ°åŸŸ**ï¼šåŸå¸‚ã€å†œæ‘ã€ä¸åŒåœ°åŒº

### How to improve response quality?

- **æ–‡åŒ–èƒŒæ™¯**ï¼šä¸åŒç§æ—ã€å®—æ•™ã€æ–‡åŒ–ä¼ ç»Ÿ

1. Create detailed, realistic persona backgrounds

2. Use clear, specific questionsControls response randomness and creativity:

3. Choose appropriate temperature parameters

4. Use more powerful models (e.g., GPT-4)### é—®å·è®¾è®¡æŠ€å·§

5. Enable response validation and consistency checks

- **0.0 - 0.3**: High consistency, suitable for standardized responses

### What about costs?

- **0.5 - 0.7**: Balanced mode, recommended for most surveys (default)#### å¥½çš„é—®é¢˜ç‰¹å¾

- **Local LM Studio**: Completely free (requires GPU)

- **DeepSeek API**: ~$0.0001/1k tokens (extremely low cost)- **0.8 - 1.0**: More diverse, suitable for exploratory research and creative testing

- **OpenAI GPT-3.5**: ~$0.002/1k tokens

- **OpenAI GPT-4**: ~$0.03/1k tokensâœ… **æ¸…æ™°å…·ä½“**



### Is my data secure?#### Max Tokens```



- **Local mode**: Data never leaves your machineå¥½ï¼šåœ¨è¿‡å»ä¸¤å‘¨å†…ï¼Œæ‚¨æœ‰å¤šå°‘å¤©æ„Ÿåˆ°æƒ…ç»ªä½è½æˆ–æ²®ä¸§ï¼Ÿ

- **API mode**: Follows each provider's privacy policy

- **Recommendation**: Use local mode for sensitive data- **150-300**: Short answers (multiple choice, scale ratings)å·®ï¼šæ‚¨æœ€è¿‘å¿ƒæƒ…æ€ä¹ˆæ ·ï¼Ÿ



---- **300-500**: Medium length (short answer questions)```



## ğŸ¤ Contributing- **500-1000**: Detailed responses (open-ended questions, in-depth interviews)



Contributions welcome! See [Contributing Guide](./docs/en/contributing/README.md) for details.âœ… **é¿å…å¤åˆé—®é¢˜**



### Development Setup#### Parallel Settings```



```bashå¥½ï¼šæ‚¨æ¯å‘¨é”»ç‚¼å¤šå°‘æ¬¡ï¼Ÿæ‚¨æ¯æ¬¡é”»ç‚¼å¤šé•¿æ—¶é—´ï¼Ÿ

# Install development dependencies

pip install -r requirements-dev.txt- **Small Scale** (<10 personas): Concurrency 2-3å·®ï¼šæ‚¨å¤šä¹…é”»ç‚¼ä¸€æ¬¡ï¼Œæ¯æ¬¡å¤šé•¿æ—¶é—´ï¼Œä»€ä¹ˆå¼ºåº¦ï¼Ÿ



# Run tests- **Medium Scale** (10-50 personas): Concurrency 5-10```

pytest

- **Large Scale** (50+ personas): Concurrency 10-15 (watch API rate limits)

# Code formatting

black src/ tests/âœ… **ä½¿ç”¨æ ‡å‡†åŒ–é‡è¡¨**

isort src/ tests/

---```

# Type checking

mypy src/ä»ä¸(0) - å¶å°”(1) - ç»å¸¸(2) - æ€»æ˜¯(3)

```

## ğŸ—ï¸ Architecture```

### Report Issues



Found a bug or have a feature suggestion? Please [create an issue](https://github.com/jason-jj-li/auto_sim_ai/issues).

For detailed architecture documentation, see **[Architecture Guide](./docs/en/architecture/README.md)**#### ä½¿ç”¨å†…ç½®æ¨¡æ¿

---



## ğŸ“„ License

### Project Structureç³»ç»Ÿå†…ç½®å¤šä¸ªéªŒè¯è¿‡çš„æ ‡å‡†åŒ–é‡è¡¨ï¼š

This project is licensed under the MIT License. See [LICENSE](LICENSE) file for details.



---

```- **PHQ-9**ï¼šæŠ‘éƒç—‡ç­›æŸ¥é‡è¡¨

## ğŸ™ Acknowledgments

auto_sim_ai/- **GAD-7**ï¼šç„¦è™‘ç—‡ç­›æŸ¥é‡è¡¨

- [Streamlit](https://streamlit.io/) - Python web framework

- [LM Studio](https://lmstudio.ai/) - Local LLM runtimeâ”œâ”€â”€ app.py                      # Streamlit main application- **PSS-10**ï¼šå‹åŠ›æ„ŸçŸ¥é‡è¡¨

- [OpenAI](https://openai.com/) - API standards

- [DeepSeek](https://www.deepseek.com/) - Cost-effective LLM serviceâ”œâ”€â”€ pages/                      # Multi-page application- æ›´å¤šæ¨¡æ¿æŒç»­æ·»åŠ ä¸­...



---â”‚   â”œâ”€â”€ 1_Setup.py             # Persona management page



## ğŸ“ Contactâ”‚   â”œâ”€â”€ 2_Simulation.py        # Simulation execution page### æ¨¡æ‹Ÿè®¾ç½®ä¼˜åŒ–



- **Maintainer**: Jason Liâ”‚   â””â”€â”€ 3_Results.py           # Results analysis page

- **GitHub**: [@jason-jj-li](https://github.com/jason-jj-li)

- **Email**: Contact via GitHub Issuesâ”œâ”€â”€ src/                        # Core modules#### æ¸©åº¦å‚æ•°ï¼ˆTemperatureï¼‰



---â”‚   â”œâ”€â”€ llm_client.py          # LLM client (sync/async)



<div align="center">â”‚   â”œâ”€â”€ persona.py             # Persona managementæ§åˆ¶å“åº”çš„éšæœºæ€§å’Œåˆ›é€ æ€§ï¼š



**â­ If this project helps you, please give it a star!**â”‚   â”œâ”€â”€ simulation.py          # Simulation engine (single/parallel)



Made with â¤ï¸ by Jason Liâ”‚   â”œâ”€â”€ storage.py             # Results storage- **0.0 - 0.3**ï¼šé«˜åº¦ä¸€è‡´ï¼Œé€‚åˆéœ€è¦æ ‡å‡†åŒ–å“åº”çš„åœºæ™¯



</div>â”‚   â”œâ”€â”€ cache.py               # Response cache- **0.5 - 0.7**ï¼šå¹³è¡¡æ¨¡å¼ï¼Œæ¨èç”¨äºå¤§å¤šæ•°è°ƒæŸ¥ï¼ˆé»˜è®¤ï¼‰


â”‚   â”œâ”€â”€ checkpoint.py          # Checkpoint management- **0.8 - 1.0**ï¼šæ›´å¤šæ ·åŒ–ï¼Œé€‚åˆæ¢ç´¢æ€§ç ”ç©¶å’Œåˆ›æ„æµ‹è¯•

â”‚   â”œâ”€â”€ scoring.py             # Auto-scoring

â”‚   â”œâ”€â”€ ab_testing.py          # A/B testing#### æœ€å¤§ä»¤ç‰Œæ•°ï¼ˆMax Tokensï¼‰

â”‚   â”œâ”€â”€ intervention_study.py  # Intervention studies (legacy)

â”‚   â”œâ”€â”€ persona_generator.py   # Persona generator- **150-300**ï¼šç®€çŸ­ç­”æ¡ˆï¼ˆé€‰æ‹©é¢˜ã€é‡è¡¨è¯„åˆ†ï¼‰

â”‚   â”œâ”€â”€ survey_templates.py    # Survey template library- **300-500**ï¼šä¸­ç­‰é•¿åº¦ï¼ˆç®€ç­”é¢˜ï¼‰

â”‚   â”œâ”€â”€ survey_config.py       # Survey configuration- **500-1000**ï¼šè¯¦ç»†å›ç­”ï¼ˆå¼€æ”¾å¼é—®é¢˜ã€æ·±åº¦è®¿è°ˆï¼‰

â”‚   â”œâ”€â”€ tools.py               # Tool registration system

â”‚   â”œâ”€â”€ ui_components.py       # UI components#### å¹¶è¡Œè®¾ç½®

â”‚   â”œâ”€â”€ styles.py              # Design system

â”‚   â””â”€â”€ validators.py          # Input validation- **å°è§„æ¨¡**ï¼ˆ<10äººï¼‰ï¼šå¹¶å‘æ•° 2-3

â”œâ”€â”€ tests/                      # Test suite- **ä¸­ç­‰è§„æ¨¡**ï¼ˆ10-50äººï¼‰ï¼šå¹¶å‘æ•° 5-10

â”œâ”€â”€ data/                       # Data directory- **å¤§è§„æ¨¡**ï¼ˆ50+äººï¼‰ï¼šå¹¶å‘æ•° 10-15ï¼ˆæ³¨æ„APIé€Ÿç‡é™åˆ¶ï¼‰

â”‚   â”œâ”€â”€ personas/              # Persona data

â”‚   â”œâ”€â”€ results/               # Simulation results---

â”‚   â”œâ”€â”€ cache/                 # Cache data

â”‚   â”œâ”€â”€ checkpoints/           # Checkpoints## ğŸ—ï¸ æ¶æ„è®¾è®¡

â”‚   â””â”€â”€ survey_configs/        # Survey configurations

â”œâ”€â”€ docs/                       # Documentationè¯¦ç»†çš„æ¶æ„æ–‡æ¡£è¯·æŸ¥çœ‹ **[Architecture Guide](./docs/architecture/README.md)**

â”œâ”€â”€ requirements.txt            # Dependencies

â””â”€â”€ pytest.ini                 # Test configuration### é¡¹ç›®ç»“æ„

```

```

### Core Module Overviewauto_sim_ai/

â”œâ”€â”€ app.py                      # Streamlit ä¸»åº”ç”¨

#### LLM Client (`llm_client.py`)â”œâ”€â”€ pages/                      # å¤šé¡µé¢åº”ç”¨

â”‚   â”œâ”€â”€ 1_Setup.py             # äººç‰©ç®¡ç†é¡µé¢

Supports both synchronous and asynchronous modes:â”‚   â”œâ”€â”€ 2_Simulation.py        # æ¨¡æ‹Ÿè¿è¡Œé¡µé¢

â”‚   â””â”€â”€ 3_Results.py           # ç»“æœåˆ†æé¡µé¢

- **LMStudioClient**: Sync client, suitable for simple scenariosâ”œâ”€â”€ src/                        # æ ¸å¿ƒæ¨¡å—

- **AsyncLLMClient**: Async client, supports high concurrencyâ”‚   â”œâ”€â”€ llm_client.py          # LLM å®¢æˆ·ç«¯ï¼ˆåŒæ­¥/å¼‚æ­¥ï¼‰

â”‚   â”œâ”€â”€ persona.py             # äººç‰©ç®¡ç†

Compatible with OpenAI API format, seamless switching between providers.â”‚   â”œâ”€â”€ simulation.py          # æ¨¡æ‹Ÿå¼•æ“ï¼ˆå•çº¿ç¨‹/å¹¶è¡Œï¼‰

â”‚   â”œâ”€â”€ storage.py             # ç»“æœå­˜å‚¨

#### Simulation Engine (`simulation.py`)â”‚   â”œâ”€â”€ cache.py               # å“åº”ç¼“å­˜

â”‚   â”œâ”€â”€ checkpoint.py          # æ–­ç‚¹ç®¡ç†

- **SimulationEngine**: Base engine, sequential executionâ”‚   â”œâ”€â”€ scoring.py             # è‡ªåŠ¨è¯„åˆ†

- **ParallelSimulationEngine**: Parallel engine, supports async batch processingâ”‚   â”œâ”€â”€ ab_testing.py          # A/Bæµ‹è¯•

â”‚   â”œâ”€â”€ intervention_study.py  # å¹²é¢„ç ”ç©¶ï¼ˆæ—§ç‰ˆï¼‰

Automatically handles error retry, progress tracking, result aggregation.â”‚   â”œâ”€â”€ longitudinal_study.py  # çºµå‘ç ”ç©¶ï¼ˆæ–°ç‰ˆï¼Œæ¨èï¼‰

â”‚   â”œâ”€â”€ persona_generator.py   # äººç‰©ç”Ÿæˆå™¨

#### Cache System (`cache.py`)â”‚   â”œâ”€â”€ survey_templates.py    # é—®å·æ¨¡æ¿åº“

â”‚   â”œâ”€â”€ survey_config.py       # é—®å·é…ç½®

Content-hash based smart caching:â”‚   â”œâ”€â”€ tools.py               # å·¥å…·æ³¨å†Œç³»ç»Ÿ

â”‚   â”œâ”€â”€ ui_components.py       # UI ç»„ä»¶

- Same persona + same question = directly return cached resultâ”‚   â”œâ”€â”€ styles.py              # è®¾è®¡ç³»ç»Ÿ

- Support cache export and importâ”‚   â””â”€â”€ validators.py          # è¾“å…¥éªŒè¯

- Significantly reduce LLM API call costsâ”œâ”€â”€ tests/                      # æµ‹è¯•å¥—ä»¶

â”œâ”€â”€ data/                       # æ•°æ®ç›®å½•

#### Scoring System (`scoring.py`)â”‚   â”œâ”€â”€ personas/              # äººç‰©æ•°æ®

â”‚   â”œâ”€â”€ results/               # æ¨¡æ‹Ÿç»“æœ

Automated scoring features:â”‚   â”œâ”€â”€ cache/                 # ç¼“å­˜æ•°æ®

â”‚   â”œâ”€â”€ checkpoints/           # æ£€æŸ¥ç‚¹

- Support for multiple standardized scalesâ”‚   â””â”€â”€ survey_configs/        # é—®å·é…ç½®

- Configurable custom scoring rulesâ”œâ”€â”€ docs/                       # æ–‡æ¡£

- Auto-calculate total and subscale scoresâ”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨

â””â”€â”€ pytest.ini                 # æµ‹è¯•é…ç½®

---```



## ğŸ”¬ Advanced Features### æ ¸å¿ƒæ¨¡å—è¯´æ˜



> ğŸ’¡ **Tip**: For detailed API documentation and advanced features, see [API Guide](./docs/en/api/README.md)#### LLM å®¢æˆ·ç«¯ (`llm_client.py`)



### 1. A/B Testingæ”¯æŒåŒæ­¥å’Œå¼‚æ­¥ä¸¤ç§æ¨¡å¼ï¼š



Compare intervention effects across versions:- **LMStudioClient**ï¼šåŒæ­¥å®¢æˆ·ç«¯ï¼Œé€‚åˆç®€å•åœºæ™¯

- **AsyncLLMClient**ï¼šå¼‚æ­¥å®¢æˆ·ç«¯ï¼Œæ”¯æŒé«˜å¹¶å‘

```python

from src import ABTestManager, Conditionå…¼å®¹ OpenAI API æ ¼å¼ï¼Œå¯æ— ç¼åˆ‡æ¢ä¸åŒæä¾›å•†ã€‚



# Define test conditions#### æ¨¡æ‹Ÿå¼•æ“ (`simulation.py`)

condition_a = Condition(

    name="Version A",- **SimulationEngine**ï¼šåŸºç¡€å¼•æ“ï¼Œé¡ºåºæ‰§è¡Œ

    intervention_text="Meditating 10 minutes daily can reduce stress.",- **ParallelSimulationEngine**ï¼šå¹¶è¡Œå¼•æ“ï¼Œæ”¯æŒå¼‚æ­¥æ‰¹å¤„ç†

    questions=["Would you try this method?"]

)è‡ªåŠ¨å¤„ç†é”™è¯¯é‡è¯•ã€è¿›åº¦è¿½è¸ªã€ç»“æœèšåˆã€‚



condition_b = Condition(#### ç¼“å­˜ç³»ç»Ÿ (`cache.py`)

    name="Version B", 

    intervention_text="Research shows daily 10-minute meditation reduces stress levels by 30%.",åŸºäºå†…å®¹å“ˆå¸Œçš„æ™ºèƒ½ç¼“å­˜ï¼š

    questions=["Would you try this method?"]- ç›¸åŒäººç‰© + ç›¸åŒé—®é¢˜ = ç›´æ¥è¿”å›ç¼“å­˜ç»“æœ

)- æ”¯æŒç¼“å­˜å¯¼å‡ºå’Œå¯¼å…¥

- æ˜¾è‘—é™ä½ LLM API è°ƒç”¨æˆæœ¬

# Run A/B test

ab_manager = ABTestManager()#### è¯„åˆ†ç³»ç»Ÿ (`scoring.py`)

results = ab_manager.run_test([condition_a, condition_b], personas)

```è‡ªåŠ¨åŒ–è¯„åˆ†åŠŸèƒ½ï¼š

- æ”¯æŒå¤šç§æ ‡å‡†åŒ–é‡è¡¨

### 2. Longitudinal Studies (Multi-Wave Tracking)- å¯é…ç½®è‡ªå®šä¹‰è¯„åˆ†è§„åˆ™

- è‡ªåŠ¨è®¡ç®—æ€»åˆ†å’Œå­é‡è¡¨åˆ†æ•°

Implement realistic longitudinal tracking with conversation memory:

---

```python

from src import LongitudinalStudyEngine, WaveConfig, LongitudinalStudyConfig## ğŸ”¬ é«˜çº§åŠŸèƒ½



# Configure study waves> ğŸ’¡ **æç¤º**: è¯¦ç»†çš„APIæ–‡æ¡£å’Œé«˜çº§åŠŸèƒ½è¯·æŸ¥çœ‹ [API Guide](./docs/api/README.md)

waves = [

    WaveConfig(### 1. A/B æµ‹è¯•

        wave_number=1,

        wave_name="Baseline",æ¯”è¾ƒä¸åŒç‰ˆæœ¬çš„å¹²é¢„æ•ˆæœï¼š

        questions=["What is your current stress level? (1-10)"],

        days_from_baseline=0```python

    ),from src import ABTestManager, Condition

    WaveConfig(

        wave_number=2,# å®šä¹‰æµ‹è¯•æ¡ä»¶

        wave_name="1 Month Follow-up",condition_a = Condition(

        questions=["What is your stress level now? (1-10)"],    name="ç‰ˆæœ¬A",

        days_from_baseline=30,    intervention_text="æ¯å¤©å†¥æƒ³10åˆ†é’Ÿå¯ä»¥é™ä½å‹åŠ›ã€‚",

        intervention_text="Practice 10 minutes of meditation daily"    questions=["æ‚¨ä¼šå°è¯•è¿™ä¸ªæ–¹æ³•å—ï¼Ÿ"]

    ))

]

condition_b = Condition(

# Run longitudinal study    name="ç‰ˆæœ¬B", 

config = LongitudinalStudyConfig(    intervention_text="ç ”ç©¶è¡¨æ˜ï¼Œæ¯å¤©å†¥æƒ³10åˆ†é’Ÿå¯ä»¥é™ä½30%çš„å‹åŠ›æ°´å¹³ã€‚",

    study_id="stress_study",    questions=["æ‚¨ä¼šå°è¯•è¿™ä¸ªæ–¹æ³•å—ï¼Ÿ"]

    study_name="Stress Intervention Study",)

    waves=waves

)# è¿è¡ŒA/Bæµ‹è¯•

ab_manager = ABTestManager()

engine = LongitudinalStudyEngine(llm_client)results = ab_manager.run_test([condition_a, condition_b], personas)

results = engine.run_study(personas, config)```

```

### 2. çºµå‘ç ”ç©¶ï¼ˆå¤šæ³¢æ¬¡è¿½è¸ªï¼‰

For detailed longitudinal study guide, see **[Longitudinal Study Guide](./docs/en/longitudinal/README.md)**

ä½¿ç”¨å¯¹è¯è®°å¿†å®ç°çœŸå®çš„çºµå‘è¿½è¸ªï¼š

### 3. Batch Persona Generation

```python

Generate virtual samples based on real demographic distributions:from src import LongitudinalStudyEngine, WaveConfig, LongitudinalStudyConfig



```python# é…ç½®ç ”ç©¶æ³¢æ¬¡

from src import PersonaGenerator, DistributionConfigwaves = [

    WaveConfig(

# Configure distribution        wave_number=1,

config = DistributionConfig(        wave_name="åŸºçº¿",

    age_distribution={        questions=["æ‚¨ç›®å‰çš„å‹åŠ›æ°´å¹³å¦‚ä½•ï¼Ÿ(1-10)"],

        "18-30": 0.3,        days_from_baseline=0

        "31-50": 0.4,    ),

        "51-70": 0.3    WaveConfig(

    },        wave_number=2,

    gender_distribution={        wave_name="1ä¸ªæœˆå",

        "Male": 0.48,        questions=["æ‚¨ç°åœ¨çš„å‹åŠ›æ°´å¹³å¦‚ä½•ï¼Ÿ(1-10)"],

        "Female": 0.52        days_from_baseline=30,

    }        intervention_text="æ¯å¤©ç»ƒä¹ 10åˆ†é’Ÿå†¥æƒ³"

)    )

]

# Generate 100 personas

generator = PersonaGenerator()# è¿è¡Œçºµå‘ç ”ç©¶

personas = generator.generate_batch(config = LongitudinalStudyConfig(

    count=100,    study_id="stress_study",

    distribution_config=config,    study_name="å‹åŠ›å¹²é¢„ç ”ç©¶",

    llm_client=client    waves=waves

))

```

engine = LongitudinalStudyEngine(llm_client)

### 4. Response Validationresults = engine.run_study(personas, config)

```

Automatically check response quality and consistency:

è¯¦ç»†çš„çºµå‘ç ”ç©¶æŒ‡å—è¯·æŸ¥çœ‹ **[Longitudinal Study Guide](./docs/longitudinal/README.md)**

```python

from src import ResponseValidator, ConsistencyChecker### 3. æ‰¹é‡äººç‰©ç”Ÿæˆ



validator = ResponseValidator()åŸºäºçœŸå®äººå£ç»Ÿè®¡åˆ†å¸ƒç”Ÿæˆè™šæ‹Ÿæ ·æœ¬ï¼š

checker = ConsistencyChecker()

```python

# Validate response formatfrom src import PersonaGenerator, DistributionConfig

is_valid = validator.validate_response(response, question_type)

# é…ç½®åˆ†å¸ƒ

# Check consistencyconfig = DistributionConfig(

metrics = checker.check_consistency(persona_responses)    age_distribution={

print(f"Consistency score: {metrics.consistency_score}")        "18-30": 0.3,

```        "31-50": 0.4,

        "51-70": 0.3

---    },

    gender_distribution={

## ğŸ“š API Documentation        "ç”·": 0.48,

        "å¥³": 0.52

### PersonaManager    }

)

```python

from src import PersonaManager# ç”Ÿæˆ100ä¸ªäººç‰©

generator = PersonaGenerator()

manager = PersonaManager()personas = generator.generate_batch(

    count=100,

# Add persona    distribution_config=config,

manager.add_persona(persona)    llm_client=client

)

# Get all personas```

personas = manager.get_all_personas()

### 5. å“åº”éªŒè¯

# Filter by criteria

young_adults = manager.filter_personas(è‡ªåŠ¨æ£€æŸ¥å“åº”è´¨é‡å’Œä¸€è‡´æ€§ï¼š

    age_range=(18, 30),

    gender="Female"```python

)from src import ResponseValidator, ConsistencyChecker



# Save/loadvalidator = ResponseValidator()

manager.save_to_file("personas.json")checker = ConsistencyChecker()

manager.load_from_file("personas.json")

```# éªŒè¯å“åº”æ ¼å¼

is_valid = validator.validate_response(response, question_type)

### SimulationEngine

# æ£€æŸ¥ä¸€è‡´æ€§

```pythonmetrics = checker.check_consistency(persona_responses)

from src import SimulationEngineprint(f"ä¸€è‡´æ€§å¾—åˆ†: {metrics.consistency_score}")

```

engine = SimulationEngine(

    llm_client=client,---

    cache=cache,

    checkpoint_manager=checkpoint_mgr## ğŸ“š API æ–‡æ¡£

)

### PersonaManager

# Run survey

result = engine.run_survey(```python

    personas=personas,from src import PersonaManager

    questions=questions,

    temperature=0.7,manager = PersonaManager()

    max_tokens=300

)# æ·»åŠ äººç‰©

manager.add_persona(persona)

# Run intervention

result = engine.run_intervention(# è·å–æ‰€æœ‰äººç‰©

    personas=personas,personas = manager.get_all_personas()

    intervention_text="Health intervention text",

    questions=followup_questions# æŒ‰æ¡ä»¶ç­›é€‰

)young_adults = manager.filter_personas(

```    age_range=(18, 30),

    gender="å¥³"

### ResultsStorage)



```python# ä¿å­˜/åŠ è½½

from src import ResultsStoragemanager.save_to_file("personas.json")

manager.load_from_file("personas.json")

storage = ResultsStorage()```



# Save result### SimulationEngine

storage.save_result(simulation_result)

```python

# Load resultsfrom src import SimulationEngine

results = storage.load_all_results()

engine = SimulationEngine(

# Export to CSV    llm_client=client,

storage.export_to_csv(result, "output.csv")    cache=cache,

    checkpoint_manager=checkpoint_mgr

# Export analysis script)

storage.export_analysis_script(result, "analysis.py", language="python")

```# è¿è¡Œè°ƒæŸ¥

result = engine.run_survey(

---    personas=personas,

    questions=questions,

## â“ FAQ    temperature=0.7,

    max_tokens=300

### Q: How many LLM API calls are needed?)



A: Call count = Number of personas Ã— Number of questions. For example:# è¿è¡Œå¹²é¢„

result = engine.run_intervention(

- 10 personas Ã— 9 questions = 90 calls    personas=personas,

- Caching can significantly reduce repeat calls    intervention_text="å¥åº·å¹²é¢„æ–‡æœ¬",

    questions=followup_questions

### Q: How long does simulation take?)

```

A: Depends on:

### ResultsStorage

- **Local model**: ~5-15 seconds/response

- **Online API**: ~1-3 seconds/response```python

- **Parallel execution**: Can reduce time by 50-80%from src import ResultsStorage



### Q: How reliable are the results?storage = ResultsStorage()



A: LLM simulation is an exploratory research tool, suitable for:# ä¿å­˜ç»“æœ

storage.save_result(simulation_result)

- âœ… Rapid prototyping

- âœ… Hypothesis generation# åŠ è½½ç»“æœ

- âœ… Questionnaire pre-testingresults = storage.load_all_results()

- âŒ **Cannot** replace real human research

# å¯¼å‡ºä¸ºCSV

### Q: How to improve response quality?storage.export_to_csv(result, "output.csv")



1. Create detailed, realistic persona backgrounds# å¯¼å‡ºåˆ†æè„šæœ¬

2. Use clear, specific questionsstorage.export_analysis_script(result, "analysis.py", language="python")

3. Choose appropriate temperature parameters```

4. Use more powerful models (e.g., GPT-4)

5. Enable response validation and consistency checks---



### Q: What about costs?## â“ å¸¸è§é—®é¢˜



- **Local LM Studio**: Completely free (requires GPU)### Q: éœ€è¦å¤šå°‘ LLM API è°ƒç”¨ï¼Ÿ

- **DeepSeek API**: ~$0.0001/1k tokens, extremely low cost

- **OpenAI GPT-3.5**: ~$0.002/1k tokensA: è°ƒç”¨æ¬¡æ•° = äººç‰©æ•°é‡ Ã— é—®é¢˜æ•°é‡ã€‚ä¾‹å¦‚ï¼š

- **OpenAI GPT-4**: ~$0.03/1k tokens- 10ä¸ªäººç‰© Ã— 9ä¸ªé—®é¢˜ = 90æ¬¡è°ƒç”¨

- ä½¿ç”¨ç¼“å­˜å¯å¤§å¹…å‡å°‘é‡å¤è°ƒç”¨

### Q: Is my data secure?

### Q: æ¨¡æ‹Ÿéœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

- Local mode: Data never leaves your machine

- API mode: Follows each provider's privacy policyA: å–å†³äºï¼š

- Recommendation: Use local mode for sensitive data- **æœ¬åœ°æ¨¡å‹**ï¼šçº¦ 5-15 ç§’/å“åº”

- **åœ¨çº¿API**ï¼šçº¦ 1-3 ç§’/å“åº”

---- **å¹¶è¡Œæ‰§è¡Œ**ï¼šå¯ç¼©çŸ­ 50-80% æ—¶é—´



## ğŸ¤ Contributing### Q: ç»“æœçš„å¯é æ€§å¦‚ä½•ï¼Ÿ



Contributions welcome! See [CONTRIBUTING.md](./docs/en/contributing/README.md) for details.A: LLMæ¨¡æ‹Ÿæ˜¯æ¢ç´¢æ€§ç ”ç©¶å·¥å…·ï¼Œé€‚åˆï¼š

- âœ… å¿«é€ŸåŸå‹æµ‹è¯•

### Development Setup- âœ… å‡è®¾ç”Ÿæˆ

- âœ… é—®å·é¢„æµ‹è¯•

```bash- âŒ **ä¸èƒ½**æ›¿ä»£çœŸå®äººç±»ç ”ç©¶

# Install development dependencies

pip install -r requirements-dev.txt### Q: å¦‚ä½•æé«˜å“åº”è´¨é‡ï¼Ÿ



# Run tests1. åˆ›å»ºè¯¦ç»†ã€çœŸå®çš„äººç‰©èƒŒæ™¯

pytest2. ä½¿ç”¨æ¸…æ™°ã€å…·ä½“çš„é—®é¢˜

3. é€‰æ‹©åˆé€‚çš„æ¸©åº¦å‚æ•°

# Code formatting4. ä½¿ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹ï¼ˆå¦‚ GPT-4ï¼‰

black src/ tests/5. å¯ç”¨å“åº”éªŒè¯å’Œä¸€è‡´æ€§æ£€æŸ¥

isort src/ tests/

### Q: æˆæœ¬å¦‚ä½•ï¼Ÿ

# Type checking

mypy src/- **æœ¬åœ°LM Studio**ï¼šå®Œå…¨å…è´¹ï¼ˆéœ€è¦GPUï¼‰

```- **DeepSeek API**ï¼š~0.001å…ƒ/åƒtokenï¼Œæä½æˆæœ¬

- **OpenAI GPT-3.5**ï¼š~0.015å…ƒ/åƒtoken

### Report Issues- **OpenAI GPT-4**ï¼š~0.3å…ƒ/åƒtoken



Found a bug or have a feature suggestion? Please [create an issue](https://github.com/jason-jj-li/auto_sim_ai/issues).### Q: æ•°æ®å®‰å…¨å—ï¼Ÿ



---- æœ¬åœ°æ¨¡å¼ï¼šæ•°æ®å®Œå…¨ä¸å‡ºæœ¬åœ°

- APIæ¨¡å¼ï¼šéµå¾ªå„æä¾›å•†çš„éšç§æ”¿ç­–

## ğŸ“„ License- å»ºè®®ï¼šæ•æ„Ÿæ•°æ®ä½¿ç”¨æœ¬åœ°æ¨¡å¼



This project is licensed under the MIT License. See [LICENSE](LICENSE) file for details.---



---## ğŸ¤ è´¡çŒ®



## ğŸ™ Acknowledgmentsæ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£è¯¦æƒ…ã€‚



- [Streamlit](https://streamlit.io/) - Excellent Python web framework### å¼€å‘è®¾ç½®

- [LM Studio](https://lmstudio.ai/) - Local LLM runtime environment

- [OpenAI](https://openai.com/) - API standards```bash

- [DeepSeek](https://www.deepseek.com/) - Cost-effective LLM service# å®‰è£…å¼€å‘ä¾èµ–

pip install -r requirements-dev.txt

---

# è¿è¡Œæµ‹è¯•

## ğŸ“ Contactpytest



- **Maintainer**: Jason Li# ä»£ç æ ¼å¼åŒ–

- **GitHub**: [@jason-jj-li](https://github.com/jason-jj-li)black src/ tests/

- **Email**: [Contact via GitHub Issues]isort src/ tests/



---# ç±»å‹æ£€æŸ¥

mypy src/

<div align="center">```



**â­ If this project helps you, please give it a star!**### æŠ¥å‘Šé—®é¢˜



Made with â¤ï¸ by Jason Liå‘ç° Bug æˆ–æœ‰åŠŸèƒ½å»ºè®®ï¼Ÿè¯·[åˆ›å»º Issue](https://github.com/jason-jj-li/auto_sim_ai/issues)ã€‚



</div>---


## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

## ğŸ™ è‡´è°¢

- [Streamlit](https://streamlit.io/) - ä¼˜ç§€çš„Python Webæ¡†æ¶
- [LM Studio](https://lmstudio.ai/) - æœ¬åœ°LLMè¿è¡Œç¯å¢ƒ
- [OpenAI](https://openai.com/) - APIæ ‡å‡†
- [DeepSeek](https://www.deepseek.com/) - é«˜æ€§ä»·æ¯”LLMæœåŠ¡

---

## ğŸ“ è”ç³»æ–¹å¼

- **ç»´æŠ¤è€…**: Jason Li
- **GitHub**: [@jason-jj-li](https://github.com/jason-jj-li)
- **Email**: [é€šè¿‡GitHub Issuesè”ç³»]

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸€ä¸ªæ˜Ÿæ ‡ï¼**

Made with â¤ï¸ by Jason Li

</div>
