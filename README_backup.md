# Auto Sim AI - LLM Survey Simulation System


<div align="center">



**English Version | [ä¸­æ–‡ç‰ˆ](./README_zh.md)**<div align="center">



---



ğŸ”¬ **AI-Powered Survey and Intervention Simulation System****English Version | [ä¸­æ–‡ç‰ˆ](./README_zh.md)**<div align="center"><div align="right">



Simulate real survey research and intervention effects using LLM-driven virtual personas



ğŸ“– **[View Complete English Documentation](./docs/en/README.md)**---



[Quick Start](./docs/en/quickstart/README.md) â€¢

[Features](#features) â€¢

[API Reference](./docs/en/api/README.md) â€¢ğŸ”¬ **AI-Powered Survey and Intervention Simulation System****English Version | [ä¸­æ–‡ç‰ˆ](./README_zh.md)**[![English](https://img.shields.io/badge/docs-English-blue?style=flat-square)](./docs/en/README.md)

[Contributing](./docs/en/contributing/README.md)



</div>

Simulate real survey research and intervention effects using LLM-driven virtual personas[![ä¸­æ–‡æ–‡æ¡£](https://img.shields.io/badge/æ–‡æ¡£-ä¸­æ–‡-red?style=flat-square)](./docs/zh/README.md)

---



## ğŸ“‹ Table of Contents

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)---

- [Overview](#overview)

- [Features](#features)[![Streamlit](https://img.shields.io/badge/streamlit-1.32.0-FF4B4B.svg)](https://streamlit.io)

- [Quick Start](#quick-start)

- [User Guide](#user-guide)[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)</div>

- [ğŸ“š Complete Documentation](./docs/README.md)

  - [Quick Start Guide](./docs/quickstart/README.md)

  - [API Documentation](./docs/api/README.md)

  - [Architecture Design](./docs/architecture/README.md)ğŸ“– **[Complete English Documentation](./docs/en/README.md)**ğŸ”¬ **AI-Powered Survey and Intervention Simulation System**

  - [Longitudinal Studies Guide](./docs/longitudinal/README.md)

  - [Contributing Guide](./docs/contributing/README.md)

- [FAQ](#faq)

- [License](#license)[Quick Start](#-quick-start) â€¢<div align="center">



---[Features](#-features) â€¢



## ğŸ¯ Overview[API Reference](./docs/en/api/README.md) â€¢Simulate real survey research and intervention effects using LLM-driven virtual personas



**LLM Simulation Survey System** is an innovative research tool that leverages Large Language Models (LLMs) to generate virtual personas that simulate real human responses to surveys and interventions.[Contributing](./docs/en/contributing/README.md)



### Use Cases**Language / è¯­è¨€:** [English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)



- ğŸ¥ **Health Intervention Research** - Test the impact of health messaging on different populations</div>

- ğŸ“Š **Market Research** - Rapidly evaluate user feedback for products or services

- ğŸ“ **Educational Research** - Assess teaching method effectiveness across different learner types[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

- ğŸ’¡ **Policy Analysis** - Predict potential policy impacts on diverse populations

- ğŸ§ª **A/B Testing** - Compare effectiveness across different approaches---

- ğŸ“ˆ **Prototype Validation** - Rapidly iterate designs before real-world research

[![Streamlit](https://img.shields.io/badge/streamlit-1.32.0-FF4B4B.svg)](https://streamlit.io)---

### Core Advantages

## ğŸ“‹ Table of Contents

âœ… **Fast Iteration** - Complete survey simulations with hundreds of participants in minutes  

âœ… **Cost-Effective** - No need to recruit real participants  [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

âœ… **Reproducible** - Precise variable control ensures experimental repeatability  

âœ… **Diverse** - Easily create virtual personas with varied backgrounds, ages, and cultures  - [Overview](#-overview)

âœ… **Deep Insights** - Obtain detailed qualitative and quantitative data  

âœ… **Flexible Deployment** - Support for local deployment and cloud API- [Features](#-features)## English



---- [Quick Start](#-quick-start)



## ğŸš€ Features- [User Guide](#-user-guide)ğŸ“– **[View Full English Documentation](./docs/en/README.md)**



### Core Capabilities- [Architecture](#-architecture)



#### 1ï¸âƒ£ Virtual Persona Management- [Advanced Features](#-advanced-features)ğŸ”¬ **AI-Powered Survey and Intervention Simulation System**



- **Rich Persona Attributes**: Age, gender, occupation, education, personality traits, values, etc.- [API Documentation](#-api-documentation)

- **Batch Creation**: Auto-generate virtual samples matching real population distributions using demographic statistics

- **CSV Import/Export**: Bulk import personas from Excel or databases- [FAQ](#-faq)[Quick Start](#quick-start) â€¢

- **Demo Templates**: Built-in typical persona templates, ready to use

- [Contributing](#-contributing)

#### 2ï¸âƒ£ Multiple Simulation Modes

- [License](#-license)[Features](#features) â€¢Simulate real survey research and intervention effects using LLM-driven virtual personas

- **Survey Mode**: Run standardized questionnaires (PHQ-9, GAD-7, etc.)

- **Intervention Mode**: Test health messaging, advertising copy, etc. on different populations

- **A/B Testing**: Test multiple versions simultaneously and compare effectiveness

- **Longitudinal Studies**: Simulate multi-wave surveys to track changes over time---[API Reference](./docs/en/api/README.md) â€¢

- **Sensitivity Analysis**: Systematically test how parameter changes affect results



#### 3ï¸âƒ£ LLM Integration

## ğŸ¯ Overview[Contributing](./docs/en/contributing/README.md)[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

- **Local Deployment**: LM Studio (free, completely private)

- **Commercial APIs**:

  - DeepSeek (cost-effective, Chinese-optimized)

  - OpenAI (GPT-4, GPT-3.5)**Auto Sim AI** is an innovative research tool that leverages Large Language Models (LLMs) to generate virtual personas that simulate real human responses to surveys and interventions.[![Streamlit](https://img.shields.io/badge/streamlit-1.32.0-FF4B4B.svg)](https://streamlit.io)

  - Other OpenAI-compatible services

- **Flexible Switching**: Change models or providers anytime



#### 4ï¸âƒ£ Advanced Analysis### Use Cases</div>[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)



- **Auto-Scoring**: Built-in automatic scoring system for standardized scales

- **Statistical Analysis**: Descriptive statistics, correlation analysis, group comparisons

- **Consistency Checks**: Validate internal consistency and logic of responses- ğŸ¥ **Health Intervention Research** - Test health messaging impact on different populations

- **Visualization**: Interactive charts, word clouds, distribution plots

- **Export Functions**: CSV, JSON, Python/R analysis scripts- ğŸ“Š **Market Research** - Rapidly evaluate product/service user feedback



#### 5ï¸âƒ£ Performance Optimization- ğŸ“ **Educational Research** - Assess teaching method effectiveness across learner types---ğŸ“– **[View Full English Documentation](./docs/en/README.md)**



- **Parallel Execution**: Async processing for multiple persona responses- ğŸ’¡ **Policy Analysis** - Predict policy impact on diverse populations

- **Smart Caching**: Avoid redundant LLM calls, save time and cost

- **Checkpoint Resume**: Support pausing and resuming large-scale simulations- ğŸ§ª **A/B Testing** - Compare effectiveness of different approaches

- **Progress Tracking**: Real-time progress display and estimated completion time

- ğŸ“ˆ **Prototype Validation** - Rapidly iterate designs before real-world research

---

## ğŸ“‹ Table of Contents[Quick Start](./docs/en/quickstart/README.md) â€¢

## âš¡ Quick Start

### Key Advantages

### System Requirements

[Features](#features-en) â€¢

- **Python**: 3.8 or higher

- **Memory**: 8GB+ recommendedâœ… **Fast Iteration** - Complete hundreds of survey simulations in minutes  

- **LLM Provider** (choose one):

  - LM Studio (local, free)âœ… **Cost-Effective** - No need to recruit real participants  - [Overview](#overview)[API Reference](./docs/en/api/README.md) â€¢

  - DeepSeek/OpenAI API key

âœ… **Reproducible** - Precise variable control ensures repeatability  

### Installation Steps

âœ… **Diverse** - Easily create personas with varied backgrounds, ages, cultures  - [Features](#features)[Contributing](./docs/en/contributing/README.md)

#### 1. Clone Repository

âœ… **Deep Insights** - Obtain detailed qualitative and quantitative data  

```bash

git clone https://github.com/jason-jj-li/auto_sim_ai.gitâœ… **Flexible Deployment** - Support for local and cloud API deployments- [Quick Start](#quick-start)

cd auto_sim_ai

```



#### 2. Install Dependencies---- [User Guide](#user-guide)### Features (EN)



```bash

# Create virtual environment (recommended)

python -m venv venv## ğŸš€ Features- [ğŸ“š Complete Documentation](./docs/en/README.md)

source venv/bin/activate  # Windows: venv\Scripts\activate



# Install dependencies

pip install -r requirements.txt### Core Capabilities  - [Quick Start Guide](./docs/en/quickstart/README.md)- **Three Research Modes**: Survey Testing, Message Testing, A/B Testing

```



Or use the setup script:

#### 1. Virtual Persona Management  - [API Documentation](./docs/en/api/README.md)- **Longitudinal Studies**: Multi-wave research with persona memory

```bash

chmod +x setup.sh

./setup.sh

```- **Rich Attributes**: Age, gender, occupation, education, personality traits, values, etc.  - [Architecture Design](./docs/en/architecture/README.md)- **Async Processing**: High-performance parallel simulations



#### 3. Configure LLM- **Batch Creation**: Auto-generate samples matching real population distributions



**Option A: Local LM Studio (Recommended for Learning and Development)**- **CSV Import/Export**: Bulk import personas from Excel or databases  - [Longitudinal Studies](./docs/en/longitudinal/README.md)- **Flexible LLM Support**: Local (LM Studio) or API (DeepSeek, OpenAI)



1. Download [LM Studio](https://lmstudio.ai/)- **Demo Templates**: Built-in templates for common persona types, ready to use

2. Download a model in LM Studio:

   - Recommended: `mistral-7b-instruct`, `llama-2-7b-chat`  - [Contributing Guide](./docs/en/contributing/README.md)- **Web Interface**: User-friendly Streamlit UI

   - Minimum: 7B parameter model

3. Start local server:#### 2. Multiple Simulation Modes

   - Click "Local Server" tab

   - Select model- [FAQ](#faq)- **Complete Data Export**: CSV, JSON formats for statistical analysis

   - Click "Start Server"

   - Confirm address is `http://localhost:1234`- **Survey Mode**: Run standardized questionnaires (PHQ-9, GAD-7, etc.)



**Option B: Online API (Recommended for Production)**- **Intervention Mode**: Test health messages, ad copy, etc. on different populations- [License](#license)



```bash- **A/B Testing**: Test multiple versions simultaneously and compare effects

# Copy environment template

cp env.example .env- **Longitudinal Studies**: Multi-wave research to track changes over time### Quick Start (EN)



# Edit .env file and add API key- **Sensitivity Analysis**: Systematically test parameter impact on results

# DEEPSEEK_API_KEY=your_api_key_here

# or---

# OPENAI_API_KEY=your_api_key_here

```#### 3. LLM Integration



#### 4. Launch Application```bash



```bash- **Local Deployment**: LM Studio (free, completely private)

streamlit run app.py

```- **Commercial APIs**:## ğŸ¯ Overviewgit clone https://github.com/jason-jj-li/auto_sim_ai.git



The app will automatically open in your browser: `http://localhost:8501`  - DeepSeek (cost-effective, Chinese-optimized)



### First-Time User Guide  - OpenAI (GPT-4, GPT-3.5)cd auto_sim_ai



1. **Connect LLM** (Home Page)  - Other OpenAI-compatible services

   - Select LLM provider

   - Test connection- **Flexible Switching**: Change models or providers anytime**Auto Sim AI** is an innovative research tool that leverages Large Language Models (LLMs) to generate virtual personas that simulate real human responses to surveys and interventions../setup.sh

   - Wait for "System Ready" message



2. **Create Virtual Personas** (Setup Page)

   - Click "Create Demo Personas" for quick start#### 4. Advanced Analysisstreamlit run app.py

   - Or manually create custom personas

   - Or upload CSV for bulk import



3. **Run Simulation** (Simulation Page)- **Auto-Scoring**: Built-in scoring for standardized scales### Use Cases```

   - Choose simulation type (Survey/Intervention)

   - Select personas to participate- **Statistical Analysis**: Descriptive stats, correlation, group comparisons

   - Choose questionnaire template or enter custom questions

   - Click "Run Simulation"- **Consistency Checks**: Validate response internal consistency and logic



4. **View Results** (Results Page)- **Visualization**: Interactive charts, word clouds, distributions

   - Browse response data

   - View statistical analysis- **Export Features**: CSV, JSON, Python/R analysis scripts- ğŸ¥ **Health Intervention Research** - Test health messaging impact on different populationsğŸ“˜ **[Complete English Documentation â†’](./docs/en/README.md)**

   - Export results for further analysis



---

#### 5. Performance Optimization- ğŸ“Š **Market Research** - Rapidly evaluate product/service user feedback

## ğŸ“– User Guide



### Persona Design Best Practices

- **Parallel Execution**: Async processing for multiple persona responses- ğŸ“ **Educational Research** - Assess teaching method effectiveness across learner types---

#### Creating High-Quality Personas

- **Smart Caching**: Avoid redundant LLM calls, save time and cost

```python

# Good Example: Specific, detailed, realistic- **Resume Capability**: Pause and resume large-scale simulations- ğŸ’¡ **Policy Analysis** - Predict policy impact on diverse populations

{

    "name": "Li Ming",- **Progress Tracking**: Real-time progress and estimated completion time

    "age": 32,

    "gender": "Male",- ğŸ§ª **A/B Testing** - Compare effectiveness of different approaches## ä¸­æ–‡

    "occupation": "Software Engineer at Startup",

    "education": "Bachelor's in Computer Science",---

    "location": "Beijing",

    "background": "Works at a fast-growing tech company, often works overtime. Recently feeling work stress and declining sleep quality. Enjoys relieving stress through exercise but often too busy to do so.",- ğŸ“ˆ **Prototype Validation** - Rapidly iterate designs before real-world research

    "personality_traits": ["Perfectionist", "Strong sense of responsibility", "Somewhat anxious"],

    "values": ["Career development", "Work-life balance", "Family health"]## âš¡ Quick Start

}

ğŸ”¬ **åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è°ƒæŸ¥ä¸å¹²é¢„æ¨¡æ‹Ÿç³»ç»Ÿ**

# Bad Example: Vague, generic

{### System Requirements

    "name": "John Doe",

    "age": 30,### Key Advantages

    "gender": "Male",

    "occupation": "Engineer",- **Python**: 3.8 or higher

    "background": "Regular person",

    "personality_traits": ["Normal"],- **Memory**: 8GB+ recommendedä½¿ç”¨ AI é©±åŠ¨çš„è™šæ‹Ÿäººç‰©æ¨¡æ‹ŸçœŸå®çš„è°ƒæŸ¥ç ”ç©¶å’Œå¹²é¢„æ•ˆæœ

    "values": ["Happiness"]

}- **LLM Provider** (choose one):

```

  - LM Studio (local, free)âœ… **Fast Iteration** - Complete hundreds of survey simulations in minutes  

#### Persona Diversity

  - DeepSeek/OpenAI API key

Ensure virtual samples reflect real population diversity:

âœ… **Cost-Effective** - No need to recruit real participants  ğŸ“— **[æŸ¥çœ‹å®Œæ•´ä¸­æ–‡æ–‡æ¡£](./docs/zh/README.md)**

- **Age**: Cover different age groups (18-80 years)

- **Gender**: Male, female, non-binary### Installation Steps

- **Occupation**: Different industries and job levels

- **Education**: High school to graduate degreesâœ… **Reproducible** - Precise variable control ensures repeatability  

- **Geography**: Urban, rural, different regions

- **Cultural Background**: Different ethnicities, religions, cultural traditions#### Step 1: Clone Repository



### Questionnaire Design Tipsâœ… **Diverse** - Easily create personas with varied backgrounds, ages, cultures  [å¿«é€Ÿå¼€å§‹](./docs/zh/quickstart/README.md) â€¢



#### Good Question Characteristics```bash



âœ… **Clear and Specific**git clone https://github.com/jason-jj-li/auto_sim_ai.gitâœ… **Deep Insights** - Obtain detailed qualitative and quantitative data  [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§) â€¢



```cd auto_sim_ai

Good: In the past two weeks, how many days have you felt down or depressed?

Bad: How have you been feeling lately?```âœ… **Flexible Deployment** - Support for local and cloud API deployments[API å‚è€ƒ](./docs/zh/api/README.md) â€¢

```



âœ… **Avoid Compound Questions**

#### Step 2: Install Dependencies[è´¡çŒ®æŒ‡å—](./docs/zh/contributing/README.md)

```

Good: How many times per week do you exercise? How long is each exercise session?

Bad: How often do you exercise, for how long, and at what intensity?

```**Option A: Automated Setup (Recommended)**---



âœ… **Use Standardized Scales**



``````bash</div>

Never(0) - Sometimes(1) - Often(2) - Always(3)

```chmod +x setup.sh



#### Use Built-in Templates./setup.sh## ğŸš€ Features



The system includes multiple validated standardized scales:```



- **PHQ-9**: Depression screening scale---

- **GAD-7**: Anxiety screening scale

- **PSS-10**: Perceived Stress Scale**Option B: Manual Installation**

- More templates continuously being added...

### Core Capabilities

### Simulation Settings Optimization

```bash

#### Temperature Parameter

# Create virtual environment## ğŸ“‹ ç›®å½•

Controls response randomness and creativity:

python -m venv venv

- **0.0 - 0.3**: High consistency, suitable for standardized responses

- **0.5 - 0.7**: Balanced mode, recommended for most surveys (default)source venv/bin/activate  # Windows: venv\Scripts\activate#### 1ï¸âƒ£ Virtual Persona Management

- **0.8 - 1.0**: More diverse, suitable for exploratory research and creative testing



#### Max Tokens

# Install dependencies- [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)

- **150-300**: Short answers (multiple choice, scale ratings)

- **300-500**: Medium length (short answer questions)pip install -r requirements.txt

- **500-1000**: Detailed responses (open-ended questions, in-depth interviews)

```- **Rich Attributes**: Age, gender, occupation, education, personality traits, values, etc.- [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§)

#### Parallel Settings



- **Small Scale** (<10 personas): Concurrency 2-3

- **Medium Scale** (10-50 personas): Concurrency 5-10#### Step 3: Configure LLM- **Batch Creation**: Auto-generate samples matching real population distributions- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)

- **Large Scale** (50+ personas): Concurrency 10-15 (watch API rate limits)



---

**Option A: Local LM Studio (Recommended for Learning)**- **CSV Import/Export**: Bulk import personas from Excel or databases- [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)

## ğŸ—ï¸ Architecture Design



For detailed architecture documentation, see **[Architecture Guide](./docs/architecture/README.md)**

1. Download [LM Studio](https://lmstudio.ai/)- **Demo Templates**: Built-in templates for common persona types, ready to use- [ğŸ“š å®Œæ•´æ–‡æ¡£](./docs/README.md)

### Project Structure

2. Download a model in LM Studio:

```

auto_sim_ai/   - Recommended: `mistral-7b-instruct`, `llama-2-7b-chat`  - [å¿«é€Ÿå¼€å§‹æŒ‡å—](./docs/quickstart/README.md)

â”œâ”€â”€ app.py                      # Streamlit main application

â”œâ”€â”€ pages/                      # Multi-page application   - Minimum: 7B parameter model

â”‚   â”œâ”€â”€ 1_Setup.py             # Persona management page

â”‚   â”œâ”€â”€ 2_Simulation.py        # Simulation execution page3. Start local server:#### 2ï¸âƒ£ Multiple Simulation Modes  - [APIæ–‡æ¡£](./docs/api/README.md)

â”‚   â””â”€â”€ 3_Results.py           # Results analysis page

â”œâ”€â”€ src/                        # Core modules   - Click "Local Server" tab

â”‚   â”œâ”€â”€ llm_client.py          # LLM client (sync/async)

â”‚   â”œâ”€â”€ persona.py             # Persona management   - Select model  - [æ¶æ„è®¾è®¡](./docs/architecture/README.md)

â”‚   â”œâ”€â”€ simulation.py          # Simulation engine (single-thread/parallel)

â”‚   â”œâ”€â”€ storage.py             # Results storage   - Click "Start Server"

â”‚   â”œâ”€â”€ cache.py               # Response cache

â”‚   â”œâ”€â”€ checkpoint.py          # Checkpoint management   - Confirm address is `http://localhost:1234`- **Survey Mode**: Run standardized questionnaires (PHQ-9, GAD-7, etc.)  - [çºµå‘ç ”ç©¶æŒ‡å—](./docs/longitudinal/README.md)

â”‚   â”œâ”€â”€ scoring.py             # Auto-scoring

â”‚   â”œâ”€â”€ ab_testing.py          # A/B testing

â”‚   â”œâ”€â”€ intervention_study.py  # Intervention studies (legacy)

â”‚   â”œâ”€â”€ longitudinal_study.py  # Longitudinal studies (new, recommended)**Option B: Online API (Recommended for Production)**- **Intervention Mode**: Test health messages, ad copy, etc. on different populations  - [è´¡çŒ®æŒ‡å—](./docs/contributing/README.md)

â”‚   â”œâ”€â”€ persona_generator.py   # Persona generator

â”‚   â”œâ”€â”€ survey_templates.py    # Survey template library

â”‚   â”œâ”€â”€ survey_config.py       # Survey configuration

â”‚   â”œâ”€â”€ tools.py               # Tool registration system```bash- **A/B Testing**: Test multiple versions simultaneously and compare effects- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

â”‚   â”œâ”€â”€ ui_components.py       # UI components

â”‚   â”œâ”€â”€ styles.py              # Design system# Copy environment template

â”‚   â””â”€â”€ validators.py          # Input validation

â”œâ”€â”€ tests/                      # Test suitecp env.example .env- **Longitudinal Studies**: Multi-wave research to track changes over time- [è®¸å¯è¯](#è®¸å¯è¯)

â”œâ”€â”€ data/                       # Data directory

â”‚   â”œâ”€â”€ personas/              # Persona data

â”‚   â”œâ”€â”€ results/               # Simulation results

â”‚   â”œâ”€â”€ cache/                 # Cache data# Edit .env file and add your API key- **Sensitivity Analysis**: Systematically test parameter impact on results

â”‚   â”œâ”€â”€ checkpoints/           # Checkpoints

â”‚   â””â”€â”€ survey_configs/        # Survey configurations# DEEPSEEK_API_KEY=your_api_key_here

â”œâ”€â”€ docs/                       # Documentation

â”œâ”€â”€ requirements.txt            # Dependencies# or---

â””â”€â”€ pytest.ini                 # Test configuration

```# OPENAI_API_KEY=your_api_key_here



### Core Module Descriptions```#### 3ï¸âƒ£ LLM Integration



#### LLM Client (`llm_client.py`)



Supports both synchronous and asynchronous modes:#### Step 4: Launch Application## ğŸ¯ é¡¹ç›®ç®€ä»‹



- **LMStudioClient**: Sync client, suitable for simple scenarios

- **AsyncLLMClient**: Async client, supports high concurrency

```bash- **Local Deployment**: LM Studio (free, completely private)

Compatible with OpenAI API format, seamless switching between providers.

streamlit run app.py

#### Simulation Engine (`simulation.py`)

```- **Commercial APIs**:**LLM Simulation Survey System** æ˜¯ä¸€ä¸ªåˆ›æ–°çš„ç ”ç©¶å·¥å…·ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆè™šæ‹Ÿäººç‰©ï¼ˆPersonasï¼‰ï¼Œæ¨¡æ‹ŸçœŸå®äººç¾¤å¯¹è°ƒæŸ¥é—®å·å’Œå¹²é¢„æªæ–½çš„å“åº”ã€‚

- **SimulationEngine**: Base engine, sequential execution

- **ParallelSimulationEngine**: Parallel engine, supports async batch processing



Automatically handles error retry, progress tracking, and result aggregation.The app will automatically open in your browser at: `http://localhost:8501`  - DeepSeek (cost-effective, Chinese-optimized)



#### Cache System (`cache.py`)



Content-hash based smart caching:### First-Time User Guide  - OpenAI (GPT-4, GPT-3.5)### é€‚ç”¨åœºæ™¯



- Same persona + same question = directly return cached result

- Support cache export and import

- Significantly reduce LLM API call costs**1. Connect LLM (Home Page)**  - Other OpenAI-compatible services



#### Scoring System (`scoring.py`)   - Select your LLM provider



Automated scoring features:   - Test the connection- **Flexible Switching**: Change models or providers anytime- ğŸ¥ **å¥åº·å¹²é¢„ç ”ç©¶** - æµ‹è¯•å¥åº·ä¿¡æ¯å¯¹ä¸åŒäººç¾¤çš„å½±å“



- Support multiple standardized scales   - Wait for "System Ready" message

- Configurable custom scoring rules

- Auto-calculate total and subscale scores- ğŸ“Š **å¸‚åœºè°ƒç ”** - å¿«é€Ÿè¯„ä¼°äº§å“æˆ–æœåŠ¡çš„ç”¨æˆ·åé¦ˆ



---**2. Create Virtual Personas (Setup Page)**



## ğŸ”¬ Advanced Features   - Click "Create Demo Personas" for quick start#### 4ï¸âƒ£ Advanced Analysis- ğŸ“ **æ•™è‚²ç ”ç©¶** - è¯„ä¼°æ•™å­¦æ–¹æ³•å¯¹ä¸åŒå­¦ä¹ è€…çš„æ•ˆæœ



> ğŸ’¡ **Tip**: For detailed API documentation and advanced features, see [API Guide](./docs/api/README.md)   - Or manually create custom personas



### 1. A/B Testing   - Or upload CSV for bulk import- ğŸ’¡ **æ”¿ç­–åˆ†æ** - é¢„æµ‹æ”¿ç­–å¯¹å¤šå…ƒç¾¤ä½“çš„æ½œåœ¨å½±å“



Compare intervention effectiveness across different versions:



```python**3. Run Simulation (Simulation Page)**- **Auto-Scoring**: Built-in scoring for standardized scales- ğŸ§ª **A/B æµ‹è¯•** - æ¯”è¾ƒä¸åŒæ–¹æ¡ˆçš„æ•ˆæœå·®å¼‚

from src import ABTestManager, Condition

   - Choose simulation type (Survey/Intervention/A/B Test)

# Define test conditions

condition_a = Condition(   - Select personas to participate- **Statistical Analysis**: Descriptive stats, correlation, group comparisons- ğŸ“ˆ **åŸå‹éªŒè¯** - åœ¨çœŸå®è°ƒç ”å‰å¿«é€Ÿè¿­ä»£è®¾è®¡

    name="Version A",

    intervention_text="Meditating 10 minutes daily can reduce stress.",   - Choose questionnaire template or enter custom questions

    questions=["Would you try this method?"]

)   - Click "Run Simulation"- **Consistency Checks**: Validate response internal consistency and logic



condition_b = Condition(

    name="Version B", 

    intervention_text="Research shows that meditating 10 minutes daily can reduce stress levels by 30%.",**4. View Results (Results Page)**- **Visualization**: Interactive charts, word clouds, distributions### æ ¸å¿ƒä¼˜åŠ¿

    questions=["Would you try this method?"]

)   - Browse response data



# Run A/B test   - View statistical analysis- **Export Features**: CSV, JSON, Python/R analysis scripts

ab_manager = ABTestManager()

results = ab_manager.run_test([condition_a, condition_b], personas)   - Export results for further analysis

```

âœ… **å¿«é€Ÿè¿­ä»£** - å‡ åˆ†é’Ÿå†…å®Œæˆæ•°ç™¾äººçš„è°ƒæŸ¥æ¨¡æ‹Ÿ  

### 2. Longitudinal Studies (Multi-Wave Tracking)

---

Implement realistic longitudinal tracking using conversation memory:

#### 5ï¸âƒ£ Performance Optimizationâœ… **æˆæœ¬ä½å»‰** - æ— éœ€æ‹›å‹ŸçœŸå®å‚ä¸è€…  

```python

from src import LongitudinalStudyEngine, WaveConfig, LongitudinalStudyConfig## ğŸ“– User Guide



# Configure study wavesâœ… **å¯é‡å¤æ€§** - ç²¾ç¡®æ§åˆ¶å˜é‡ï¼Œç¡®ä¿å®éªŒå¯é‡å¤  

waves = [

    WaveConfig(### Persona Design Best Practices

        wave_number=1,

        wave_name="Baseline",- **Parallel Execution**: Async processing for multiple persona responsesâœ… **å¤šæ ·åŒ–** - è½»æ¾åˆ›å»ºä¸åŒèƒŒæ™¯ã€å¹´é¾„ã€æ–‡åŒ–çš„è™šæ‹Ÿäººç‰©  

        questions=["What is your current stress level? (1-10)"],

        days_from_baseline=0#### Creating High-Quality Personas

    ),

    WaveConfig(- **Smart Caching**: Avoid redundant LLM calls, save time and costâœ… **æ·±åº¦æ´å¯Ÿ** - è·å¾—è¯¦ç»†çš„è´¨æ€§å’Œé‡åŒ–æ•°æ®  

        wave_number=2,

        wave_name="1 Month Follow-up",**Good Example: Specific, detailed, realistic**

        questions=["What is your stress level now? (1-10)"],

        days_from_baseline=30,- **Resume Capability**: Pause and resume large-scale simulationsâœ… **çµæ´»éƒ¨ç½²** - æ”¯æŒæœ¬åœ°è¿è¡Œå’Œäº‘ç«¯API

        intervention_text="Practice 10 minutes of meditation daily"

    )```python

]

{- **Progress Tracking**: Real-time progress and estimated completion time

# Run longitudinal study

config = LongitudinalStudyConfig(    "name": "Sarah Chen",

    study_id="stress_study",

    study_name="Stress Intervention Study",    "age": 32,---

    waves=waves

)    "gender": "Female",



engine = LongitudinalStudyEngine(llm_client)    "occupation": "Software Engineer at startup",---

results = engine.run_study(personas, config)

```    "education": "Bachelor's in Computer Science",



For detailed longitudinal study guide, see **[Longitudinal Study Guide](./docs/longitudinal/README.md)**    "location": "San Francisco, CA",## ğŸš€ åŠŸèƒ½ç‰¹æ€§



### 3. Batch Persona Generation    "background": "Works at a fast-growing tech company, often works overtime. Recently experiencing work stress and sleep quality decline. Likes to relieve stress through exercise but often too busy.",



Generate virtual samples based on real demographic distributions:    "personality_traits": ["Perfectionist", "Strong sense of responsibility", "Somewhat anxious"],## âš¡ Quick Start



```python    "values": ["Career development", "Work-life balance", "Family health"]

from src import PersonaGenerator, DistributionConfig

}### æ ¸å¿ƒåŠŸèƒ½

# Configure distribution

config = DistributionConfig(```

    age_distribution={

        "18-30": 0.3,### System Requirements

        "31-50": 0.4,

        "51-70": 0.3**Bad Example: Vague, generic**

    },

    gender_distribution={#### 1ï¸âƒ£ è™šæ‹Ÿäººç‰©ç®¡ç†

        "Male": 0.48,

        "Female": 0.52```python

    }

){- **Python**: 3.8 or higher- **ä¸°å¯Œçš„äººç‰©å±æ€§**ï¼šå¹´é¾„ã€æ€§åˆ«ã€èŒä¸šã€æ•™è‚²èƒŒæ™¯ã€æ€§æ ¼ç‰¹å¾ã€ä»·å€¼è§‚ç­‰



# Generate 100 personas    "name": "John Doe",

generator = PersonaGenerator()

personas = generator.generate_batch(    "age": 30,- **Memory**: 8GB+ recommended- **æ‰¹é‡åˆ›å»º**ï¼šä½¿ç”¨äººå£ç»Ÿè®¡åˆ†å¸ƒè‡ªåŠ¨ç”Ÿæˆç¬¦åˆçœŸå®äººå£çš„è™šæ‹Ÿæ ·æœ¬

    count=100,

    distribution_config=config,    "gender": "Male",

    llm_client=client

)    "occupation": "Engineer",- **LLM Provider** (choose one):- **CSV å¯¼å…¥/å¯¼å‡º**ï¼šæ”¯æŒä»Excelæˆ–æ•°æ®åº“æ‰¹é‡å¯¼å…¥äººç‰©

```

    "background": "Regular person",

### 4. Response Validation

    "personality_traits": ["Normal"],  - LM Studio (local, free)- **æ¼”ç¤ºæ¨¡æ¿**ï¼šå†…ç½®å¤šç§å…¸å‹äººç‰©æ¨¡æ¿ï¼Œå³å¼€å³ç”¨

Automatically check response quality and consistency:

    "values": ["Happiness"]

```python

from src import ResponseValidator, ConsistencyChecker}  - DeepSeek/OpenAI API key



validator = ResponseValidator()```

checker = ConsistencyChecker()

#### 2ï¸âƒ£ å¤šç§æ¨¡æ‹Ÿæ¨¡å¼

# Validate response format

is_valid = validator.validate_response(response, question_type)#### Persona Diversity Guidelines



# Check consistency### Installation- **è°ƒæŸ¥æ¨¡å¼**ï¼šè¿è¡Œæ ‡å‡†åŒ–é—®å·ï¼ˆPHQ-9ã€GAD-7 ç­‰ï¼‰

metrics = checker.check_consistency(persona_responses)

print(f"Consistency score: {metrics.consistency_score}")Ensure your virtual sample reflects real population diversity:

```

- **å¹²é¢„æ¨¡å¼**ï¼šæµ‹è¯•å¥åº·ä¿¡æ¯ã€å¹¿å‘Šæ–‡æ¡ˆç­‰å¯¹ä¸åŒäººç¾¤çš„å½±å“

---

- **Age**: Cover different age groups (18-80 years)

## ğŸ“š API Documentation

- **Gender**: Male, female, non-binary#### 1. Clone Repository- **A/B æµ‹è¯•**ï¼šåŒæ—¶æµ‹è¯•å¤šä¸ªç‰ˆæœ¬ï¼Œæ¯”è¾ƒæ•ˆæœå·®å¼‚

### PersonaManager

- **Occupation**: Different industries and position levels

```python

from src import PersonaManager- **Education**: High school to graduate degrees- **çºµå‘ç ”ç©¶**ï¼šæ¨¡æ‹Ÿå¤šæ³¢æ¬¡è°ƒæŸ¥ï¼Œè¿½è¸ªå˜åŒ–è¶‹åŠ¿



manager = PersonaManager()- **Geography**: Urban, rural, different regions



# Add persona- **Cultural Background**: Different ethnicities, religions, cultural traditions```bash- **æ•æ„Ÿæ€§åˆ†æ**ï¼šç³»ç»Ÿæ€§æµ‹è¯•å‚æ•°å˜åŒ–å¯¹ç»“æœçš„å½±å“

manager.add_persona(persona)



# Get all personas

personas = manager.get_all_personas()### Questionnaire Design Tipsgit clone https://github.com/jason-jj-li/auto_sim_ai.git



# Filter by criteria

young_adults = manager.filter_personas(

    age_range=(18, 30),#### Characteristics of Good Questionscd auto_sim_ai#### 3ï¸âƒ£ LLM é›†æˆ

    gender="Female"

)



# Save/loadâœ… **Clear and Specific**```- **æœ¬åœ°éƒ¨ç½²**ï¼šLM Studioï¼ˆå…è´¹ï¼Œå®Œå…¨ç§å¯†ï¼‰

manager.save_to_file("personas.json")

manager.load_from_file("personas.json")

```

```- **å•†ä¸šAPI**ï¼š

### SimulationEngine

Good: "In the past two weeks, how many days have you felt down or depressed?"

```python

from src import SimulationEngineBad: "How have you been feeling lately?"#### 2. Install Dependencies  - DeepSeekï¼ˆé«˜æ€§ä»·æ¯”ï¼Œä¸­æ–‡ä¼˜åŒ–ï¼‰



engine = SimulationEngine(```

    llm_client=client,

    cache=cache,  - OpenAIï¼ˆGPT-4ã€GPT-3.5ï¼‰

    checkpoint_manager=checkpoint_mgr

)âœ… **Avoid Compound Questions**



# Run survey```bash  - å…¶ä»– OpenAI å…¼å®¹æœåŠ¡

result = engine.run_survey(

    personas=personas,```

    questions=questions,

    temperature=0.7,Good: "How many times per week do you exercise?" + "How long is each exercise session?"# Create virtual environment (recommended)- **çµæ´»åˆ‡æ¢**ï¼šéšæ—¶æ›´æ¢æ¨¡å‹æˆ–æä¾›å•†

    max_tokens=300

)Bad: "How often do you exercise, for how long, and at what intensity?"



# Run intervention```python -m venv venv

result = engine.run_intervention(

    personas=personas,

    intervention_text="Health intervention text",

    questions=followup_questionsâœ… **Use Standardized Scales**source venv/bin/activate  # Windows: venv\Scripts\activate#### 4ï¸âƒ£ é«˜çº§åˆ†æ

)

```



### ResultsStorage```- **è‡ªåŠ¨è¯„åˆ†**ï¼šå†…ç½®æ ‡å‡†åŒ–é‡è¡¨çš„è‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿ



```pythonNever(0) - Sometimes(1) - Often(2) - Always(3)

from src import ResultsStorage

```# Install dependencies- **ç»Ÿè®¡åˆ†æ**ï¼šæè¿°ç»Ÿè®¡ã€ç›¸å…³åˆ†æã€ç»„é—´æ¯”è¾ƒ

storage = ResultsStorage()



# Save result

storage.save_result(simulation_result)#### Built-in Templatespip install -r requirements.txt- **ä¸€è‡´æ€§æ£€æŸ¥**ï¼šéªŒè¯å“åº”çš„å†…éƒ¨ä¸€è‡´æ€§å’Œé€»è¾‘æ€§



# Load results

results = storage.load_all_results()

The system includes validated standardized scales:```- **å¯è§†åŒ–**ï¼šäº¤äº’å¼å›¾è¡¨ã€è¯äº‘ã€åˆ†å¸ƒå›¾

# Export to CSV

storage.export_to_csv(result, "output.csv")



# Export analysis script- **PHQ-9**: Depression screening scale- **å¯¼å‡ºåŠŸèƒ½**ï¼šCSVã€JSONã€Python/R åˆ†æè„šæœ¬

storage.export_analysis_script(result, "analysis.py", language="python")

```- **GAD-7**: Anxiety screening scale  



---- **PSS-10**: Perceived Stress ScaleOr use the setup script:



## â“ FAQ- More templates continuously being added...



### Q: How many LLM API calls are needed?#### 5ï¸âƒ£ æ€§èƒ½ä¼˜åŒ–



A: Call count = Number of personas Ã— Number of questions. For example:### Simulation Settings Optimization



- 10 personas Ã— 9 questions = 90 calls```bash- **å¹¶è¡Œæ‰§è¡Œ**ï¼šå¼‚æ­¥å¤„ç†å¤šä¸ªäººç‰©çš„å“åº”

- Using cache can significantly reduce repeat calls

#### Temperature Parameter

### Q: How long does simulation take?

chmod +x setup.sh- **æ™ºèƒ½ç¼“å­˜**ï¼šé¿å…é‡å¤è°ƒç”¨ LLMï¼ŒèŠ‚çœæ—¶é—´å’Œæˆæœ¬

A: Depends on:

Controls response randomness and creativity:

- **Local model**: ~5-15 seconds/response

- **Online API**: ~1-3 seconds/response./setup.sh- **æ–­ç‚¹ç»­ä¼ **ï¼šæ”¯æŒæš‚åœå’Œæ¢å¤å¤§è§„æ¨¡æ¨¡æ‹Ÿ

- **Parallel execution**: Can reduce time by 50-80%

- **0.0 - 0.3**: High consistency, suitable for standardized responses

### Q: How reliable are the results?

- **0.5 - 0.7**: Balanced mode, recommended for most surveys (default)```- **è¿›åº¦è¿½è¸ª**ï¼šå®æ—¶æ˜¾ç¤ºæ¨¡æ‹Ÿè¿›åº¦å’Œé¢„ä¼°å®Œæˆæ—¶é—´

A: LLM simulation is an exploratory research tool, suitable for:

- **0.8 - 1.0**: More diverse, suitable for exploratory research

- âœ… Rapid prototype testing

- âœ… Hypothesis generation

- âœ… Questionnaire pre-testing

- âŒ **Cannot** replace real human research#### Max Tokens



### Q: How to improve response quality?#### 3. Configure LLM---



1. Create detailed, realistic persona backgrounds- **150-300**: Short answers (multiple choice, scale ratings)

2. Use clear, specific questions

3. Choose appropriate temperature parameters- **300-500**: Medium length (short answer questions)

4. Use more powerful models (e.g., GPT-4)

5. Enable response validation and consistency checks- **500-1000**: Detailed responses (open-ended questions, in-depth interviews)



### Q: What are the costs?**Option A: Local LM Studio (recommended for learning/development)**## âš¡ å¿«é€Ÿå¼€å§‹



- **Local LM Studio**: Completely free (requires GPU)#### Parallel Settings

- **DeepSeek API**: ~$0.0001/1k tokens, extremely low cost

- **OpenAI GPT-3.5**: ~$0.002/1k tokens

- **OpenAI GPT-4**: ~$0.03/1k tokens

- **Small Scale** (<10 personas): Concurrency 2-3

### Q: Is my data secure?

- **Medium Scale** (10-50 personas): Concurrency 5-101. Download [LM Studio](https://lmstudio.ai/)### ç³»ç»Ÿè¦æ±‚

- Local mode: Data never leaves your machine

- API mode: Follows each provider's privacy policy- **Large Scale** (50+ personas): Concurrency 10-15 (watch API rate limits)

- Recommendation: Use local mode for sensitive data

2. Download a model in LM Studio:

---

---

## ğŸ¤ Contributing

   - Recommended: `mistral-7b-instruct`, `llama-2-7b-chat`- **Python**: 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for details.

## ğŸ—ï¸ Architecture

### Development Setup

   - Minimum: 7B parameter model- **å†…å­˜**: å»ºè®® 8GB ä»¥ä¸Š

```bash

# Install development dependenciesFor detailed architecture documentation, see **[Architecture Guide](./docs/en/architecture/README.md)**

pip install -r requirements-dev.txt

3. Start local server:- **LLM æä¾›å•†**ï¼ˆä»»é€‰å…¶ä¸€ï¼‰ï¼š

# Run tests

pytest### Project Structure



# Code formatting   - Click "Local Server" tab  - LM Studioï¼ˆæœ¬åœ°è¿è¡Œï¼Œå…è´¹ï¼‰

black src/ tests/

isort src/ tests/```



# Type checkingauto_sim_ai/   - Select model  - DeepSeek/OpenAI API å¯†é’¥

mypy src/

```â”œâ”€â”€ app.py                      # Streamlit main application



### Report Issuesâ”œâ”€â”€ pages/                      # Multi-page application   - Click "Start Server"



Found a bug or have a feature suggestion? Please [create an issue](https://github.com/jason-jj-li/auto_sim_ai/issues).â”‚   â”œâ”€â”€ 1_Setup.py             # Persona management



---â”‚   â”œâ”€â”€ 2_Simulation.py        # Run simulations   - Confirm address is `http://localhost:1234`### å®‰è£…æ­¥éª¤



## ğŸ“„ Licenseâ”‚   â””â”€â”€ 3_Results.py           # View results



This project is licensed under the MIT License. See [LICENSE](LICENSE) file for details.â”œâ”€â”€ src/                        # Core modules



---â”‚   â”œâ”€â”€ llm_client.py          # LLM client (sync/async)



## ğŸ™ Acknowledgmentsâ”‚   â”œâ”€â”€ persona.py             # Persona management**Option B: Online API (recommended for production)**#### 1. å…‹éš†é¡¹ç›®



- [Streamlit](https://streamlit.io/) - Excellent Python web frameworkâ”‚   â”œâ”€â”€ simulation.py          # Simulation engine

- [LM Studio](https://lmstudio.ai/) - Local LLM runtime environment

- [OpenAI](https://openai.com/) - API standardsâ”‚   â”œâ”€â”€ storage.py             # Results storage

- [DeepSeek](https://www.deepseek.com/) - Cost-effective LLM service

â”‚   â”œâ”€â”€ cache.py               # Response caching

---

â”‚   â”œâ”€â”€ scoring.py             # Auto-scoring```bash```bash

## ğŸ“ Contact

â”‚   â””â”€â”€ ...                    # Additional modules

- **Maintainer**: Jason Li

- **GitHub**: [@jason-jj-li](https://github.com/jason-jj-li)â”œâ”€â”€ tests/                      # Test suite# Copy environment templategit clone https://github.com/jason-jj-li/auto_sim_ai.git

- **Email**: [Contact via GitHub Issues]

â”œâ”€â”€ data/                       # Data directory

---

â”‚   â”œâ”€â”€ personas/              # Persona datacp env.example .envcd auto_sim_ai

<div align="center">

â”‚   â”œâ”€â”€ results/               # Simulation results

**â­ If this project helps you, please give it a star!**

â”‚   â””â”€â”€ cache/                 # Cached responses```

Made with â¤ï¸ by Jason Li

â””â”€â”€ docs/                       # Documentation

</div>

```# Edit .env file, add API key



### Core Modules# DEEPSEEK_API_KEY=your_api_key_here#### 2. å®‰è£…ä¾èµ–



**LLM Client** (`llm_client.py`)# or

- Synchronous and asynchronous modes

- Compatible with OpenAI API format# OPENAI_API_KEY=your_api_key_here```bash

- Seamless switching between providers

```# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

**Simulation Engine** (`simulation.py`)

- Sequential and parallel executionpython -m venv venv

- Automatic error retry and progress tracking

- Result aggregation#### 4. Launch Applicationsource venv/bin/activate  # Windows: venv\Scripts\activate



**Cache System** (`cache.py`)

- Content-hash based smart caching

- Significantly reduce API costs```bash# å®‰è£…ä¾èµ–

- Import/export capability

streamlit run app.pypip install -r requirements.txt

**Scoring System** (`scoring.py`)

- Automated scoring for standardized scales``````

- Configurable custom rules

- Total and subscale calculations



---The app will automatically open in your browser: `http://localhost:8501`æˆ–ä½¿ç”¨å®‰è£…è„šæœ¬ï¼š



## ğŸ”¬ Advanced Features```bash



> ğŸ’¡ **See [API Guide](./docs/en/api/README.md) for detailed documentation**### First-Time User Guidechmod +x setup.sh



### 1. A/B Testing./setup.sh



Compare different intervention versions:1. **Connect LLM** (Home Page)```



```python   - Select LLM provider

from src import ABTestManager, Condition

   - Test connection#### 3. é…ç½® LLM

# Define test conditions

condition_a = Condition(   - Wait for "System Ready" message

    name="Version A",

    intervention_text="Meditating 10 minutes daily can reduce stress.",**æ–¹å¼ Aï¼šæœ¬åœ° LM Studioï¼ˆæ¨èç”¨äºå­¦ä¹ å’Œå¼€å‘ï¼‰**

    questions=["Would you try this method?"]

)2. **Create Virtual Personas** (Setup Page)



condition_b = Condition(   - Click "Create Demo Personas" for quick start1. ä¸‹è½½ [LM Studio](https://lmstudio.ai/)

    name="Version B", 

    intervention_text="Research shows daily 10-minute meditation reduces stress by 30%.",   - Or manually create custom personas2. åœ¨ LM Studio ä¸­ä¸‹è½½æ¨¡å‹ï¼š

    questions=["Would you try this method?"]

)   - Or upload CSV for bulk import   - æ¨èï¼š`mistral-7b-instruct`ã€`llama-2-7b-chat`



# Run A/B test   - æœ€ä½ï¼š7B å‚æ•°æ¨¡å‹

ab_manager = ABTestManager()

results = ab_manager.run_test([condition_a, condition_b], personas)3. **Run Simulation** (Simulation Page)3. å¯åŠ¨æœ¬åœ°æœåŠ¡å™¨ï¼š

```

   - Choose simulation type (Survey/Intervention)   - ç‚¹å‡» "Local Server" æ ‡ç­¾

### 2. Longitudinal Studies

   - Select personas to participate   - é€‰æ‹©æ¨¡å‹

Multi-wave tracking with conversation memory:

   - Choose questionnaire template or enter custom questions   - ç‚¹å‡» "Start Server"

```python

from src import LongitudinalStudyEngine, WaveConfig, LongitudinalStudyConfig   - Click "Run Simulation"   - ç¡®è®¤åœ°å€ä¸º `http://localhost:1234`



# Configure study waves

waves = [

    WaveConfig(4. **View Results** (Results Page)**æ–¹å¼ Bï¼šåœ¨çº¿ APIï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰**

        wave_number=1,

        wave_name="Baseline",   - Browse response data

        questions=["What is your current stress level? (1-10)"],

        days_from_baseline=0   - View statistical analysis```bash

    ),

    WaveConfig(   - Export results for further analysis# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿

        wave_number=2,

        wave_name="1 Month Follow-up",cp env.example .env

        questions=["What is your stress level now? (1-10)"],

        days_from_baseline=30,---

        intervention_text="Practice 10 minutes of meditation daily"

    )# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œæ·»åŠ  API å¯†é’¥

]

## ğŸ“– User Guide# DEEPSEEK_API_KEY=your_api_key_here

# Run study

config = LongitudinalStudyConfig(# æˆ–

    study_id="stress_study",

    study_name="Stress Intervention Study",### Persona Design Best Practices# OPENAI_API_KEY=your_api_key_here

    waves=waves

)```



engine = LongitudinalStudyEngine(llm_client)#### Creating High-Quality Personas

results = engine.run_study(personas, config)

```#### 4. å¯åŠ¨åº”ç”¨



See **[Longitudinal Study Guide](./docs/en/longitudinal/README.md)** for details.```python



### 3. Batch Persona Generation# Good Example: Specific, detailed, realistic```bash



Generate samples based on real demographic distributions:{streamlit run app.py



```python    "name": "Sarah Chen",```

from src import PersonaGenerator, DistributionConfig

    "age": 32,

# Configure distribution

config = DistributionConfig(    "gender": "Female",åº”ç”¨å°†åœ¨æµè§ˆå™¨ä¸­è‡ªåŠ¨æ‰“å¼€ï¼š`http://localhost:8501`

    age_distribution={"18-30": 0.3, "31-50": 0.4, "51-70": 0.3},

    gender_distribution={"Male": 0.48, "Female": 0.52}    "occupation": "Software Engineer at startup",

)

    "education": "Bachelor's in Computer Science",### é¦–æ¬¡ä½¿ç”¨æŒ‡å—

# Generate 100 personas

generator = PersonaGenerator()    "location": "San Francisco, CA",

personas = generator.generate_batch(

    count=100,    "background": "Works at a fast-growing tech company, often works overtime. Recently experiencing work stress and sleep quality decline. Likes to relieve stress through exercise but often too busy.",1. **è¿æ¥ LLM**ï¼ˆé¦–é¡µï¼‰

    distribution_config=config,

    llm_client=client    "personality_traits": ["Perfectionist", "Strong sense of responsibility", "Somewhat anxious"],   - é€‰æ‹© LLM æä¾›å•†

)

```    "values": ["Career development", "Work-life balance", "Family health"]   - æµ‹è¯•è¿æ¥



### 4. Response Validation}   - ç­‰å¾…"ç³»ç»Ÿå°±ç»ª"æç¤º



Check response quality and consistency:



```python# Bad Example: Vague, generic2. **åˆ›å»ºè™šæ‹Ÿäººç‰©**ï¼ˆSetup é¡µé¢ï¼‰

from src import ResponseValidator, ConsistencyChecker

{   - ç‚¹å‡» "Create Demo Personas" å¿«é€Ÿåˆ›å»º

validator = ResponseValidator()

checker = ConsistencyChecker()    "name": "John Doe",   - æˆ–æ‰‹åŠ¨åˆ›å»ºè‡ªå®šä¹‰äººç‰©



# Validate format    "age": 30,   - æˆ–ä¸Šä¼  CSV æ‰¹é‡å¯¼å…¥

is_valid = validator.validate_response(response, question_type)

    "gender": "Male",

# Check consistency

metrics = checker.check_consistency(persona_responses)    "occupation": "Engineer",3. **è¿è¡Œæ¨¡æ‹Ÿ**ï¼ˆSimulation é¡µé¢ï¼‰

print(f"Consistency score: {metrics.consistency_score}")

```    "background": "Regular person",   - é€‰æ‹©æ¨¡æ‹Ÿç±»å‹ï¼ˆè°ƒæŸ¥/å¹²é¢„ï¼‰



---    "personality_traits": ["Normal"],   - é€‰æ‹©è¦å‚ä¸çš„äººç‰©



## ğŸ“š API Documentation    "values": ["Happiness"]   - é€‰æ‹©é—®å·æ¨¡æ¿æˆ–è¾“å…¥è‡ªå®šä¹‰é—®é¢˜



### PersonaManager}   - ç‚¹å‡» "Run Simulation"



```python```

from src import PersonaManager

4. **æŸ¥çœ‹ç»“æœ**ï¼ˆResults é¡µé¢ï¼‰

manager = PersonaManager()

#### Persona Diversity   - æµè§ˆå“åº”æ•°æ®

# Add persona

manager.add_persona(persona)   - æŸ¥çœ‹ç»Ÿè®¡åˆ†æ



# Get all personasEnsure virtual samples reflect real population diversity:   - å¯¼å‡ºç»“æœç”¨äºè¿›ä¸€æ­¥åˆ†æ

personas = manager.get_all_personas()



# Filter by criteria

young_adults = manager.filter_personas(- **Age**: Cover different age groups (18-80 years)---

    age_range=(18, 30),

    gender="Female"- **Gender**: Male, female, non-binary

)

- **Occupation**: Different industries and position levels## ğŸ“– ä½¿ç”¨æŒ‡å—

# Save/load

manager.save_to_file("personas.json")- **Education**: High school to graduate degrees

manager.load_from_file("personas.json")

```- **Geography**: Urban, rural, different regions### è™šæ‹Ÿäººç‰©è®¾è®¡æœ€ä½³å®è·µ



### SimulationEngine- **Cultural Background**: Different ethnicities, religions, cultural traditions



```python#### åˆ›å»ºé«˜è´¨é‡äººç‰©

from src import SimulationEngine

### Questionnaire Design Tips

engine = SimulationEngine(

    llm_client=client,```python

    cache=cache,

    checkpoint_manager=checkpoint_mgr#### Good Question Characteristics# å¥½çš„ä¾‹å­ï¼šå…·ä½“ã€è¯¦ç»†ã€çœŸå®

)

{

# Run survey

result = engine.run_survey(âœ… **Clear and Specific**    "name": "ææ˜",

    personas=personas,

    questions=questions,    "age": 32,

    temperature=0.7,

    max_tokens=300```    "gender": "ç”·",

)

Good: In the past two weeks, how many days have you felt down or depressed?    "occupation": "åˆåˆ›å…¬å¸è½¯ä»¶å·¥ç¨‹å¸ˆ",

# Run intervention

result = engine.run_intervention(Bad: How have you been feeling lately?    "education": "æœ¬ç§‘è®¡ç®—æœºç§‘å­¦",

    personas=personas,

    intervention_text="Health intervention text",```    "location": "åŒ—äº¬",

    questions=followup_questions

)    "background": "åœ¨ä¸€å®¶å¿«é€Ÿæˆé•¿çš„ç§‘æŠ€å…¬å¸å·¥ä½œï¼Œç»å¸¸åŠ ç­ã€‚æœ€è¿‘æ„Ÿåˆ°å·¥ä½œå‹åŠ›å¤§ï¼Œç¡çœ è´¨é‡ä¸‹é™ã€‚å–œæ¬¢é€šè¿‡è¿åŠ¨ç¼“è§£å‹åŠ›ï¼Œä½†å·¥ä½œç¹å¿™å¸¸å¸¸æ²¡æ—¶é—´ã€‚",

```

âœ… **Avoid Compound Questions**    "personality_traits": ["å®Œç¾ä¸»ä¹‰", "è´£ä»»å¿ƒå¼º", "æœ‰äº›ç„¦è™‘"],

### ResultsStorage

    "values": ["èŒä¸šå‘å±•", "å·¥ä½œç”Ÿæ´»å¹³è¡¡", "å®¶åº­å¥åº·"]

```python

from src import ResultsStorage```}



storage = ResultsStorage()Good: How many times per week do you exercise? How long is each exercise session?



# Save resultBad: How often do you exercise, for how long, and at what intensity?# ä¸å¥½çš„ä¾‹å­ï¼šæ¨¡ç³Šã€ä¸€èˆ¬åŒ–

storage.save_result(simulation_result)

```{

# Load results

results = storage.load_all_results()    "name": "å¼ ä¸‰",



# Export to CSVâœ… **Use Standardized Scales**    "age": 30,

storage.export_to_csv(result, "output.csv")

    "gender": "ç”·",

# Export analysis script

storage.export_analysis_script(result, "analysis.py", language="python")```    "occupation": "å·¥ç¨‹å¸ˆ",

```

Never(0) - Sometimes(1) - Often(2) - Always(3)    "background": "æ™®é€šäºº",

---

```    "personality_traits": ["æ­£å¸¸"],

## â“ FAQ

    "values": ["å¹¸ç¦"]

### How many LLM API calls are needed?

#### Use Built-in Templates}

Call count = Number of personas Ã— Number of questions

```

Example:

- 10 personas Ã— 9 questions = 90 callsThe system includes validated standardized scales:

- Caching significantly reduces repeat calls

#### äººç‰©å¤šæ ·æ€§

### How long does simulation take?

- **PHQ-9**: Depression screening scale

Depends on:

- **Local model**: ~5-15 seconds/response- **GAD-7**: Anxiety screening scaleç¡®ä¿è™šæ‹Ÿæ ·æœ¬åæ˜ çœŸå®äººå£çš„å¤šæ ·æ€§ï¼š

- **Online API**: ~1-3 seconds/response

- **Parallel execution**: Can reduce time by 50-80%- **PSS-10**: Perceived Stress Scale



### How reliable are the results?- More templates continuously being added...- **å¹´é¾„**ï¼šè¦†ç›–ä¸åŒå¹´é¾„æ®µï¼ˆ18-80å²ï¼‰



LLM simulation is an exploratory research tool, suitable for:- **æ€§åˆ«**ï¼šç”·ã€å¥³ã€éäºŒå…ƒæ€§åˆ«



âœ… Rapid prototyping  ### Simulation Settings Optimization- **èŒä¸š**ï¼šä¸åŒè¡Œä¸šå’ŒèŒä½å±‚çº§

âœ… Hypothesis generation  

âœ… Questionnaire pre-testing  - **æ•™è‚²**ï¼šä»é«˜ä¸­åˆ°ç ”ç©¶ç”Ÿ

âŒ **Cannot** replace real human research

#### Temperature Parameter- **åœ°åŸŸ**ï¼šåŸå¸‚ã€å†œæ‘ã€ä¸åŒåœ°åŒº

### How to improve response quality?

- **æ–‡åŒ–èƒŒæ™¯**ï¼šä¸åŒç§æ—ã€å®—æ•™ã€æ–‡åŒ–ä¼ ç»Ÿ

1. Create detailed, realistic persona backgrounds

2. Use clear, specific questionsControls response randomness and creativity:

3. Choose appropriate temperature parameters

4. Use more powerful models (e.g., GPT-4)### é—®å·è®¾è®¡æŠ€å·§

5. Enable response validation and consistency checks

- **0.0 - 0.3**: High consistency, suitable for standardized responses

### What about costs?

- **0.5 - 0.7**: Balanced mode, recommended for most surveys (default)#### å¥½çš„é—®é¢˜ç‰¹å¾

- **Local LM Studio**: Completely free (requires GPU)

- **DeepSeek API**: ~$0.0001/1k tokens (extremely low cost)- **0.8 - 1.0**: More diverse, suitable for exploratory research and creative testing

- **OpenAI GPT-3.5**: ~$0.002/1k tokens

- **OpenAI GPT-4**: ~$0.03/1k tokensâœ… **æ¸…æ™°å…·ä½“**



### Is my data secure?#### Max Tokens```



- **Local mode**: Data never leaves your machineå¥½ï¼šåœ¨è¿‡å»ä¸¤å‘¨å†…ï¼Œæ‚¨æœ‰å¤šå°‘å¤©æ„Ÿåˆ°æƒ…ç»ªä½è½æˆ–æ²®ä¸§ï¼Ÿ

- **API mode**: Follows each provider's privacy policy

- **Recommendation**: Use local mode for sensitive data- **150-300**: Short answers (multiple choice, scale ratings)å·®ï¼šæ‚¨æœ€è¿‘å¿ƒæƒ…æ€ä¹ˆæ ·ï¼Ÿ



---- **300-500**: Medium length (short answer questions)```



## ğŸ¤ Contributing- **500-1000**: Detailed responses (open-ended questions, in-depth interviews)



Contributions welcome! See [Contributing Guide](./docs/en/contributing/README.md) for details.âœ… **é¿å…å¤åˆé—®é¢˜**



### Development Setup#### Parallel Settings```



```bashå¥½ï¼šæ‚¨æ¯å‘¨é”»ç‚¼å¤šå°‘æ¬¡ï¼Ÿæ‚¨æ¯æ¬¡é”»ç‚¼å¤šé•¿æ—¶é—´ï¼Ÿ

# Install development dependencies

pip install -r requirements-dev.txt- **Small Scale** (<10 personas): Concurrency 2-3å·®ï¼šæ‚¨å¤šä¹…é”»ç‚¼ä¸€æ¬¡ï¼Œæ¯æ¬¡å¤šé•¿æ—¶é—´ï¼Œä»€ä¹ˆå¼ºåº¦ï¼Ÿ



# Run tests- **Medium Scale** (10-50 personas): Concurrency 5-10```

pytest

- **Large Scale** (50+ personas): Concurrency 10-15 (watch API rate limits)

# Code formatting

black src/ tests/âœ… **ä½¿ç”¨æ ‡å‡†åŒ–é‡è¡¨**

isort src/ tests/

---```

# Type checking

mypy src/ä»ä¸(0) - å¶å°”(1) - ç»å¸¸(2) - æ€»æ˜¯(3)

```

## ğŸ—ï¸ Architecture```

### Report Issues



Found a bug or have a feature suggestion? Please [create an issue](https://github.com/jason-jj-li/auto_sim_ai/issues).

For detailed architecture documentation, see **[Architecture Guide](./docs/en/architecture/README.md)**#### ä½¿ç”¨å†…ç½®æ¨¡æ¿

---



## ğŸ“„ License

### Project Structureç³»ç»Ÿå†…ç½®å¤šä¸ªéªŒè¯è¿‡çš„æ ‡å‡†åŒ–é‡è¡¨ï¼š

This project is licensed under the MIT License. See [LICENSE](LICENSE) file for details.



---

```- **PHQ-9**ï¼šæŠ‘éƒç—‡ç­›æŸ¥é‡è¡¨

## ğŸ™ Acknowledgments

auto_sim_ai/- **GAD-7**ï¼šç„¦è™‘ç—‡ç­›æŸ¥é‡è¡¨

- [Streamlit](https://streamlit.io/) - Python web framework

- [LM Studio](https://lmstudio.ai/) - Local LLM runtimeâ”œâ”€â”€ app.py                      # Streamlit main application- **PSS-10**ï¼šå‹åŠ›æ„ŸçŸ¥é‡è¡¨

- [OpenAI](https://openai.com/) - API standards

- [DeepSeek](https://www.deepseek.com/) - Cost-effective LLM serviceâ”œâ”€â”€ pages/                      # Multi-page application- æ›´å¤šæ¨¡æ¿æŒç»­æ·»åŠ ä¸­...



---â”‚   â”œâ”€â”€ 1_Setup.py             # Persona management page



## ğŸ“ Contactâ”‚   â”œâ”€â”€ 2_Simulation.py        # Simulation execution page### æ¨¡æ‹Ÿè®¾ç½®ä¼˜åŒ–



- **Maintainer**: Jason Liâ”‚   â””â”€â”€ 3_Results.py           # Results analysis page

- **GitHub**: [@jason-jj-li](https://github.com/jason-jj-li)

- **Email**: Contact via GitHub Issuesâ”œâ”€â”€ src/                        # Core modules#### æ¸©åº¦å‚æ•°ï¼ˆTemperatureï¼‰



---â”‚   â”œâ”€â”€ llm_client.py          # LLM client (sync/async)



<div align="center">â”‚   â”œâ”€â”€ persona.py             # Persona managementæ§åˆ¶å“åº”çš„éšæœºæ€§å’Œåˆ›é€ æ€§ï¼š



**â­ If this project helps you, please give it a star!**â”‚   â”œâ”€â”€ simulation.py          # Simulation engine (single/parallel)



Made with â¤ï¸ by Jason Liâ”‚   â”œâ”€â”€ storage.py             # Results storage- **0.0 - 0.3**ï¼šé«˜åº¦ä¸€è‡´ï¼Œé€‚åˆéœ€è¦æ ‡å‡†åŒ–å“åº”çš„åœºæ™¯



</div>â”‚   â”œâ”€â”€ cache.py               # Response cache- **0.5 - 0.7**ï¼šå¹³è¡¡æ¨¡å¼ï¼Œæ¨èç”¨äºå¤§å¤šæ•°è°ƒæŸ¥ï¼ˆé»˜è®¤ï¼‰


â”‚   â”œâ”€â”€ checkpoint.py          # Checkpoint management- **0.8 - 1.0**ï¼šæ›´å¤šæ ·åŒ–ï¼Œé€‚åˆæ¢ç´¢æ€§ç ”ç©¶å’Œåˆ›æ„æµ‹è¯•

â”‚   â”œâ”€â”€ scoring.py             # Auto-scoring

â”‚   â”œâ”€â”€ ab_testing.py          # A/B testing#### æœ€å¤§ä»¤ç‰Œæ•°ï¼ˆMax Tokensï¼‰

â”‚   â”œâ”€â”€ intervention_study.py  # Intervention studies (legacy)

â”‚   â”œâ”€â”€ persona_generator.py   # Persona generator- **150-300**ï¼šç®€çŸ­ç­”æ¡ˆï¼ˆé€‰æ‹©é¢˜ã€é‡è¡¨è¯„åˆ†ï¼‰

â”‚   â”œâ”€â”€ survey_templates.py    # Survey template library- **300-500**ï¼šä¸­ç­‰é•¿åº¦ï¼ˆç®€ç­”é¢˜ï¼‰

â”‚   â”œâ”€â”€ survey_config.py       # Survey configuration- **500-1000**ï¼šè¯¦ç»†å›ç­”ï¼ˆå¼€æ”¾å¼é—®é¢˜ã€æ·±åº¦è®¿è°ˆï¼‰

â”‚   â”œâ”€â”€ tools.py               # Tool registration system

â”‚   â”œâ”€â”€ ui_components.py       # UI components#### å¹¶è¡Œè®¾ç½®

â”‚   â”œâ”€â”€ styles.py              # Design system

â”‚   â””â”€â”€ validators.py          # Input validation- **å°è§„æ¨¡**ï¼ˆ<10äººï¼‰ï¼šå¹¶å‘æ•° 2-3

â”œâ”€â”€ tests/                      # Test suite- **ä¸­ç­‰è§„æ¨¡**ï¼ˆ10-50äººï¼‰ï¼šå¹¶å‘æ•° 5-10

â”œâ”€â”€ data/                       # Data directory- **å¤§è§„æ¨¡**ï¼ˆ50+äººï¼‰ï¼šå¹¶å‘æ•° 10-15ï¼ˆæ³¨æ„APIé€Ÿç‡é™åˆ¶ï¼‰

â”‚   â”œâ”€â”€ personas/              # Persona data

â”‚   â”œâ”€â”€ results/               # Simulation results---

â”‚   â”œâ”€â”€ cache/                 # Cache data

â”‚   â”œâ”€â”€ checkpoints/           # Checkpoints## ğŸ—ï¸ æ¶æ„è®¾è®¡

â”‚   â””â”€â”€ survey_configs/        # Survey configurations

â”œâ”€â”€ docs/                       # Documentationè¯¦ç»†çš„æ¶æ„æ–‡æ¡£è¯·æŸ¥çœ‹ **[Architecture Guide](./docs/architecture/README.md)**

â”œâ”€â”€ requirements.txt            # Dependencies

â””â”€â”€ pytest.ini                 # Test configuration### é¡¹ç›®ç»“æ„

```

```

### Core Module Overviewauto_sim_ai/

â”œâ”€â”€ app.py                      # Streamlit ä¸»åº”ç”¨

#### LLM Client (`llm_client.py`)â”œâ”€â”€ pages/                      # å¤šé¡µé¢åº”ç”¨

â”‚   â”œâ”€â”€ 1_Setup.py             # äººç‰©ç®¡ç†é¡µé¢

Supports both synchronous and asynchronous modes:â”‚   â”œâ”€â”€ 2_Simulation.py        # æ¨¡æ‹Ÿè¿è¡Œé¡µé¢

â”‚   â””â”€â”€ 3_Results.py           # ç»“æœåˆ†æé¡µé¢

- **LMStudioClient**: Sync client, suitable for simple scenariosâ”œâ”€â”€ src/                        # æ ¸å¿ƒæ¨¡å—

- **AsyncLLMClient**: Async client, supports high concurrencyâ”‚   â”œâ”€â”€ llm_client.py          # LLM å®¢æˆ·ç«¯ï¼ˆåŒæ­¥/å¼‚æ­¥ï¼‰

â”‚   â”œâ”€â”€ persona.py             # äººç‰©ç®¡ç†

Compatible with OpenAI API format, seamless switching between providers.â”‚   â”œâ”€â”€ simulation.py          # æ¨¡æ‹Ÿå¼•æ“ï¼ˆå•çº¿ç¨‹/å¹¶è¡Œï¼‰

â”‚   â”œâ”€â”€ storage.py             # ç»“æœå­˜å‚¨

#### Simulation Engine (`simulation.py`)â”‚   â”œâ”€â”€ cache.py               # å“åº”ç¼“å­˜

â”‚   â”œâ”€â”€ checkpoint.py          # æ–­ç‚¹ç®¡ç†

- **SimulationEngine**: Base engine, sequential executionâ”‚   â”œâ”€â”€ scoring.py             # è‡ªåŠ¨è¯„åˆ†

- **ParallelSimulationEngine**: Parallel engine, supports async batch processingâ”‚   â”œâ”€â”€ ab_testing.py          # A/Bæµ‹è¯•

â”‚   â”œâ”€â”€ intervention_study.py  # å¹²é¢„ç ”ç©¶ï¼ˆæ—§ç‰ˆï¼‰

Automatically handles error retry, progress tracking, result aggregation.â”‚   â”œâ”€â”€ longitudinal_study.py  # çºµå‘ç ”ç©¶ï¼ˆæ–°ç‰ˆï¼Œæ¨èï¼‰

â”‚   â”œâ”€â”€ persona_generator.py   # äººç‰©ç”Ÿæˆå™¨

#### Cache System (`cache.py`)â”‚   â”œâ”€â”€ survey_templates.py    # é—®å·æ¨¡æ¿åº“

â”‚   â”œâ”€â”€ survey_config.py       # é—®å·é…ç½®

Content-hash based smart caching:â”‚   â”œâ”€â”€ tools.py               # å·¥å…·æ³¨å†Œç³»ç»Ÿ

â”‚   â”œâ”€â”€ ui_components.py       # UI ç»„ä»¶

- Same persona + same question = directly return cached resultâ”‚   â”œâ”€â”€ styles.py              # è®¾è®¡ç³»ç»Ÿ

- Support cache export and importâ”‚   â””â”€â”€ validators.py          # è¾“å…¥éªŒè¯

- Significantly reduce LLM API call costsâ”œâ”€â”€ tests/                      # æµ‹è¯•å¥—ä»¶

â”œâ”€â”€ data/                       # æ•°æ®ç›®å½•

#### Scoring System (`scoring.py`)â”‚   â”œâ”€â”€ personas/              # äººç‰©æ•°æ®

â”‚   â”œâ”€â”€ results/               # æ¨¡æ‹Ÿç»“æœ

Automated scoring features:â”‚   â”œâ”€â”€ cache/                 # ç¼“å­˜æ•°æ®

â”‚   â”œâ”€â”€ checkpoints/           # æ£€æŸ¥ç‚¹

- Support for multiple standardized scalesâ”‚   â””â”€â”€ survey_configs/        # é—®å·é…ç½®

- Configurable custom scoring rulesâ”œâ”€â”€ docs/                       # æ–‡æ¡£

- Auto-calculate total and subscale scoresâ”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨

â””â”€â”€ pytest.ini                 # æµ‹è¯•é…ç½®

---```



## ğŸ”¬ Advanced Features### æ ¸å¿ƒæ¨¡å—è¯´æ˜



> ğŸ’¡ **Tip**: For detailed API documentation and advanced features, see [API Guide](./docs/en/api/README.md)#### LLM å®¢æˆ·ç«¯ (`llm_client.py`)



### 1. A/B Testingæ”¯æŒåŒæ­¥å’Œå¼‚æ­¥ä¸¤ç§æ¨¡å¼ï¼š



Compare intervention effects across versions:- **LMStudioClient**ï¼šåŒæ­¥å®¢æˆ·ç«¯ï¼Œé€‚åˆç®€å•åœºæ™¯

- **AsyncLLMClient**ï¼šå¼‚æ­¥å®¢æˆ·ç«¯ï¼Œæ”¯æŒé«˜å¹¶å‘

```python

from src import ABTestManager, Conditionå…¼å®¹ OpenAI API æ ¼å¼ï¼Œå¯æ— ç¼åˆ‡æ¢ä¸åŒæä¾›å•†ã€‚



# Define test conditions#### æ¨¡æ‹Ÿå¼•æ“ (`simulation.py`)

condition_a = Condition(

    name="Version A",- **SimulationEngine**ï¼šåŸºç¡€å¼•æ“ï¼Œé¡ºåºæ‰§è¡Œ

    intervention_text="Meditating 10 minutes daily can reduce stress.",- **ParallelSimulationEngine**ï¼šå¹¶è¡Œå¼•æ“ï¼Œæ”¯æŒå¼‚æ­¥æ‰¹å¤„ç†

    questions=["Would you try this method?"]

)è‡ªåŠ¨å¤„ç†é”™è¯¯é‡è¯•ã€è¿›åº¦è¿½è¸ªã€ç»“æœèšåˆã€‚



condition_b = Condition(#### ç¼“å­˜ç³»ç»Ÿ (`cache.py`)

    name="Version B", 

    intervention_text="Research shows daily 10-minute meditation reduces stress levels by 30%.",åŸºäºå†…å®¹å“ˆå¸Œçš„æ™ºèƒ½ç¼“å­˜ï¼š

    questions=["Would you try this method?"]- ç›¸åŒäººç‰© + ç›¸åŒé—®é¢˜ = ç›´æ¥è¿”å›ç¼“å­˜ç»“æœ

)- æ”¯æŒç¼“å­˜å¯¼å‡ºå’Œå¯¼å…¥

- æ˜¾è‘—é™ä½ LLM API è°ƒç”¨æˆæœ¬

# Run A/B test

ab_manager = ABTestManager()#### è¯„åˆ†ç³»ç»Ÿ (`scoring.py`)

results = ab_manager.run_test([condition_a, condition_b], personas)

```è‡ªåŠ¨åŒ–è¯„åˆ†åŠŸèƒ½ï¼š

- æ”¯æŒå¤šç§æ ‡å‡†åŒ–é‡è¡¨

### 2. Longitudinal Studies (Multi-Wave Tracking)- å¯é…ç½®è‡ªå®šä¹‰è¯„åˆ†è§„åˆ™

- è‡ªåŠ¨è®¡ç®—æ€»åˆ†å’Œå­é‡è¡¨åˆ†æ•°

Implement realistic longitudinal tracking with conversation memory:

---

```python

from src import LongitudinalStudyEngine, WaveConfig, LongitudinalStudyConfig## ğŸ”¬ é«˜çº§åŠŸèƒ½



# Configure study waves> ğŸ’¡ **æç¤º**: è¯¦ç»†çš„APIæ–‡æ¡£å’Œé«˜çº§åŠŸèƒ½è¯·æŸ¥çœ‹ [API Guide](./docs/api/README.md)

waves = [

    WaveConfig(### 1. A/B æµ‹è¯•

        wave_number=1,

        wave_name="Baseline",æ¯”è¾ƒä¸åŒç‰ˆæœ¬çš„å¹²é¢„æ•ˆæœï¼š

        questions=["What is your current stress level? (1-10)"],

        days_from_baseline=0```python

    ),from src import ABTestManager, Condition

    WaveConfig(

        wave_number=2,# å®šä¹‰æµ‹è¯•æ¡ä»¶

        wave_name="1 Month Follow-up",condition_a = Condition(

        questions=["What is your stress level now? (1-10)"],    name="ç‰ˆæœ¬A",

        days_from_baseline=30,    intervention_text="æ¯å¤©å†¥æƒ³10åˆ†é’Ÿå¯ä»¥é™ä½å‹åŠ›ã€‚",

        intervention_text="Practice 10 minutes of meditation daily"    questions=["æ‚¨ä¼šå°è¯•è¿™ä¸ªæ–¹æ³•å—ï¼Ÿ"]

    ))

]

condition_b = Condition(

# Run longitudinal study    name="ç‰ˆæœ¬B", 

config = LongitudinalStudyConfig(    intervention_text="ç ”ç©¶è¡¨æ˜ï¼Œæ¯å¤©å†¥æƒ³10åˆ†é’Ÿå¯ä»¥é™ä½30%çš„å‹åŠ›æ°´å¹³ã€‚",

    study_id="stress_study",    questions=["æ‚¨ä¼šå°è¯•è¿™ä¸ªæ–¹æ³•å—ï¼Ÿ"]

    study_name="Stress Intervention Study",)

    waves=waves

)# è¿è¡ŒA/Bæµ‹è¯•

ab_manager = ABTestManager()

engine = LongitudinalStudyEngine(llm_client)results = ab_manager.run_test([condition_a, condition_b], personas)

results = engine.run_study(personas, config)```

```

### 2. çºµå‘ç ”ç©¶ï¼ˆå¤šæ³¢æ¬¡è¿½è¸ªï¼‰

For detailed longitudinal study guide, see **[Longitudinal Study Guide](./docs/en/longitudinal/README.md)**

ä½¿ç”¨å¯¹è¯è®°å¿†å®ç°çœŸå®çš„çºµå‘è¿½è¸ªï¼š

### 3. Batch Persona Generation

```python

Generate virtual samples based on real demographic distributions:from src import LongitudinalStudyEngine, WaveConfig, LongitudinalStudyConfig



```python# é…ç½®ç ”ç©¶æ³¢æ¬¡

from src import PersonaGenerator, DistributionConfigwaves = [

    WaveConfig(

# Configure distribution        wave_number=1,

config = DistributionConfig(        wave_name="åŸºçº¿",

    age_distribution={        questions=["æ‚¨ç›®å‰çš„å‹åŠ›æ°´å¹³å¦‚ä½•ï¼Ÿ(1-10)"],

        "18-30": 0.3,        days_from_baseline=0

        "31-50": 0.4,    ),

        "51-70": 0.3    WaveConfig(

    },        wave_number=2,

    gender_distribution={        wave_name="1ä¸ªæœˆå",

        "Male": 0.48,        questions=["æ‚¨ç°åœ¨çš„å‹åŠ›æ°´å¹³å¦‚ä½•ï¼Ÿ(1-10)"],

        "Female": 0.52        days_from_baseline=30,

    }        intervention_text="æ¯å¤©ç»ƒä¹ 10åˆ†é’Ÿå†¥æƒ³"

)    )

]

# Generate 100 personas

generator = PersonaGenerator()# è¿è¡Œçºµå‘ç ”ç©¶

personas = generator.generate_batch(config = LongitudinalStudyConfig(

    count=100,    study_id="stress_study",

    distribution_config=config,    study_name="å‹åŠ›å¹²é¢„ç ”ç©¶",

    llm_client=client    waves=waves

))

```

engine = LongitudinalStudyEngine(llm_client)

### 4. Response Validationresults = engine.run_study(personas, config)

```

Automatically check response quality and consistency:

è¯¦ç»†çš„çºµå‘ç ”ç©¶æŒ‡å—è¯·æŸ¥çœ‹ **[Longitudinal Study Guide](./docs/longitudinal/README.md)**

```python

from src import ResponseValidator, ConsistencyChecker### 3. æ‰¹é‡äººç‰©ç”Ÿæˆ



validator = ResponseValidator()åŸºäºçœŸå®äººå£ç»Ÿè®¡åˆ†å¸ƒç”Ÿæˆè™šæ‹Ÿæ ·æœ¬ï¼š

checker = ConsistencyChecker()

```python

# Validate response formatfrom src import PersonaGenerator, DistributionConfig

is_valid = validator.validate_response(response, question_type)

# é…ç½®åˆ†å¸ƒ

# Check consistencyconfig = DistributionConfig(

metrics = checker.check_consistency(persona_responses)    age_distribution={

print(f"Consistency score: {metrics.consistency_score}")        "18-30": 0.3,

```        "31-50": 0.4,

        "51-70": 0.3

---    },

    gender_distribution={

## ğŸ“š API Documentation        "ç”·": 0.48,

        "å¥³": 0.52

### PersonaManager    }

)

```python

from src import PersonaManager# ç”Ÿæˆ100ä¸ªäººç‰©

generator = PersonaGenerator()

manager = PersonaManager()personas = generator.generate_batch(

    count=100,

# Add persona    distribution_config=config,

manager.add_persona(persona)    llm_client=client

)

# Get all personas```

personas = manager.get_all_personas()

### 5. å“åº”éªŒè¯

# Filter by criteria

young_adults = manager.filter_personas(è‡ªåŠ¨æ£€æŸ¥å“åº”è´¨é‡å’Œä¸€è‡´æ€§ï¼š

    age_range=(18, 30),

    gender="Female"```python

)from src import ResponseValidator, ConsistencyChecker



# Save/loadvalidator = ResponseValidator()

manager.save_to_file("personas.json")checker = ConsistencyChecker()

manager.load_from_file("personas.json")

```# éªŒè¯å“åº”æ ¼å¼

is_valid = validator.validate_response(response, question_type)

### SimulationEngine

# æ£€æŸ¥ä¸€è‡´æ€§

```pythonmetrics = checker.check_consistency(persona_responses)

from src import SimulationEngineprint(f"ä¸€è‡´æ€§å¾—åˆ†: {metrics.consistency_score}")

```

engine = SimulationEngine(

    llm_client=client,---

    cache=cache,

    checkpoint_manager=checkpoint_mgr## ğŸ“š API æ–‡æ¡£

)

### PersonaManager

# Run survey

result = engine.run_survey(```python

    personas=personas,from src import PersonaManager

    questions=questions,

    temperature=0.7,manager = PersonaManager()

    max_tokens=300

)# æ·»åŠ äººç‰©

manager.add_persona(persona)

# Run intervention

result = engine.run_intervention(# è·å–æ‰€æœ‰äººç‰©

    personas=personas,personas = manager.get_all_personas()

    intervention_text="Health intervention text",

    questions=followup_questions# æŒ‰æ¡ä»¶ç­›é€‰

)young_adults = manager.filter_personas(

```    age_range=(18, 30),

    gender="å¥³"

### ResultsStorage)



```python# ä¿å­˜/åŠ è½½

from src import ResultsStoragemanager.save_to_file("personas.json")

manager.load_from_file("personas.json")

storage = ResultsStorage()```



# Save result### SimulationEngine

storage.save_result(simulation_result)

```python

# Load resultsfrom src import SimulationEngine

results = storage.load_all_results()

engine = SimulationEngine(

# Export to CSV    llm_client=client,

storage.export_to_csv(result, "output.csv")    cache=cache,

    checkpoint_manager=checkpoint_mgr

# Export analysis script)

storage.export_analysis_script(result, "analysis.py", language="python")

```# è¿è¡Œè°ƒæŸ¥

result = engine.run_survey(

---    personas=personas,

    questions=questions,

## â“ FAQ    temperature=0.7,

    max_tokens=300

### Q: How many LLM API calls are needed?)



A: Call count = Number of personas Ã— Number of questions. For example:# è¿è¡Œå¹²é¢„

result = engine.run_intervention(

- 10 personas Ã— 9 questions = 90 calls    personas=personas,

- Caching can significantly reduce repeat calls    intervention_text="å¥åº·å¹²é¢„æ–‡æœ¬",

    questions=followup_questions

### Q: How long does simulation take?)

```

A: Depends on:

### ResultsStorage

- **Local model**: ~5-15 seconds/response

- **Online API**: ~1-3 seconds/response```python

- **Parallel execution**: Can reduce time by 50-80%from src import ResultsStorage



### Q: How reliable are the results?storage = ResultsStorage()



A: LLM simulation is an exploratory research tool, suitable for:# ä¿å­˜ç»“æœ

storage.save_result(simulation_result)

- âœ… Rapid prototyping

- âœ… Hypothesis generation# åŠ è½½ç»“æœ

- âœ… Questionnaire pre-testingresults = storage.load_all_results()

- âŒ **Cannot** replace real human research

# å¯¼å‡ºä¸ºCSV

### Q: How to improve response quality?storage.export_to_csv(result, "output.csv")



1. Create detailed, realistic persona backgrounds# å¯¼å‡ºåˆ†æè„šæœ¬

2. Use clear, specific questionsstorage.export_analysis_script(result, "analysis.py", language="python")

3. Choose appropriate temperature parameters```

4. Use more powerful models (e.g., GPT-4)

5. Enable response validation and consistency checks---



### Q: What about costs?## â“ å¸¸è§é—®é¢˜



- **Local LM Studio**: Completely free (requires GPU)### Q: éœ€è¦å¤šå°‘ LLM API è°ƒç”¨ï¼Ÿ

- **DeepSeek API**: ~$0.0001/1k tokens, extremely low cost

- **OpenAI GPT-3.5**: ~$0.002/1k tokensA: è°ƒç”¨æ¬¡æ•° = äººç‰©æ•°é‡ Ã— é—®é¢˜æ•°é‡ã€‚ä¾‹å¦‚ï¼š

- **OpenAI GPT-4**: ~$0.03/1k tokens- 10ä¸ªäººç‰© Ã— 9ä¸ªé—®é¢˜ = 90æ¬¡è°ƒç”¨

- ä½¿ç”¨ç¼“å­˜å¯å¤§å¹…å‡å°‘é‡å¤è°ƒç”¨

### Q: Is my data secure?

### Q: æ¨¡æ‹Ÿéœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

- Local mode: Data never leaves your machine

- API mode: Follows each provider's privacy policyA: å–å†³äºï¼š

- Recommendation: Use local mode for sensitive data- **æœ¬åœ°æ¨¡å‹**ï¼šçº¦ 5-15 ç§’/å“åº”

- **åœ¨çº¿API**ï¼šçº¦ 1-3 ç§’/å“åº”

---- **å¹¶è¡Œæ‰§è¡Œ**ï¼šå¯ç¼©çŸ­ 50-80% æ—¶é—´



## ğŸ¤ Contributing### Q: ç»“æœçš„å¯é æ€§å¦‚ä½•ï¼Ÿ



Contributions welcome! See [CONTRIBUTING.md](./docs/en/contributing/README.md) for details.A: LLMæ¨¡æ‹Ÿæ˜¯æ¢ç´¢æ€§ç ”ç©¶å·¥å…·ï¼Œé€‚åˆï¼š

- âœ… å¿«é€ŸåŸå‹æµ‹è¯•

### Development Setup- âœ… å‡è®¾ç”Ÿæˆ

- âœ… é—®å·é¢„æµ‹è¯•

```bash- âŒ **ä¸èƒ½**æ›¿ä»£çœŸå®äººç±»ç ”ç©¶

# Install development dependencies

pip install -r requirements-dev.txt### Q: å¦‚ä½•æé«˜å“åº”è´¨é‡ï¼Ÿ



# Run tests1. åˆ›å»ºè¯¦ç»†ã€çœŸå®çš„äººç‰©èƒŒæ™¯

pytest2. ä½¿ç”¨æ¸…æ™°ã€å…·ä½“çš„é—®é¢˜

3. é€‰æ‹©åˆé€‚çš„æ¸©åº¦å‚æ•°

# Code formatting4. ä½¿ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹ï¼ˆå¦‚ GPT-4ï¼‰

black src/ tests/5. å¯ç”¨å“åº”éªŒè¯å’Œä¸€è‡´æ€§æ£€æŸ¥

isort src/ tests/

### Q: æˆæœ¬å¦‚ä½•ï¼Ÿ

# Type checking

mypy src/- **æœ¬åœ°LM Studio**ï¼šå®Œå…¨å…è´¹ï¼ˆéœ€è¦GPUï¼‰

```- **DeepSeek API**ï¼š~0.001å…ƒ/åƒtokenï¼Œæä½æˆæœ¬

- **OpenAI GPT-3.5**ï¼š~0.015å…ƒ/åƒtoken

### Report Issues- **OpenAI GPT-4**ï¼š~0.3å…ƒ/åƒtoken



Found a bug or have a feature suggestion? Please [create an issue](https://github.com/jason-jj-li/auto_sim_ai/issues).### Q: æ•°æ®å®‰å…¨å—ï¼Ÿ



---- æœ¬åœ°æ¨¡å¼ï¼šæ•°æ®å®Œå…¨ä¸å‡ºæœ¬åœ°

- APIæ¨¡å¼ï¼šéµå¾ªå„æä¾›å•†çš„éšç§æ”¿ç­–

## ğŸ“„ License- å»ºè®®ï¼šæ•æ„Ÿæ•°æ®ä½¿ç”¨æœ¬åœ°æ¨¡å¼



This project is licensed under the MIT License. See [LICENSE](LICENSE) file for details.---



---## ğŸ¤ è´¡çŒ®



## ğŸ™ Acknowledgmentsæ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£è¯¦æƒ…ã€‚



- [Streamlit](https://streamlit.io/) - Excellent Python web framework### å¼€å‘è®¾ç½®

- [LM Studio](https://lmstudio.ai/) - Local LLM runtime environment

- [OpenAI](https://openai.com/) - API standards```bash

- [DeepSeek](https://www.deepseek.com/) - Cost-effective LLM service# å®‰è£…å¼€å‘ä¾èµ–

pip install -r requirements-dev.txt

---

# è¿è¡Œæµ‹è¯•

## ğŸ“ Contactpytest



- **Maintainer**: Jason Li# ä»£ç æ ¼å¼åŒ–

- **GitHub**: [@jason-jj-li](https://github.com/jason-jj-li)black src/ tests/

- **Email**: [Contact via GitHub Issues]isort src/ tests/



---# ç±»å‹æ£€æŸ¥

mypy src/

<div align="center">```



**â­ If this project helps you, please give it a star!**### æŠ¥å‘Šé—®é¢˜



Made with â¤ï¸ by Jason Liå‘ç° Bug æˆ–æœ‰åŠŸèƒ½å»ºè®®ï¼Ÿè¯·[åˆ›å»º Issue](https://github.com/jason-jj-li/auto_sim_ai/issues)ã€‚



</div>---


## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

## ğŸ™ è‡´è°¢

- [Streamlit](https://streamlit.io/) - ä¼˜ç§€çš„Python Webæ¡†æ¶
- [LM Studio](https://lmstudio.ai/) - æœ¬åœ°LLMè¿è¡Œç¯å¢ƒ
- [OpenAI](https://openai.com/) - APIæ ‡å‡†
- [DeepSeek](https://www.deepseek.com/) - é«˜æ€§ä»·æ¯”LLMæœåŠ¡

---

## ğŸ“ è”ç³»æ–¹å¼

- **ç»´æŠ¤è€…**: Jason Li
- **GitHub**: [@jason-jj-li](https://github.com/jason-jj-li)
- **Email**: [é€šè¿‡GitHub Issuesè”ç³»]

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸€ä¸ªæ˜Ÿæ ‡ï¼**

Made with â¤ï¸ by Jason Li

</div>
